{
    "instances": [
        {
            "network": "cifar10_2_255_simplified",
            "property": "cifar10_spec_idx_0_eps_0.00784_n1",
            "timeout": "300",
            "verifier": "abcrown",
            "config": "Configuration(values={\n  'attack__attack_mode': 'PGD',\n  'attack__enable_mip_attack': False,\n  'attack__pgd_order': 'before',\n  'bab__branching__input_split__enable': False,\n  'bab__branching__method': 'kfsb',\n  'bab__branching__reduceop': 'min',\n  'general__complete_verifier': 'bab',\n  'general__enable_incomplete_verification': True,\n  'general__loss_reduction_func': 'sum',\n  'solver__bound_prop_method': 'alpha-crown',\n})",
            "success": "OK",
            "result": "SAT",
            "took": "6.801259279251099",
            "stderr": "",
            "stdout": "/bin/bash: /home/tristan/miniconda3/envs/__av__abcrown/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nConfigurations:\n\ngeneral:\n  device: cuda\n  seed: 100\n  conv_mode: patches\n  deterministic: false\n  double_fp: false\n  loss_reduction_func: sum\n  record_bounds: false\n  sparse_alpha: true\n  save_adv_example: true\n  precompile_jit: false\n  complete_verifier: bab\n  enable_incomplete_verification: true\n  csv_name: null\n  results_file: /tmp/tmpc88fb8h8.txt\n  root_path: ''\nmodel:\n  name: null\n  path: null\n  onnx_path: /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/cifar10_2_255_simplified.onnx\n  onnx_path_prefix: ''\n  cache_onnx_conversion: false\n  onnx_quirks: null\n  input_shape: null\n  onnx_loader: default_onnx_and_vnnlib_loader\n  onnx_optimization_flags: none\ndata:\n  start: 0\n  end: 10000\n  select_instance: null\n  num_outputs: 10\n  mean: 0.0\n  std: 1.0\n  pkl_path: null\n  dataset: CIFAR\n  data_filter_path: null\n  data_idx_file: null\nspecification:\n  type: lp\n  robustness_type: verified-acc\n  norm: .inf\n  epsilon: null\n  vnnlib_path: /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_0_eps_0.00784_n1.vnnlib\n  vnnlib_path_prefix: ''\nsolver:\n  batch_size: 512\n  min_batch_size_ratio: 0.1\n  use_float64_in_last_iteration: false\n  early_stop_patience: 10\n  start_save_best: 0.5\n  bound_prop_method: alpha-crown\n  prune_after_crown: false\n  crown:\n    batch_size: 1000000000\n    max_crown_size: 1000000000\n  alpha-crown:\n    alpha: true\n    lr_alpha: 0.1\n    iteration: 100\n    share_slopes: false\n    no_joint_opt: false\n    lr_decay: 0.98\n    full_conv_alpha: true\n  beta-crown:\n    lr_alpha: 0.01\n    lr_beta: 0.05\n    lr_decay: 0.98\n    optimizer: adam\n    iteration: 50\n    beta: true\n    beta_warmup: true\n    enable_opt_interm_bounds: false\n    all_node_split_LP: false\n  forward:\n    refine: false\n    dynamic: false\n    max_dim: 10000\n  multi_class:\n    multi_class_method: allclass_domain\n    label_batch_size: 32\n    skip_with_refined_bound: true\n  mip:\n    parallel_solvers: null\n    solver_threads: 1\n    refine_neuron_timeout: 15\n    refine_neuron_time_percentage: 0.8\n    early_stop: true\n    adv_warmup: true\n    mip_solver: gurobi\nbab:\n  initial_max_domains: 1\n  max_domains: .inf\n  decision_thresh: 0\n  timeout: 300.0\n  timeout_scale: 1\n  override_timeout: null\n  get_upper_bound: false\n  dfs_percent: 0.0\n  pruning_in_iteration: true\n  pruning_in_iteration_ratio: 0.2\n  sort_targets: false\n  batched_domain_list: true\n  optimized_intermediate_layers: ''\n  interm_transfer: true\n  cut:\n    enabled: false\n    bab_cut: false\n    lp_cut: false\n    method: null\n    lr: 0.01\n    lr_decay: 1.0\n    iteration: 100\n    bab_iteration: -1\n    early_stop_patience: -1\n    lr_beta: 0.02\n    number_cuts: 50\n    topk_cuts_in_filter: 100\n    batch_size_primal: 100\n    max_num: 1000000000\n    patches_cut: false\n    cplex_cuts: false\n    cplex_cuts_wait: 0\n    cplex_cuts_revpickup: true\n    cut_reference_bounds: true\n    fix_intermediate_bounds: false\n  branching:\n    method: kfsb\n    candidates: 3\n    reduceop: min\n    sb_coeff_thresh: 0.001\n    input_split:\n      enable: false\n      enhanced_bound_prop_method: alpha-crown\n      enhanced_branching_method: naive\n      enhanced_bound_patience: 100000000.0\n      attack_patience: 100000000.0\n      adv_check: 0\n      sort_domain_interval: -1\n  attack:\n    enabled: false\n    beam_candidates: 8\n    beam_depth: 7\n    max_dive_fix_ratio: 0.8\n    min_local_free_ratio: 0.2\n    mip_start_iteration: 5\n    mip_timeout: 30.0\n    adv_pool_threshold: null\n    refined_mip_attacker: false\n    refined_batch_size: null\nattack:\n  pgd_order: before\n  pgd_steps: 100\n  pgd_restarts: 30\n  pgd_early_stop: true\n  pgd_lr_decay: 0.99\n  pgd_alpha: auto\n  pgd_loss_mode: null\n  enable_mip_attack: false\n  cex_path: ./test_cex.txt\n  attack_mode: PGD\n  gama_lambda: 10.0\n  gama_decay: 0.9\n  check_clean: false\n  input_split:\n    pgd_steps: 100\n    pgd_restarts: 30\n    pgd_alpha: auto\n  input_split_enhanced:\n    pgd_steps: 200\n    pgd_restarts: 5000000\n    pgd_alpha: auto\n  input_split_check_adv:\n    pgd_steps: 5\n    pgd_restarts: 5\n    pgd_alpha: auto\ndebug:\n  lp_test: null\n\nExperiments at Mon May 13 21:07:34 2024 on Cerberus\nInternal results will be saved to /tmp/tmpc88fb8h8.txt.\n\n %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nUsing onnx /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/cifar10_2_255_simplified.onnx\nUsing vnnlib /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_0_eps_0.00784_n1.vnnlib\nPrecompiled vnnlib file found at /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_0_eps_0.00784_n1.vnnlib.compiled\nLoading onnx /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/cifar10_2_255_simplified.onnx wih quirks {}\n/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/onnx2pytorch/convert/layer.py:30: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_numpy.cpp:178.)\n  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))\n/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/onnx2pytorch/convert/model.py:154: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.\n  \"Using experimental implementation that allows 'batch_size > 1'.\"\nAttack parameters: initialization=uniform, steps=100, restarts=30, alpha=0.009833455085754395, initialization=uniform, GAMA=False\nModel output of first 5 examples:\n tensor([[-0.67527163, -1.52271450,  0.63711810,  4.41396284,  0.79158354,\n          3.94307709,  1.38516212, -1.23928893, -1.21486461, -1.90701199]],\n       device='cuda:0')\nAdv example prediction (first 2 examples and 2 restarts):\n tensor([[[-0.59891230, -1.67729628,  0.56920362,  4.30161333,  0.84799862,\n           4.37968922,  1.18421865, -1.15600204, -1.47534275, -1.94664717],\n         [-0.59891230, -1.67729628,  0.56920362,  4.30161333,  0.84799862,\n           4.37968922,  1.18421865, -1.15600204, -1.47534275, -1.94664717]]],\n       device='cuda:0')\nPGD attack margin (first 2 examles and 10 specs):\n tensor([[[ 4.90052557,  5.97890949,  3.73240972,  3.45361471, -0.07807589,\n           3.11739469,  5.45761538,  5.77695608,  6.24826050]]],\n       device='cuda:0')\nnumber of violation:  1\nAttack finished in 1.8182 seconds.\nPGD attack succeeded!\nResult: sat\nTime: 5.186419248580933\n"
        },
        {
            "network": "cifar10_2_255_simplified",
            "property": "cifar10_spec_idx_9_eps_0.00784_n1",
            "timeout": "300",
            "verifier": "abcrown",
            "config": "Configuration(values={\n  'attack__attack_mode': 'PGD',\n  'attack__enable_mip_attack': False,\n  'attack__pgd_order': 'before',\n  'bab__branching__input_split__enable': False,\n  'bab__branching__method': 'kfsb',\n  'bab__branching__reduceop': 'min',\n  'general__complete_verifier': 'bab',\n  'general__enable_incomplete_verification': True,\n  'general__loss_reduction_func': 'sum',\n  'solver__bound_prop_method': 'alpha-crown',\n})",
            "success": "OK",
            "result": "UNSAT",
            "took": "18.716369152069092",
            "stderr": "",
            "stdout": "/bin/bash: /home/tristan/miniconda3/envs/__av__abcrown/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nConfigurations:\n\ngeneral:\n  device: cuda\n  seed: 100\n  conv_mode: patches\n  deterministic: false\n  double_fp: false\n  loss_reduction_func: sum\n  record_bounds: false\n  sparse_alpha: true\n  save_adv_example: true\n  precompile_jit: false\n  complete_verifier: bab\n  enable_incomplete_verification: true\n  csv_name: null\n  results_file: /tmp/tmpdx96yicm.txt\n  root_path: ''\nmodel:\n  name: null\n  path: null\n  onnx_path: /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/cifar10_2_255_simplified.onnx\n  onnx_path_prefix: ''\n  cache_onnx_conversion: false\n  onnx_quirks: null\n  input_shape: null\n  onnx_loader: default_onnx_and_vnnlib_loader\n  onnx_optimization_flags: none\ndata:\n  start: 0\n  end: 10000\n  select_instance: null\n  num_outputs: 10\n  mean: 0.0\n  std: 1.0\n  pkl_path: null\n  dataset: CIFAR\n  data_filter_path: null\n  data_idx_file: null\nspecification:\n  type: lp\n  robustness_type: verified-acc\n  norm: .inf\n  epsilon: null\n  vnnlib_path: /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_9_eps_0.00784_n1.vnnlib\n  vnnlib_path_prefix: ''\nsolver:\n  batch_size: 512\n  min_batch_size_ratio: 0.1\n  use_float64_in_last_iteration: false\n  early_stop_patience: 10\n  start_save_best: 0.5\n  bound_prop_method: alpha-crown\n  prune_after_crown: false\n  crown:\n    batch_size: 1000000000\n    max_crown_size: 1000000000\n  alpha-crown:\n    alpha: true\n    lr_alpha: 0.1\n    iteration: 100\n    share_slopes: false\n    no_joint_opt: false\n    lr_decay: 0.98\n    full_conv_alpha: true\n  beta-crown:\n    lr_alpha: 0.01\n    lr_beta: 0.05\n    lr_decay: 0.98\n    optimizer: adam\n    iteration: 50\n    beta: true\n    beta_warmup: true\n    enable_opt_interm_bounds: false\n    all_node_split_LP: false\n  forward:\n    refine: false\n    dynamic: false\n    max_dim: 10000\n  multi_class:\n    multi_class_method: allclass_domain\n    label_batch_size: 32\n    skip_with_refined_bound: true\n  mip:\n    parallel_solvers: null\n    solver_threads: 1\n    refine_neuron_timeout: 15\n    refine_neuron_time_percentage: 0.8\n    early_stop: true\n    adv_warmup: true\n    mip_solver: gurobi\nbab:\n  initial_max_domains: 1\n  max_domains: .inf\n  decision_thresh: 0\n  timeout: 300.0\n  timeout_scale: 1\n  override_timeout: null\n  get_upper_bound: false\n  dfs_percent: 0.0\n  pruning_in_iteration: true\n  pruning_in_iteration_ratio: 0.2\n  sort_targets: false\n  batched_domain_list: true\n  optimized_intermediate_layers: ''\n  interm_transfer: true\n  cut:\n    enabled: false\n    bab_cut: false\n    lp_cut: false\n    method: null\n    lr: 0.01\n    lr_decay: 1.0\n    iteration: 100\n    bab_iteration: -1\n    early_stop_patience: -1\n    lr_beta: 0.02\n    number_cuts: 50\n    topk_cuts_in_filter: 100\n    batch_size_primal: 100\n    max_num: 1000000000\n    patches_cut: false\n    cplex_cuts: false\n    cplex_cuts_wait: 0\n    cplex_cuts_revpickup: true\n    cut_reference_bounds: true\n    fix_intermediate_bounds: false\n  branching:\n    method: kfsb\n    candidates: 3\n    reduceop: min\n    sb_coeff_thresh: 0.001\n    input_split:\n      enable: false\n      enhanced_bound_prop_method: alpha-crown\n      enhanced_branching_method: naive\n      enhanced_bound_patience: 100000000.0\n      attack_patience: 100000000.0\n      adv_check: 0\n      sort_domain_interval: -1\n  attack:\n    enabled: false\n    beam_candidates: 8\n    beam_depth: 7\n    max_dive_fix_ratio: 0.8\n    min_local_free_ratio: 0.2\n    mip_start_iteration: 5\n    mip_timeout: 30.0\n    adv_pool_threshold: null\n    refined_mip_attacker: false\n    refined_batch_size: null\nattack:\n  pgd_order: before\n  pgd_steps: 100\n  pgd_restarts: 30\n  pgd_early_stop: true\n  pgd_lr_decay: 0.99\n  pgd_alpha: auto\n  pgd_loss_mode: null\n  enable_mip_attack: false\n  cex_path: ./test_cex.txt\n  attack_mode: PGD\n  gama_lambda: 10.0\n  gama_decay: 0.9\n  check_clean: false\n  input_split:\n    pgd_steps: 100\n    pgd_restarts: 30\n    pgd_alpha: auto\n  input_split_enhanced:\n    pgd_steps: 200\n    pgd_restarts: 5000000\n    pgd_alpha: auto\n  input_split_check_adv:\n    pgd_steps: 5\n    pgd_restarts: 5\n    pgd_alpha: auto\ndebug:\n  lp_test: null\n\nExperiments at Mon May 13 21:07:42 2024 on Cerberus\nInternal results will be saved to /tmp/tmpdx96yicm.txt.\n\n %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nUsing onnx /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/cifar10_2_255_simplified.onnx\nUsing vnnlib /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_9_eps_0.00784_n1.vnnlib\nPrecompiled vnnlib file found at /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_9_eps_0.00784_n1.vnnlib.compiled\nLoading onnx /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/cifar10_2_255_simplified.onnx wih quirks {}\n/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/onnx2pytorch/convert/layer.py:30: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_numpy.cpp:178.)\n  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))\n/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/onnx2pytorch/convert/model.py:154: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.\n  \"Using experimental implementation that allows 'batch_size > 1'.\"\nAttack parameters: initialization=uniform, steps=100, restarts=30, alpha=0.0098334401845932, initialization=uniform, GAMA=False\nModel output of first 5 examples:\n tensor([[ 1.33182096,  8.01652718, -0.83784550,  0.33827630, -1.59518743,\n         -0.11049002,  0.60660005, -2.18435478,  2.48944187,  5.76314831]],\n       device='cuda:0')\nAdv example prediction (first 2 examples and 2 restarts):\n tensor([[[ 1.38077497,  7.11155891, -0.81550092,  0.36877590, -1.63488841,\n          -0.19252896,  0.41075173, -2.10415339,  2.38559103,  6.26932716],\n         [ 1.38077497,  7.11155891, -0.81550092,  0.36877590, -1.63488841,\n          -0.19252896,  0.41075173, -2.10415339,  2.38559103,  6.26932716]]],\n       device='cuda:0')\nPGD attack margin (first 2 examles and 10 specs):\n tensor([[[5.73078394, 7.92705965, 6.74278307, 8.74644756, 7.30408764,\n          6.70080709, 9.21571255, 4.72596788, 0.84223175]]], device='cuda:0')\nnumber of violation:  0\nAttack finished in 1.8055 seconds.\nPGD attack failed\nModel prediction is: tensor([[ 1.33182096,  8.01652718, -0.83784550,  0.33827630, -1.59518743,\n         -0.11049002,  0.60660005, -2.18435478,  2.48944187,  5.76314831]],\n       device='cuda:0')\nlayer /22 using sparse-features alpha with shape [1386]; unstable size 1386; total size 32768 (torch.Size([1, 32, 32, 32]))\nlayer /22 start_node /input.4 using full alpha with unstable size 32 total_size 32 output_shape 32\nlayer /22 start_node /input.8 using sparse-spec alpha with unstable size 115 total_size 128 output_shape 128\nlayer /22 start_node /input.12 using sparse-spec alpha with unstable size 54 total_size 250 output_shape torch.Size([250])\nlayer /22 start_node /30 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /24 using sparse-features alpha with shape [725]; unstable size 725; total size 8192 (torch.Size([1, 32, 16, 16]))\nlayer /24 start_node /input.8 using sparse-spec alpha with unstable size 115 total_size 128 output_shape 128\nlayer /24 start_node /input.12 using sparse-spec alpha with unstable size 54 total_size 250 output_shape torch.Size([250])\nlayer /24 start_node /30 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /26 using sparse-features alpha with shape [675]; unstable size 675; total size 8192 (torch.Size([1, 128, 8, 8]))\nlayer /26 start_node /input.12 using sparse-spec alpha with unstable size 54 total_size 250 output_shape torch.Size([250])\nlayer /26 start_node /30 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /29 using sparse-features alpha with shape [54]; unstable size 54; total size 250 (torch.Size([1, 250]))\nlayer /29 start_node /30 using full alpha with unstable size None total_size 9 output_shape 9\nOptimizable variables initialized.\ninitial CROWN bounds: tensor([[ 2.91427612,  4.55403137,  4.00052261,  5.54376316,  4.45263481,\n          3.79798222,  5.70426178,  1.83534622, -0.87034941]], device='cuda:0') None\nbest_l after optimization: 35.21476745605469 with beta sum per layer: []\nalpha/beta optimization time: 8.624515771865845\ninitial alpha-CROWN bounds: tensor([[ 3.25364780,  4.91605091,  4.39051723,  5.89016724,  4.82440948,\n          4.12996674,  6.11451960,  2.23822784, -0.54273653]], device='cuda:0')\nWorst class: (+ rhs) -0.5427365303039551\nTotal VNNLIB file length: 9, max property batch size: 1, total number of batches: 9\nlA shape: [torch.Size([1, 9, 32, 32, 32]), torch.Size([1, 9, 32, 16, 16]), torch.Size([1, 9, 128, 8, 8]), torch.Size([1, 9, 250])]\n\nProperties batch 0, size 1\nRemaining timeout: 285.67234802246094\n##### Instance 0 first 10 spec matrices: [[[-1.  1.  0.  0.  0.  0.  0.  0.  0.  0.]]]\nthresholds: [0.] ######\nInitial alpha-CROWN verified for spec index [0] with bound 3.253647804260254.\n\nProperties batch 1, size 1\nRemaining timeout: 285.5715374946594\n##### Instance 0 first 10 spec matrices: [[[ 0.  1. -1.  0.  0.  0.  0.  0.  0.  0.]]]\nthresholds: [0.] ######\nInitial alpha-CROWN verified for spec index [0] with bound 4.916050910949707.\n\nProperties batch 2, size 1\nRemaining timeout: 285.50387620925903\n##### Instance 0 first 10 spec matrices: [[[ 0.  1.  0. -1.  0.  0.  0.  0.  0.  0.]]]\nthresholds: [0.] ######\nInitial alpha-CROWN verified for spec index [0] with bound 4.390517234802246.\n\nProperties batch 3, size 1\nRemaining timeout: 285.4207856655121\n##### Instance 0 first 10 spec matrices: [[[ 0.  1.  0.  0. -1.  0.  0.  0.  0.  0.]]]\nthresholds: [0.] ######\nInitial alpha-CROWN verified for spec index [0] with bound 5.890167236328125.\n\nProperties batch 4, size 1\nRemaining timeout: 285.337034702301\n##### Instance 0 first 10 spec matrices: [[[ 0.  1.  0.  0.  0. -1.  0.  0.  0.  0.]]]\nthresholds: [0.] ######\nInitial alpha-CROWN verified for spec index [0] with bound 4.824409484863281.\n\nProperties batch 5, size 1\nRemaining timeout: 285.26393461227417\n##### Instance 0 first 10 spec matrices: [[[ 0.  1.  0.  0.  0.  0. -1.  0.  0.  0.]]]\nthresholds: [0.] ######\nInitial alpha-CROWN verified for spec index [0] with bound 4.129966735839844.\n\nProperties batch 6, size 1\nRemaining timeout: 285.2127261161804\n##### Instance 0 first 10 spec matrices: [[[ 0.  1.  0.  0.  0.  0.  0. -1.  0.  0.]]]\nthresholds: [0.] ######\nInitial alpha-CROWN verified for spec index [0] with bound 6.1145195960998535.\n\nProperties batch 7, size 1\nRemaining timeout: 285.164128780365\n##### Instance 0 first 10 spec matrices: [[[ 0.  1.  0.  0.  0.  0.  0.  0. -1.  0.]]]\nthresholds: [0.] ######\nInitial alpha-CROWN verified for spec index [0] with bound 2.2382278442382812.\n\nProperties batch 8, size 1\nRemaining timeout: 285.1160328388214\n##### Instance 0 first 10 spec matrices: [[[ 0.  1.  0.  0.  0.  0.  0.  0.  0. -1.]]]\nthresholds: [0.] ######\nRemaining spec index [0] with bounds tensor([[-0.54273653]], device='cuda:0') need to verify.\nModel prediction is: tensor([ 1.33182096,  8.01652718, -0.83784550,  0.33827630, -1.59518743,\n        -0.11049002,  0.60660005, -2.18435478,  2.48944187,  5.76314831],\n       device='cuda:0')\nbuild_the_model_with_refined_bounds batch [0/1]\nsetting alpha for layer /22 start_node /30 with alignment adjustment\nsetting alpha for layer /24 start_node /30 with alignment adjustment\nsetting alpha for layer /26 start_node /30 with alignment adjustment\nsetting alpha for layer /29 start_node /30 with alignment adjustment\nall slope initialized\ndirectly get lb and ub from refined bounds\nlA shapes: [torch.Size([1, 1, 32, 32, 32]), torch.Size([1, 1, 32, 16, 16]), torch.Size([1, 1, 128, 8, 8]), torch.Size([1, 1, 250])]\nc shape: torch.Size([1, 1, 10])\nalpha-CROWN with fixed intermediate bounds: tensor([[-0.54273653]], device='cuda:0') tensor([[inf]], device='cuda:0')\nKeeping slopes for these layers: ['/30']\nKeeping slopes for these layers: ['/30']\nlayer 0 size torch.Size([32768]) unstable 1386\nlayer 1 size torch.Size([8192]) unstable 713\nlayer 2 size torch.Size([8192]) unstable 658\nlayer 3 size torch.Size([250]) unstable 51\n-----------------\n# of unstable neurons: 2808\n-----------------\n\nbatch:  torch.Size([1, 32, 32, 32]) pre split depth:  5\nbatch:  torch.Size([1, 32, 32, 32]) post split depth:  5\nsplitting decisions: \nsplit level 0: [3, 56] \nsplit level 1: [3, 27] \nsplit level 2: [3, 169] \nsplit level 3: [3, 203] \nsplit level 4: [3, 43] \n(32, 3, 32, 32) torch.Size([32, 1, 10]) torch.Size([32, 1])\npruning_in_iteration open status: True\nratio of positive domain = 30 / 32 = 0.9375\npruning-in-iteration extra time: 0.03930950164794922\nTensors transferred: pre=3.0153M lA=0.0942M alpha=0.1733M beta=0.0002M\nThis batch time : update_bounds func: 1.0467\t prepare: 0.0059\t bound: 1.0324\t transfer: 0.0077\t finalize: 0.0006\nAccumulated time: update_bounds func: 1.0467\t prepare: 0.0059\t bound: 1.0324\t transfer: 0.0077\t finalize: 0.0006\nbatch bounding time:  1.0468266010284424\nCurrent worst splitting domains lb-rhs (depth):\n-0.04987 (5), -0.02502 (5), \nlength of domains: 2\nTotal time: 1.5951\t pickout: 0.0023\t decision: 0.5266\t get_bound: 1.0595\t add_domain: 0.0067\nAccumulated time:\t pickout: 0.0023\t decision: 0.5266\t get_bound: 1.0595\t add_domain: 0.0067\nCurrent (lb-rhs): -0.049870967864990234\n30 domains visited\nCumulative time: 1.940687894821167\n\nbatch:  torch.Size([2, 32, 32, 32]) pre split depth:  4\nbatch:  torch.Size([2, 32, 32, 32]) post split depth:  4\nsplitting decisions: \nsplit level 0: [3, 40] [3, 40] \nsplit level 1: [3, 112] [3, 112] \nsplit level 2: [3, 207] [3, 207] \nsplit level 3: [3, 116] [3, 116] \n(32, 3, 32, 32) torch.Size([32, 1, 10]) torch.Size([32, 1])\n\nall verified at 0th iter\npruning_in_iteration open status: False\nratio of positive domain = 32 / 32 = 1.0\npruning-in-iteration extra time: 0.00020766258239746094\nTensors transferred: pre=3.0153M lA=1.5076M alpha=0.1733M beta=0.0003M\nThis batch time : update_bounds func: 0.0193\t prepare: 0.0033\t bound: 0.0088\t transfer: 0.0063\t finalize: 0.0008\nAccumulated time: update_bounds func: 1.0661\t prepare: 0.0093\t bound: 1.0412\t transfer: 0.0140\t finalize: 0.0014\nbatch bounding time:  0.019411802291870117\nlength of domains: 0\nTotal time: 0.0593\t pickout: 0.0011\t decision: 0.0323\t get_bound: 0.0249\t add_domain: 0.0011\nAccumulated time:\t pickout: 0.0033\t decision: 0.5590\t get_bound: 1.0844\t add_domain: 0.0077\nNo domains left, verification finished!\n62 domains visited\n/home/tristan/.local/share/autoverify/verifiers/abcrown/tool/complete_verifier/batch_branch_and_bound.py:321: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  return torch.tensor(arguments.Config[\"bab\"][\"decision_thresh\"] + 1e-7), np.inf\nCumulative time: 2.001222610473633\n\nResult: unsat\nTime: 17.088505744934082\n"
        },
        {
            "network": "cifar10_2_255_simplified",
            "property": "cifar10_spec_idx_17_eps_0.00784_n1",
            "timeout": "300",
            "verifier": "abcrown",
            "config": "Configuration(values={\n  'attack__attack_mode': 'PGD',\n  'attack__enable_mip_attack': False,\n  'attack__pgd_order': 'before',\n  'bab__branching__input_split__enable': False,\n  'bab__branching__method': 'kfsb',\n  'bab__branching__reduceop': 'min',\n  'general__complete_verifier': 'bab',\n  'general__enable_incomplete_verification': True,\n  'general__loss_reduction_func': 'sum',\n  'solver__bound_prop_method': 'alpha-crown',\n})",
            "success": "OK",
            "result": "UNSAT",
            "took": "8.122518539428711",
            "stderr": "",
            "stdout": "/bin/bash: /home/tristan/miniconda3/envs/__av__abcrown/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nConfigurations:\n\ngeneral:\n  device: cuda\n  seed: 100\n  conv_mode: patches\n  deterministic: false\n  double_fp: false\n  loss_reduction_func: sum\n  record_bounds: false\n  sparse_alpha: true\n  save_adv_example: true\n  precompile_jit: false\n  complete_verifier: bab\n  enable_incomplete_verification: true\n  csv_name: null\n  results_file: /tmp/tmpzgafob7b.txt\n  root_path: ''\nmodel:\n  name: null\n  path: null\n  onnx_path: /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/cifar10_2_255_simplified.onnx\n  onnx_path_prefix: ''\n  cache_onnx_conversion: false\n  onnx_quirks: null\n  input_shape: null\n  onnx_loader: default_onnx_and_vnnlib_loader\n  onnx_optimization_flags: none\ndata:\n  start: 0\n  end: 10000\n  select_instance: null\n  num_outputs: 10\n  mean: 0.0\n  std: 1.0\n  pkl_path: null\n  dataset: CIFAR\n  data_filter_path: null\n  data_idx_file: null\nspecification:\n  type: lp\n  robustness_type: verified-acc\n  norm: .inf\n  epsilon: null\n  vnnlib_path: /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_17_eps_0.00784_n1.vnnlib\n  vnnlib_path_prefix: ''\nsolver:\n  batch_size: 512\n  min_batch_size_ratio: 0.1\n  use_float64_in_last_iteration: false\n  early_stop_patience: 10\n  start_save_best: 0.5\n  bound_prop_method: alpha-crown\n  prune_after_crown: false\n  crown:\n    batch_size: 1000000000\n    max_crown_size: 1000000000\n  alpha-crown:\n    alpha: true\n    lr_alpha: 0.1\n    iteration: 100\n    share_slopes: false\n    no_joint_opt: false\n    lr_decay: 0.98\n    full_conv_alpha: true\n  beta-crown:\n    lr_alpha: 0.01\n    lr_beta: 0.05\n    lr_decay: 0.98\n    optimizer: adam\n    iteration: 50\n    beta: true\n    beta_warmup: true\n    enable_opt_interm_bounds: false\n    all_node_split_LP: false\n  forward:\n    refine: false\n    dynamic: false\n    max_dim: 10000\n  multi_class:\n    multi_class_method: allclass_domain\n    label_batch_size: 32\n    skip_with_refined_bound: true\n  mip:\n    parallel_solvers: null\n    solver_threads: 1\n    refine_neuron_timeout: 15\n    refine_neuron_time_percentage: 0.8\n    early_stop: true\n    adv_warmup: true\n    mip_solver: gurobi\nbab:\n  initial_max_domains: 1\n  max_domains: .inf\n  decision_thresh: 0\n  timeout: 300.0\n  timeout_scale: 1\n  override_timeout: null\n  get_upper_bound: false\n  dfs_percent: 0.0\n  pruning_in_iteration: true\n  pruning_in_iteration_ratio: 0.2\n  sort_targets: false\n  batched_domain_list: true\n  optimized_intermediate_layers: ''\n  interm_transfer: true\n  cut:\n    enabled: false\n    bab_cut: false\n    lp_cut: false\n    method: null\n    lr: 0.01\n    lr_decay: 1.0\n    iteration: 100\n    bab_iteration: -1\n    early_stop_patience: -1\n    lr_beta: 0.02\n    number_cuts: 50\n    topk_cuts_in_filter: 100\n    batch_size_primal: 100\n    max_num: 1000000000\n    patches_cut: false\n    cplex_cuts: false\n    cplex_cuts_wait: 0\n    cplex_cuts_revpickup: true\n    cut_reference_bounds: true\n    fix_intermediate_bounds: false\n  branching:\n    method: kfsb\n    candidates: 3\n    reduceop: min\n    sb_coeff_thresh: 0.001\n    input_split:\n      enable: false\n      enhanced_bound_prop_method: alpha-crown\n      enhanced_branching_method: naive\n      enhanced_bound_patience: 100000000.0\n      attack_patience: 100000000.0\n      adv_check: 0\n      sort_domain_interval: -1\n  attack:\n    enabled: false\n    beam_candidates: 8\n    beam_depth: 7\n    max_dive_fix_ratio: 0.8\n    min_local_free_ratio: 0.2\n    mip_start_iteration: 5\n    mip_timeout: 30.0\n    adv_pool_threshold: null\n    refined_mip_attacker: false\n    refined_batch_size: null\nattack:\n  pgd_order: before\n  pgd_steps: 100\n  pgd_restarts: 30\n  pgd_early_stop: true\n  pgd_lr_decay: 0.99\n  pgd_alpha: auto\n  pgd_loss_mode: null\n  enable_mip_attack: false\n  cex_path: ./test_cex.txt\n  attack_mode: PGD\n  gama_lambda: 10.0\n  gama_decay: 0.9\n  check_clean: false\n  input_split:\n    pgd_steps: 100\n    pgd_restarts: 30\n    pgd_alpha: auto\n  input_split_enhanced:\n    pgd_steps: 200\n    pgd_restarts: 5000000\n    pgd_alpha: auto\n  input_split_check_adv:\n    pgd_steps: 5\n    pgd_restarts: 5\n    pgd_alpha: auto\ndebug:\n  lp_test: null\n\nExperiments at Mon May 13 21:08:03 2024 on Cerberus\nInternal results will be saved to /tmp/tmpzgafob7b.txt.\n\n %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nUsing onnx /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/cifar10_2_255_simplified.onnx\nUsing vnnlib /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_17_eps_0.00784_n1.vnnlib\nPrecompiled vnnlib file found at /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_17_eps_0.00784_n1.vnnlib.compiled\nLoading onnx /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/cifar10_2_255_simplified.onnx wih quirks {}\n/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/onnx2pytorch/convert/layer.py:30: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_numpy.cpp:178.)\n  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))\n/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/onnx2pytorch/convert/model.py:154: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.\n  \"Using experimental implementation that allows 'batch_size > 1'.\"\nAttack parameters: initialization=uniform, steps=100, restarts=30, alpha=0.0098334401845932, initialization=uniform, GAMA=False\nModel output of first 5 examples:\n tensor([[-0.71794301, -2.73549056,  0.46490240,  2.03653789,  2.18022227,\n          1.30874860, -0.23802117,  5.58075476, -1.34880483, -1.73270965]],\n       device='cuda:0')\nAdv example prediction (first 2 examples and 2 restarts):\n tensor([[[-0.48575890, -2.88859630,  0.55571985,  2.02314472,  2.39839435,\n           1.23517108, -0.19022425,  4.85715294, -1.25886095, -1.80295110],\n         [-0.48575890, -2.88859630,  0.55571985,  2.02314472,  2.39839435,\n           1.23517108, -0.19022425,  4.85715294, -1.25886095, -1.80295110]]],\n       device='cuda:0')\nPGD attack margin (first 2 examles and 10 specs):\n tensor([[[5.34291172, 7.74574947, 4.30143309, 2.83400822, 2.45875859,\n          3.62198186, 5.04737711, 6.11601400, 6.66010380]]], device='cuda:0')\nnumber of violation:  0\nAttack finished in 1.8622 seconds.\nPGD attack failed\nModel prediction is: tensor([[-0.71794301, -2.73549056,  0.46490240,  2.03653789,  2.18022227,\n          1.30874860, -0.23802117,  5.58075476, -1.34880483, -1.73270965]],\n       device='cuda:0')\nlayer /22 using sparse-features alpha with shape [1626]; unstable size 1626; total size 32768 (torch.Size([1, 32, 32, 32]))\nlayer /22 start_node /input.4 using full alpha with unstable size 32 total_size 32 output_shape 32\nlayer /22 start_node /input.8 using full alpha with unstable size 119 total_size 128 output_shape 128\nlayer /22 start_node /input.12 using sparse-spec alpha with unstable size 67 total_size 250 output_shape torch.Size([250])\nlayer /22 start_node /30 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /24 using sparse-features alpha with shape [939]; unstable size 939; total size 8192 (torch.Size([1, 32, 16, 16]))\nlayer /24 start_node /input.8 using full alpha with unstable size 119 total_size 128 output_shape 128\nlayer /24 start_node /input.12 using sparse-spec alpha with unstable size 67 total_size 250 output_shape torch.Size([250])\nlayer /24 start_node /30 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /26 using sparse-features alpha with shape [715]; unstable size 715; total size 8192 (torch.Size([1, 128, 8, 8]))\nlayer /26 start_node /input.12 using sparse-spec alpha with unstable size 67 total_size 250 output_shape torch.Size([250])\nlayer /26 start_node /30 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /29 using sparse-features alpha with shape [67]; unstable size 67; total size 250 (torch.Size([1, 250]))\nlayer /29 start_node /30 using full alpha with unstable size None total_size 9 output_shape 9\nOptimizable variables initialized.\ninitial CROWN bounds: tensor([[2.33360052, 3.98111725, 2.04257298, 1.23024106, 1.41948509, 1.87243617,\n         3.18333101, 3.42235327, 2.19060993]], device='cuda:0') None\nverified with init bound!\nResult: unsat\nTime: 6.332714080810547\n"
        },
        {
            "network": "cifar10_2_255_simplified",
            "property": "cifar10_spec_idx_27_eps_0.00784_n1",
            "timeout": "300",
            "verifier": "abcrown",
            "config": "Configuration(values={\n  'attack__attack_mode': 'PGD',\n  'attack__enable_mip_attack': False,\n  'attack__pgd_order': 'before',\n  'bab__branching__input_split__enable': False,\n  'bab__branching__method': 'kfsb',\n  'bab__branching__reduceop': 'min',\n  'general__complete_verifier': 'bab',\n  'general__enable_incomplete_verification': True,\n  'general__loss_reduction_func': 'sum',\n  'solver__bound_prop_method': 'alpha-crown',\n})",
            "success": "OK",
            "result": "TIMEOUT",
            "took": "300",
            "stderr": "",
            "stdout": "/bin/bash: /home/tristan/miniconda3/envs/__av__abcrown/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nConfigurations:\n\ngeneral:\n  device: cuda\n  seed: 100\n  conv_mode: patches\n  deterministic: false\n  double_fp: false\n  loss_reduction_func: sum\n  record_bounds: false\n  sparse_alpha: true\n  save_adv_example: true\n  precompile_jit: false\n  complete_verifier: bab\n  enable_incomplete_verification: true\n  csv_name: null\n  results_file: /tmp/tmp58kisiyq.txt\n  root_path: ''\nmodel:\n  name: null\n  path: null\n  onnx_path: /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/cifar10_2_255_simplified.onnx\n  onnx_path_prefix: ''\n  cache_onnx_conversion: false\n  onnx_quirks: null\n  input_shape: null\n  onnx_loader: default_onnx_and_vnnlib_loader\n  onnx_optimization_flags: none\ndata:\n  start: 0\n  end: 10000\n  select_instance: null\n  num_outputs: 10\n  mean: 0.0\n  std: 1.0\n  pkl_path: null\n  dataset: CIFAR\n  data_filter_path: null\n  data_idx_file: null\nspecification:\n  type: lp\n  robustness_type: verified-acc\n  norm: .inf\n  epsilon: null\n  vnnlib_path: /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_27_eps_0.00784_n1.vnnlib\n  vnnlib_path_prefix: ''\nsolver:\n  batch_size: 512\n  min_batch_size_ratio: 0.1\n  use_float64_in_last_iteration: false\n  early_stop_patience: 10\n  start_save_best: 0.5\n  bound_prop_method: alpha-crown\n  prune_after_crown: false\n  crown:\n    batch_size: 1000000000\n    max_crown_size: 1000000000\n  alpha-crown:\n    alpha: true\n    lr_alpha: 0.1\n    iteration: 100\n    share_slopes: false\n    no_joint_opt: false\n    lr_decay: 0.98\n    full_conv_alpha: true\n  beta-crown:\n    lr_alpha: 0.01\n    lr_beta: 0.05\n    lr_decay: 0.98\n    optimizer: adam\n    iteration: 50\n    beta: true\n    beta_warmup: true\n    enable_opt_interm_bounds: false\n    all_node_split_LP: false\n  forward:\n    refine: false\n    dynamic: false\n    max_dim: 10000\n  multi_class:\n    multi_class_method: allclass_domain\n    label_batch_size: 32\n    skip_with_refined_bound: true\n  mip:\n    parallel_solvers: null\n    solver_threads: 1\n    refine_neuron_timeout: 15\n    refine_neuron_time_percentage: 0.8\n    early_stop: true\n    adv_warmup: true\n    mip_solver: gurobi\nbab:\n  initial_max_domains: 1\n  max_domains: .inf\n  decision_thresh: 0\n  timeout: 300.0\n  timeout_scale: 1\n  override_timeout: null\n  get_upper_bound: false\n  dfs_percent: 0.0\n  pruning_in_iteration: true\n  pruning_in_iteration_ratio: 0.2\n  sort_targets: false\n  batched_domain_list: true\n  optimized_intermediate_layers: ''\n  interm_transfer: true\n  cut:\n    enabled: false\n    bab_cut: false\n    lp_cut: false\n    method: null\n    lr: 0.01\n    lr_decay: 1.0\n    iteration: 100\n    bab_iteration: -1\n    early_stop_patience: -1\n    lr_beta: 0.02\n    number_cuts: 50\n    topk_cuts_in_filter: 100\n    batch_size_primal: 100\n    max_num: 1000000000\n    patches_cut: false\n    cplex_cuts: false\n    cplex_cuts_wait: 0\n    cplex_cuts_revpickup: true\n    cut_reference_bounds: true\n    fix_intermediate_bounds: false\n  branching:\n    method: kfsb\n    candidates: 3\n    reduceop: min\n    sb_coeff_thresh: 0.001\n    input_split:\n      enable: false\n      enhanced_bound_prop_method: alpha-crown\n      enhanced_branching_method: naive\n      enhanced_bound_patience: 100000000.0\n      attack_patience: 100000000.0\n      adv_check: 0\n      sort_domain_interval: -1\n  attack:\n    enabled: false\n    beam_candidates: 8\n    beam_depth: 7\n    max_dive_fix_ratio: 0.8\n    min_local_free_ratio: 0.2\n    mip_start_iteration: 5\n    mip_timeout: 30.0\n    adv_pool_threshold: null\n    refined_mip_attacker: false\n    refined_batch_size: null\nattack:\n  pgd_order: before\n  pgd_steps: 100\n  pgd_restarts: 30\n  pgd_early_stop: true\n  pgd_lr_decay: 0.99\n  pgd_alpha: auto\n  pgd_loss_mode: null\n  enable_mip_attack: false\n  cex_path: ./test_cex.txt\n  attack_mode: PGD\n  gama_lambda: 10.0\n  gama_decay: 0.9\n  check_clean: false\n  input_split:\n    pgd_steps: 100\n    pgd_restarts: 30\n    pgd_alpha: auto\n  input_split_enhanced:\n    pgd_steps: 200\n    pgd_restarts: 5000000\n    pgd_alpha: auto\n  input_split_check_adv:\n    pgd_steps: 5\n    pgd_restarts: 5\n    pgd_alpha: auto\ndebug:\n  lp_test: null\n\nExperiments at Mon May 13 21:08:12 2024 on Cerberus\nInternal results will be saved to /tmp/tmp58kisiyq.txt.\n\n %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nUsing onnx /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/cifar10_2_255_simplified.onnx\nUsing vnnlib /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_27_eps_0.00784_n1.vnnlib\nPrecompiled vnnlib file found at /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_27_eps_0.00784_n1.vnnlib.compiled\nLoading onnx /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/cifar10_2_255_simplified.onnx wih quirks {}\n/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/onnx2pytorch/convert/layer.py:30: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_numpy.cpp:178.)\n  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))\n/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/onnx2pytorch/convert/model.py:154: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.\n  \"Using experimental implementation that allows 'batch_size > 1'.\"\nAttack parameters: initialization=uniform, steps=100, restarts=30, alpha=0.009833455085754395, initialization=uniform, GAMA=False\nModel output of first 5 examples:\n tensor([[ 3.42392373, -4.39966679,  1.84774685,  0.68908328,  2.66574335,\n          0.62991524, -0.17185465,  1.23229563, -3.23374295, -0.60079861]],\n       device='cuda:0')\nAdv example prediction (first 2 examples and 2 restarts):\n tensor([[[ 2.89373541, -4.66593504,  1.82701683,  0.85894787,  2.86403251,\n           0.92236614, -0.28302976,  1.52670109, -3.56230187, -0.78883207],\n         [ 2.89373541, -4.66593504,  1.82701683,  0.85894787,  2.86403251,\n           0.92236614, -0.28302976,  1.52670109, -3.56230187, -0.78883207]]],\n       device='cuda:0')\nPGD attack margin (first 2 examles and 10 specs):\n tensor([[[7.55967045, 1.06671858, 2.03478765, 0.02970290, 1.97136927,\n          3.17676520, 1.36703432, 6.45603752, 3.68256760]]], device='cuda:0')\nnumber of violation:  0\nAttack finished in 1.9146 seconds.\nPGD attack failed\nModel prediction is: tensor([[ 3.42392373, -4.39966679,  1.84774685,  0.68908328,  2.66574335,\n          0.62991524, -0.17185465,  1.23229563, -3.23374295, -0.60079861]],\n       device='cuda:0')\nlayer /22 using sparse-features alpha with shape [1437]; unstable size 1437; total size 32768 (torch.Size([1, 32, 32, 32]))\nlayer /22 start_node /input.4 using full alpha with unstable size 32 total_size 32 output_shape 32\nlayer /22 start_node /input.8 using sparse-spec alpha with unstable size 115 total_size 128 output_shape 128\nlayer /22 start_node /input.12 using sparse-spec alpha with unstable size 54 total_size 250 output_shape torch.Size([250])\nlayer /22 start_node /30 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /24 using sparse-features alpha with shape [675]; unstable size 675; total size 8192 (torch.Size([1, 32, 16, 16]))\nlayer /24 start_node /input.8 using sparse-spec alpha with unstable size 115 total_size 128 output_shape 128\nlayer /24 start_node /input.12 using sparse-spec alpha with unstable size 54 total_size 250 output_shape torch.Size([250])\nlayer /24 start_node /30 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /26 using sparse-features alpha with shape [555]; unstable size 555; total size 8192 (torch.Size([1, 128, 8, 8]))\nlayer /26 start_node /input.12 using sparse-spec alpha with unstable size 54 total_size 250 output_shape torch.Size([250])\nlayer /26 start_node /30 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /29 using sparse-features alpha with shape [54]; unstable size 54; total size 250 (torch.Size([1, 250]))\nlayer /29 start_node /30 using full alpha with unstable size None total_size 9 output_shape 9\nOptimizable variables initialized.\ninitial CROWN bounds: tensor([[ 5.91306973, -0.15005445,  0.85581970, -0.97931981,  0.71283937,\n          1.95830727, -0.64448309,  4.80564117,  1.95628119]], device='cuda:0') None\nbest_l after optimization: 15.584522247314453 with beta sum per layer: []\nalpha/beta optimization time: 7.295480012893677\ninitial alpha-CROWN bounds: tensor([[ 6.05828190, -0.03196740,  0.96516776, -0.86231709,  0.83091283,\n          2.05264521, -0.49636126,  4.94511318,  2.12304711]], device='cuda:0')\nWorst class: (+ rhs) -0.8623170852661133\nTotal VNNLIB file length: 9, max property batch size: 1, total number of batches: 9\nlA shape: [torch.Size([1, 9, 32, 32, 32]), torch.Size([1, 9, 32, 16, 16]), torch.Size([1, 9, 128, 8, 8]), torch.Size([1, 9, 250])]\n\nProperties batch 0, size 1\nRemaining timeout: 286.2299931049347\n##### Instance 0 first 10 spec matrices: [[[ 1. -1.  0.  0.  0.  0.  0.  0.  0.  0.]]]\nthresholds: [0.] ######\nInitial alpha-CROWN verified for spec index [0] with bound 6.058281898498535.\n\nProperties batch 1, size 1\nRemaining timeout: 286.1175014972687\n##### Instance 0 first 10 spec matrices: [[[ 1.  0. -1.  0.  0.  0.  0.  0.  0.  0.]]]\nthresholds: [0.] ######\nRemaining spec index [0] with bounds tensor([[-0.03196740]], device='cuda:0') need to verify.\nModel prediction is: tensor([ 3.42392373, -4.39966679,  1.84774685,  0.68908328,  2.66574335,\n         0.62991524, -0.17185465,  1.23229563, -3.23374295, -0.60079861],\n       device='cuda:0')\nbuild_the_model_with_refined_bounds batch [0/1]\nsetting alpha for layer /22 start_node /30 with alignment adjustment\nsetting alpha for layer /24 start_node /30 with alignment adjustment\nsetting alpha for layer /26 start_node /30 with alignment adjustment\nsetting alpha for layer /29 start_node /30 with alignment adjustment\nall slope initialized\ndirectly get lb and ub from refined bounds\nlA shapes: [torch.Size([1, 1, 32, 32, 32]), torch.Size([1, 1, 32, 16, 16]), torch.Size([1, 1, 128, 8, 8]), torch.Size([1, 1, 250])]\nc shape: torch.Size([1, 1, 10])\nalpha-CROWN with fixed intermediate bounds: tensor([[-0.03196740]], device='cuda:0') tensor([[inf]], device='cuda:0')\nKeeping slopes for these layers: ['/30']\nKeeping slopes for these layers: ['/30']\nlayer 0 size torch.Size([32768]) unstable 1437\nlayer 1 size torch.Size([8192]) unstable 665\nlayer 2 size torch.Size([8192]) unstable 541\nlayer 3 size torch.Size([250]) unstable 53\n-----------------\n# of unstable neurons: 2696\n-----------------\n\nbatch:  torch.Size([1, 32, 32, 32]) pre split depth:  5\nbatch:  torch.Size([1, 32, 32, 32]) post split depth:  5\nsplitting decisions: \nsplit level 0: [3, 123] \nsplit level 1: [3, 247] \nsplit level 2: [3, 248] \nsplit level 3: [3, 126] \nsplit level 4: [3, 55] \n(32, 3, 32, 32) torch.Size([32, 1, 10]) torch.Size([32, 1])\n\nall verified at 0th iter\npruning_in_iteration open status: False\nratio of positive domain = 32 / 32 = 1.0\npruning-in-iteration extra time: 0.00023436546325683594\nTensors transferred: pre=3.0153M lA=1.5076M alpha=0.1661M beta=0.0002M\nThis batch time : update_bounds func: 0.0205\t prepare: 0.0027\t bound: 0.0100\t transfer: 0.0073\t finalize: 0.0005\nAccumulated time: update_bounds func: 0.0205\t prepare: 0.0027\t bound: 0.0100\t transfer: 0.0073\t finalize: 0.0005\nbatch bounding time:  0.020548105239868164\nlength of domains: 0\nTotal time: 0.3222\t pickout: 0.0015\t decision: 0.2956\t get_bound: 0.0245\t add_domain: 0.0007\nAccumulated time:\t pickout: 0.0015\t decision: 0.2956\t get_bound: 0.0245\t add_domain: 0.0007\nNo domains left, verification finished!\n32 domains visited\n/home/tristan/.local/share/autoverify/verifiers/abcrown/tool/complete_verifier/batch_branch_and_bound.py:321: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  return torch.tensor(arguments.Config[\"bab\"][\"decision_thresh\"] + 1e-7), np.inf\nCumulative time: 0.5439763069152832\n\n\nProperties batch 2, size 1\nRemaining timeout: 285.44492840766907\n##### Instance 0 first 10 spec matrices: [[[ 1.  0.  0. -1.  0.  0.  0.  0.  0.  0.]]]\nthresholds: [0.] ######\nInitial alpha-CROWN verified for spec index [0] with bound 0.965167760848999.\n\nProperties batch 3, size 1\nRemaining timeout: 285.39766097068787\n##### Instance 0 first 10 spec matrices: [[[ 1.  0.  0.  0. -1.  0.  0.  0.  0.  0.]]]\nthresholds: [0.] ######\nRemaining spec index [0] with bounds tensor([[-0.86231709]], device='cuda:0') need to verify.\nModel prediction is: tensor([ 3.42392373, -4.39966679,  1.84774685,  0.68908328,  2.66574335,\n         0.62991524, -0.17185465,  1.23229563, -3.23374295, -0.60079861],\n       device='cuda:0')\nbuild_the_model_with_refined_bounds batch [0/1]\nsetting alpha for layer /22 start_node /30 with alignment adjustment\nsetting alpha for layer /24 start_node /30 with alignment adjustment\nsetting alpha for layer /26 start_node /30 with alignment adjustment\nsetting alpha for layer /29 start_node /30 with alignment adjustment\nall slope initialized\ndirectly get lb and ub from refined bounds\nlA shapes: [torch.Size([1, 1, 32, 32, 32]), torch.Size([1, 1, 32, 16, 16]), torch.Size([1, 1, 128, 8, 8]), torch.Size([1, 1, 250])]\nc shape: torch.Size([1, 1, 10])\nalpha-CROWN with fixed intermediate bounds: tensor([[-0.86231709]], device='cuda:0') tensor([[inf]], device='cuda:0')\nKeeping slopes for these layers: ['/30']\nKeeping slopes for these layers: ['/30']\nlayer 0 size torch.Size([32768]) unstable 1437\nlayer 1 size torch.Size([8192]) unstable 665\nlayer 2 size torch.Size([8192]) unstable 541\nlayer 3 size torch.Size([250]) unstable 53\n-----------------\n# of unstable neurons: 2696\n-----------------\n\nbatch:  torch.Size([1, 32, 32, 32]) pre split depth:  5\nbatch:  torch.Size([1, 32, 32, 32]) post split depth:  5\nsplitting decisions: \nsplit level 0: [3, 134] \nsplit level 1: [3, 247] \nsplit level 2: [3, 123] \nsplit level 3: [3, 71] \nsplit level 4: [3, 52] \n(32, 3, 32, 32) torch.Size([32, 1, 10]) torch.Size([32, 1])\npruning_in_iteration open status: True\nratio of positive domain = 11 / 32 = 0.34375\npruning-in-iteration extra time: 0.032778024673461914\nTensors transferred: pre=3.0153M lA=0.9894M alpha=0.1661M beta=0.0002M\nThis batch time : update_bounds func: 0.9480\t prepare: 0.0035\t bound: 0.9374\t transfer: 0.0065\t finalize: 0.0005\nAccumulated time: update_bounds func: 0.9684\t prepare: 0.0061\t bound: 0.9474\t transfer: 0.0138\t finalize: 0.0010\nbatch bounding time:  0.9480292797088623\nCurrent worst splitting domains lb-rhs (depth):\n-0.51872 (5), -0.50867 (5), -0.47914 (5), -0.47639 (5), -0.46053 (5), -0.44768 (5), -0.40703 (5), -0.39984 (5), -0.26980 (5), -0.25875 (5), -0.25381 (5), -0.24612 (5), -0.24009 (5), -0.22822 (5), -0.22390 (5), -0.21487 (5), -0.19789 (5), -0.18600 (5), -0.16737 (5), -0.14893 (5), \nlength of domains: 21\nTotal time: 0.9880\t pickout: 0.0008\t decision: 0.0297\t get_bound: 0.9538\t add_domain: 0.0037\nAccumulated time:\t pickout: 0.0008\t decision: 0.0297\t get_bound: 0.9538\t add_domain: 0.0037\nCurrent (lb-rhs): -0.5187225341796875\n11 domains visited\nCumulative time: 0.9955315589904785\n\nbatch:  torch.Size([21, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([21, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [3, 214] [3, 214] [3, 214] [3, 214] [3, 214] [3, 214] [3, 214] [3, 214] [3, 214] [3, 214] \n(42, 3, 32, 32) torch.Size([42, 1, 10]) torch.Size([42, 1])\npruning_in_iteration open status: True\nratio of positive domain = 14 / 42 = 0.33333333333333337\npruning-in-iteration extra time: 0.02961897850036621\nTensors transferred: pre=3.9575M lA=1.3192M alpha=0.2180M beta=0.0002M\nThis batch time : update_bounds func: 0.8289\t prepare: 0.0049\t bound: 0.8152\t transfer: 0.0076\t finalize: 0.0010\nAccumulated time: update_bounds func: 1.7973\t prepare: 0.0111\t bound: 1.7626\t transfer: 0.0215\t finalize: 0.0020\nbatch bounding time:  0.8289999961853027\nCurrent worst splitting domains lb-rhs (depth):\n-0.47139 (6), -0.46284 (6), -0.43350 (6), -0.43137 (6), -0.41344 (6), -0.40248 (6), -0.36402 (6), -0.36149 (6), -0.35578 (6), -0.33287 (6), -0.29660 (6), -0.28733 (6), -0.27547 (6), -0.24269 (6), -0.22407 (6), -0.21333 (6), -0.20803 (6), -0.19957 (6), -0.19530 (6), -0.19490 (6), \nlength of domains: 28\nTotal time: 0.8659\t pickout: 0.0012\t decision: 0.0306\t get_bound: 0.8291\t add_domain: 0.0050\nAccumulated time:\t pickout: 0.0020\t decision: 0.0604\t get_bound: 1.7829\t add_domain: 0.0087\nCurrent (lb-rhs): -0.471386194229126\n25 domains visited\nCumulative time: 1.8617486953735352\n\nbatch:  torch.Size([28, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([28, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [3, 248] [3, 248] [3, 248] [3, 248] [3, 248] [3, 248] [3, 248] [3, 248] [3, 248] [3, 248] \n(56, 3, 32, 32) torch.Size([56, 1, 10]) torch.Size([56, 1])\npruning_in_iteration open status: True\nratio of positive domain = 12 / 56 = 0.2142857142857143\npruning-in-iteration extra time: 0.00020766258239746094\nTensors transferred: pre=5.2767M lA=2.6384M alpha=0.2906M beta=0.0004M\nThis batch time : update_bounds func: 0.6586\t prepare: 0.0050\t bound: 0.6439\t transfer: 0.0088\t finalize: 0.0007\nAccumulated time: update_bounds func: 2.4559\t prepare: 0.0161\t bound: 2.4066\t transfer: 0.0302\t finalize: 0.0027\nbatch bounding time:  0.6586284637451172\nCurrent worst splitting domains lb-rhs (depth):\n-0.43693 (7), -0.42708 (7), -0.39961 (7), -0.39623 (7), -0.37680 (7), -0.36551 (7), -0.34704 (7), -0.33570 (7), -0.32636 (7), -0.32498 (7), -0.31908 (7), -0.29468 (7), -0.28918 (7), -0.28457 (7), -0.27956 (7), -0.27039 (7), -0.25666 (7), -0.24449 (7), -0.23416 (7), -0.22628 (7), \nlength of domains: 44\nTotal time: 0.7151\t pickout: 0.0015\t decision: 0.0477\t get_bound: 0.6587\t add_domain: 0.0072\nAccumulated time:\t pickout: 0.0035\t decision: 0.1081\t get_bound: 2.4416\t add_domain: 0.0159\nCurrent (lb-rhs): -0.436934232711792\n37 domains visited\nCumulative time: 2.5782253742218018\n\nbatch:  torch.Size([44, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([44, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [3, 195] [3, 195] [3, 195] [3, 195] [3, 195] [3, 195] [3, 195] [3, 195] [3, 195] [3, 195] \n(88, 3, 32, 32) torch.Size([88, 1, 10]) torch.Size([88, 1])\npruning_in_iteration open status: True\nratio of positive domain = 25 / 88 = 0.28409090909090906\npruning-in-iteration extra time: 0.029009103775024414\nTensors transferred: pre=8.2920M lA=2.9681M alpha=0.4567M beta=0.0007M\nThis batch time : update_bounds func: 0.7768\t prepare: 0.0045\t bound: 0.7502\t transfer: 0.0209\t finalize: 0.0011\nAccumulated time: update_bounds func: 3.2327\t prepare: 0.0205\t bound: 3.1568\t transfer: 0.0512\t finalize: 0.0038\nbatch bounding time:  0.7769062519073486\nCurrent worst splitting domains lb-rhs (depth):\n-0.40897 (8), -0.39871 (8), -0.37132 (8), -0.36745 (8), -0.34902 (8), -0.33764 (8), -0.31770 (8), -0.30631 (8), -0.29810 (8), -0.29695 (8), -0.29110 (8), -0.29056 (8), -0.28809 (8), -0.26678 (8), -0.26006 (8), -0.25461 (8), -0.25300 (8), -0.24933 (8), -0.24835 (8), -0.24093 (8), \nlength of domains: 63\nTotal time: 0.8378\t pickout: 0.0019\t decision: 0.0503\t get_bound: 0.7770\t add_domain: 0.0086\nAccumulated time:\t pickout: 0.0054\t decision: 0.1584\t get_bound: 3.2186\t add_domain: 0.0245\nCurrent (lb-rhs): -0.4089665412902832\n62 domains visited\nCumulative time: 3.417494773864746\n\nbatch:  torch.Size([63, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([63, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [3, 45] [3, 45] [3, 45] [3, 45] [3, 45] [3, 45] [3, 45] [3, 45] [3, 45] [3, 45] \n(126, 3, 32, 32) torch.Size([126, 1, 10]) torch.Size([126, 1])\npruning_in_iteration open status: False\nratio of positive domain = 13 / 126 = 0.10317460317460314\npruning-in-iteration extra time: 0.00022792816162109375\nTensors transferred: pre=11.8726M lA=5.9363M alpha=0.6539M beta=0.0011M\nThis batch time : update_bounds func: 0.7716\t prepare: 0.0077\t bound: 0.7351\t transfer: 0.0252\t finalize: 0.0032\nAccumulated time: update_bounds func: 4.0043\t prepare: 0.0283\t bound: 3.8918\t transfer: 0.0764\t finalize: 0.0070\nbatch bounding time:  0.7716498374938965\nCurrent worst splitting domains lb-rhs (depth):\n-0.38090 (9), -0.37239 (9), -0.37092 (9), -0.36096 (9), -0.34137 (9), -0.33827 (9), -0.33674 (9), -0.33229 (9), -0.32070 (9), -0.31300 (9), -0.30942 (9), -0.30053 (9), -0.28946 (9), -0.27811 (9), -0.27461 (9), -0.26701 (9), -0.26686 (9), -0.26371 (9), -0.26330 (9), -0.26261 (9), \nlength of domains: 113\nTotal time: 0.8492\t pickout: 0.0025\t decision: 0.0583\t get_bound: 0.7717\t add_domain: 0.0166\nAccumulated time:\t pickout: 0.0079\t decision: 0.2167\t get_bound: 3.9903\t add_domain: 0.0411\nCurrent (lb-rhs): -0.38089609146118164\n75 domains visited\nCumulative time: 4.26875114440918\n\nbatch:  torch.Size([113, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([113, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [3, 83] [3, 83] [3, 83] [3, 83] [3, 83] [3, 83] [3, 83] [3, 83] [3, 83] [3, 83] \n(226, 3, 32, 32) torch.Size([226, 1, 10]) torch.Size([226, 1])\npruning_in_iteration open status: True\nratio of positive domain = 110 / 226 = 0.48672566371681414\npruning-in-iteration extra time: 0.04263114929199219\nTensors transferred: pre=21.2953M lA=5.4652M alpha=1.1729M beta=0.0022M\nThis batch time : update_bounds func: 0.8884\t prepare: 0.0177\t bound: 0.8330\t transfer: 0.0349\t finalize: 0.0024\nAccumulated time: update_bounds func: 4.8926\t prepare: 0.0459\t bound: 4.7249\t transfer: 0.1113\t finalize: 0.0095\nbatch bounding time:  0.88848876953125\nCurrent worst splitting domains lb-rhs (depth):\n-0.35947 (10), -0.35085 (10), -0.34871 (10), -0.33884 (10), -0.31798 (10), -0.31492 (10), -0.31355 (10), -0.30911 (10), -0.29946 (10), -0.29199 (10), -0.28763 (10), -0.27889 (10), -0.26958 (10), -0.25749 (10), -0.25433 (10), -0.24743 (10), -0.24447 (10), -0.24396 (10), -0.23997 (10), -0.23954 (10), \nlength of domains: 116\nTotal time: 0.9974\t pickout: 0.0037\t decision: 0.0872\t get_bound: 0.8886\t add_domain: 0.0178\nAccumulated time:\t pickout: 0.0117\t decision: 0.3040\t get_bound: 4.8789\t add_domain: 0.0589\nCurrent (lb-rhs): -0.3594698905944824\n185 domains visited\nCumulative time: 5.268333435058594\n\nbatch:  torch.Size([116, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([116, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [3, 95] [3, 95] [3, 95] [3, 95] [3, 95] [3, 95] [3, 95] [3, 95] [3, 95] [3, 95] \n(232, 3, 32, 32) torch.Size([232, 1, 10]) torch.Size([232, 1])\npruning_in_iteration open status: False\nratio of positive domain = 39 / 232 = 0.1681034482758621\npruning-in-iteration extra time: 0.00017762184143066406\nTensors transferred: pre=21.8606M lA=10.9303M alpha=1.2041M beta=0.0024M\nThis batch time : update_bounds func: 0.8381\t prepare: 0.0089\t bound: 0.7937\t transfer: 0.0303\t finalize: 0.0050\nAccumulated time: update_bounds func: 5.7307\t prepare: 0.0548\t bound: 5.5186\t transfer: 0.1416\t finalize: 0.0144\nbatch bounding time:  0.8382682800292969\nCurrent worst splitting domains lb-rhs (depth):\n-0.33915 (11), -0.33049 (11), -0.32864 (11), -0.32759 (11), -0.32069 (11), -0.31964 (11), -0.31778 (11), -0.30983 (11), -0.29697 (11), -0.29359 (11), -0.29238 (11), -0.28871 (11), -0.28763 (11), -0.28691 (11), -0.28415 (11), -0.28056 (11), -0.27859 (11), -0.27084 (11), -0.27044 (11), -0.26671 (11), \nlength of domains: 193\nTotal time: 0.9386\t pickout: 0.0041\t decision: 0.0712\t get_bound: 0.8383\t add_domain: 0.0250\nAccumulated time:\t pickout: 0.0158\t decision: 0.3751\t get_bound: 5.7172\t add_domain: 0.0838\nCurrent (lb-rhs): -0.3391530513763428\n224 domains visited\nCumulative time: 6.208299875259399\n\nbatch:  torch.Size([193, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([193, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [3, 55] [3, 55] [3, 55] [3, 55] [3, 55] [3, 55] [3, 55] [3, 55] [3, 55] [3, 55] \n(386, 3, 32, 32) torch.Size([386, 1, 10]) torch.Size([386, 1])\npruning_in_iteration open status: True\nratio of positive domain = 190 / 386 = 0.49222797927461137\npruning-in-iteration extra time: 0.04242348670959473\nTensors transferred: pre=36.3716M lA=9.2342M alpha=2.0033M beta=0.0044M\nThis batch time : update_bounds func: 0.9855\t prepare: 0.0330\t bound: 0.9027\t transfer: 0.0436\t finalize: 0.0055\nAccumulated time: update_bounds func: 6.7162\t prepare: 0.0879\t bound: 6.4213\t transfer: 0.1852\t finalize: 0.0199\nbatch bounding time:  0.9855499267578125\nCurrent worst splitting domains lb-rhs (depth):\n-0.31952 (12), -0.31131 (12), -0.31026 (12), -0.30937 (12), -0.30279 (12), -0.30224 (12), -0.29970 (12), -0.29263 (12), -0.27878 (12), -0.27646 (12), -0.27427 (12), -0.27156 (12), -0.27052 (12), -0.27051 (12), -0.26702 (12), -0.26424 (12), -0.25998 (12), -0.25235 (12), -0.25228 (12), -0.24906 (12), \nlength of domains: 196\nTotal time: 1.1493\t pickout: 0.0059\t decision: 0.1268\t get_bound: 0.9856\t add_domain: 0.0309\nAccumulated time:\t pickout: 0.0216\t decision: 0.5020\t get_bound: 6.7029\t add_domain: 0.1148\nCurrent (lb-rhs): -0.3195207118988037\n414 domains visited\nCumulative time: 7.359467267990112\n\nbatch:  torch.Size([196, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([196, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [3, 50] [3, 50] [3, 50] [3, 50] [3, 50] [3, 50] [3, 50] [3, 50] [3, 50] [3, 50] \n(392, 3, 32, 32) torch.Size([392, 1, 10]) torch.Size([392, 1])\npruning_in_iteration open status: True\nratio of positive domain = 222 / 392 = 0.5663265306122449\npruning-in-iteration extra time: 0.048534393310546875\nTensors transferred: pre=36.9369M lA=8.0093M alpha=2.0344M beta=0.0049M\nThis batch time : update_bounds func: 0.9904\t prepare: 0.0178\t bound: 0.9072\t transfer: 0.0591\t finalize: 0.0059\nAccumulated time: update_bounds func: 7.7066\t prepare: 0.1056\t bound: 7.3286\t transfer: 0.2443\t finalize: 0.0258\nbatch bounding time:  0.9905743598937988\nCurrent worst splitting domains lb-rhs (depth):\n-0.30481 (13), -0.29672 (13), -0.29490 (13), -0.29435 (13), -0.28757 (13), -0.28673 (13), -0.28491 (13), -0.27730 (13), -0.26466 (13), -0.26204 (13), -0.26015 (13), -0.25702 (13), -0.25624 (13), -0.25574 (13), -0.25263 (13), -0.24974 (13), -0.24498 (13), -0.23744 (13), -0.23679 (13), -0.23403 (13), \nlength of domains: 170\nTotal time: 1.1342\t pickout: 0.0062\t decision: 0.1105\t get_bound: 0.9907\t add_domain: 0.0269\nAccumulated time:\t pickout: 0.0279\t decision: 0.6124\t get_bound: 7.6935\t add_domain: 0.1416\nCurrent (lb-rhs): -0.3048114776611328\n636 domains visited\nCumulative time: 8.49535059928894\n\nbatch:  torch.Size([170, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([170, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [3, 1] [3, 1] [3, 1] [3, 1] [3, 1] [3, 1] [3, 1] [3, 1] [3, 241] [3, 1] \n(340, 3, 32, 32) torch.Size([340, 1, 10]) torch.Size([340, 1])\npruning_in_iteration open status: True\nratio of positive domain = 157 / 340 = 0.46176470588235297\npruning-in-iteration extra time: 0.044748544692993164\nTensors transferred: pre=32.0371M lA=8.6218M alpha=1.7646M beta=0.0049M\nThis batch time : update_bounds func: 1.0250\t prepare: 0.0225\t bound: 0.9436\t transfer: 0.0528\t finalize: 0.0055\nAccumulated time: update_bounds func: 8.7316\t prepare: 0.1281\t bound: 8.2722\t transfer: 0.2971\t finalize: 0.0313\nbatch bounding time:  1.025054693222046\nCurrent worst splitting domains lb-rhs (depth):\n-0.29670 (14), -0.28881 (14), -0.28705 (14), -0.28641 (14), -0.27990 (14), -0.27885 (14), -0.27709 (14), -0.26964 (14), -0.25611 (14), -0.25369 (14), -0.25189 (14), -0.24857 (14), -0.24808 (14), -0.24733 (14), -0.24442 (14), -0.24156 (14), -0.23736 (14), -0.22968 (14), -0.22925 (14), -0.22633 (14), \nlength of domains: 183\nTotal time: 1.1599\t pickout: 0.0058\t decision: 0.1006\t get_bound: 1.0251\t add_domain: 0.0283\nAccumulated time:\t pickout: 0.0337\t decision: 0.7130\t get_bound: 8.7187\t add_domain: 0.1699\nCurrent (lb-rhs): -0.29670214653015137\n793 domains visited\nCumulative time: 9.657165288925171\n\nbatch:  torch.Size([183, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([183, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [3, 241] [3, 241] [3, 241] [3, 241] [3, 241] [3, 241] [3, 1] [3, 241] [3, 1] [3, 1] \n(366, 3, 32, 32) torch.Size([366, 1, 10]) torch.Size([366, 1])\npruning_in_iteration open status: True\nratio of positive domain = 183 / 366 = 0.5\npruning-in-iteration extra time: 0.04084181785583496\nTensors transferred: pre=34.4870M lA=8.6689M alpha=1.8995M beta=0.0056M\nThis batch time : update_bounds func: 0.9615\t prepare: 0.0167\t bound: 0.8796\t transfer: 0.0589\t finalize: 0.0058\nAccumulated time: update_bounds func: 9.6931\t prepare: 0.1448\t bound: 9.1518\t transfer: 0.3560\t finalize: 0.0371\nbatch bounding time:  0.9616320133209229\nCurrent worst splitting domains lb-rhs (depth):\n-0.28925 (15), -0.28125 (15), -0.27959 (15), -0.27886 (15), -0.27232 (15), -0.27128 (15), -0.26941 (15), -0.26196 (15), -0.24885 (15), -0.24620 (15), -0.24452 (15), -0.24128 (15), -0.24048 (15), -0.23979 (15), -0.23700 (15), -0.23391 (15), -0.22978 (15), -0.22230 (15), -0.22158 (15), -0.21881 (15), \nlength of domains: 183\nTotal time: 1.0991\t pickout: 0.0058\t decision: 0.1031\t get_bound: 0.9617\t add_domain: 0.0284\nAccumulated time:\t pickout: 0.0395\t decision: 0.8161\t get_bound: 9.6804\t add_domain: 0.1984\nCurrent (lb-rhs): -0.2892458438873291\n976 domains visited\nCumulative time: 10.757966995239258\n\nbatch:  torch.Size([183, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([183, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [3, 1] [2, 1206] [3, 126] [3, 126] [3, 241] [3, 241] [3, 1] [3, 1] [3, 126] [3, 126] \n(366, 3, 32, 32) torch.Size([366, 1, 10]) torch.Size([366, 1])\npruning_in_iteration open status: True\nratio of positive domain = 100 / 366 = 0.27322404371584696\npruning-in-iteration extra time: 0.06273293495178223\nTensors transferred: pre=34.4870M lA=12.5322M alpha=1.8995M beta=0.0063M\nThis batch time : update_bounds func: 1.3773\t prepare: 0.0144\t bound: 1.2669\t transfer: 0.0849\t finalize: 0.0107\nAccumulated time: update_bounds func: 11.0705\t prepare: 0.1593\t bound: 10.4187\t transfer: 0.4409\t finalize: 0.0478\nbatch bounding time:  1.377776861190796\nCurrent worst splitting domains lb-rhs (depth):\n-0.28220 (16), -0.28135 (16), -0.27413 (16), -0.27373 (16), -0.27290 (16), -0.27183 (16), -0.27069 (16), -0.26854 (16), -0.26549 (16), -0.26459 (16), -0.26269 (16), -0.26225 (16), -0.26180 (16), -0.26055 (16), -0.25507 (16), -0.25287 (16), -0.24245 (16), -0.24022 (16), -0.23833 (16), -0.23810 (16), \nlength of domains: 266\nTotal time: 1.5863\t pickout: 0.0059\t decision: 0.1398\t get_bound: 1.3779\t add_domain: 0.0627\nAccumulated time:\t pickout: 0.0454\t decision: 0.9559\t get_bound: 11.0583\t add_domain: 0.2611\nCurrent (lb-rhs): -0.2821977138519287\n1076 domains visited\nCumulative time: 12.347241163253784\n\nbatch:  torch.Size([266, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([266, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [3, 1] [2, 3243] [2, 7594] [2, 7054] [3, 1] [2, 2190] [2, 6307] [3, 56] [2, 2190] [2, 1206] \n(532, 3, 32, 32) torch.Size([532, 1, 10]) torch.Size([532, 1])\npruning_in_iteration open status: False\nratio of positive domain = 85 / 532 = 0.15977443609022557\npruning-in-iteration extra time: 0.0002880096435546875\nTensors transferred: pre=50.1287M lA=25.0643M alpha=2.7610M beta=0.0096M\nThis batch time : update_bounds func: 1.7012\t prepare: 0.0771\t bound: 1.4850\t transfer: 0.1169\t finalize: 0.0213\nAccumulated time: update_bounds func: 12.7716\t prepare: 0.2363\t bound: 11.9037\t transfer: 0.5578\t finalize: 0.0690\nbatch bounding time:  1.7014055252075195\nCurrent worst splitting domains lb-rhs (depth):\n-0.27554 (17), -0.27521 (17), -0.27478 (17), -0.27388 (17), -0.26762 (17), -0.26734 (17), -0.26732 (17), -0.26678 (17), -0.26653 (17), -0.26590 (17), -0.26547 (17), -0.26499 (17), -0.26431 (17), -0.26397 (17), -0.26379 (17), -0.25926 (17), -0.25828 (17), -0.25810 (17), -0.25799 (17), -0.25676 (17), \nlength of domains: 447\nTotal time: 2.0495\t pickout: 0.0088\t decision: 0.2228\t get_bound: 1.7015\t add_domain: 0.1164\nAccumulated time:\t pickout: 0.0542\t decision: 1.1787\t get_bound: 12.7598\t add_domain: 0.3775\nCurrent (lb-rhs): -0.27553701400756836\n1161 domains visited\nCumulative time: 14.39883279800415\n\nbatch:  torch.Size([447, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([447, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [2, 4883] [2, 6307] [2, 2190] [2, 1206] [3, 126] [3, 56] [3, 230] [2, 6307] [3, 230] [2, 6307] \n(894, 3, 32, 32) torch.Size([894, 1, 10]) torch.Size([894, 1])\npruning_in_iteration open status: True\nratio of positive domain = 196 / 894 = 0.2192393736017897\npruning-in-iteration extra time: 0.03419351577758789\nTensors transferred: pre=84.2388M lA=32.8852M alpha=4.6398M beta=0.0179M\nThis batch time : update_bounds func: 2.2599\t prepare: 0.1207\t bound: 1.9668\t transfer: 0.1571\t finalize: 0.0132\nAccumulated time: update_bounds func: 15.0315\t prepare: 0.3570\t bound: 13.8705\t transfer: 0.7149\t finalize: 0.0822\nbatch bounding time:  2.260159730911255\nCurrent worst splitting domains lb-rhs (depth):\n-0.26964 (18), -0.26939 (18), -0.26929 (18), -0.26886 (18), -0.26860 (18), -0.26832 (18), -0.26787 (18), -0.26185 (18), -0.26156 (18), -0.26148 (18), -0.26128 (18), -0.26094 (18), -0.26049 (18), -0.26047 (18), -0.26028 (18), -0.26027 (18), -0.26019 (18), -0.25964 (18), -0.25964 (18), -0.25960 (18), \nlength of domains: 698\nTotal time: 3.4875\t pickout: 0.0151\t decision: 1.1031\t get_bound: 2.2604\t add_domain: 0.1089\nAccumulated time:\t pickout: 0.0692\t decision: 2.2818\t get_bound: 15.0202\t add_domain: 0.4864\nCurrent (lb-rhs): -0.2696380615234375\n1357 domains visited\nCumulative time: 17.889668464660645\n\nbatch:  torch.Size([512, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([512, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [3, 56] [3, 56] [2, 6307] [3, 56] [2, 6307] [3, 56] [2, 1206] [3, 56] [2, 1206] [3, 56] \n(1024, 3, 32, 32) torch.Size([1024, 1, 10]) torch.Size([1024, 1])\npruning_in_iteration open status: True\nratio of positive domain = 325 / 1024 = 0.3173828125\npruning-in-iteration extra time: 0.0441594123840332\nTensors transferred: pre=96.4883M lA=32.9323M alpha=5.3145M beta=0.0215M\nThis batch time : update_bounds func: 2.4667\t prepare: 0.0565\t bound: 2.2104\t transfer: 0.1884\t finalize: 0.0105\nAccumulated time: update_bounds func: 17.4982\t prepare: 0.4135\t bound: 16.0809\t transfer: 0.9033\t finalize: 0.0927\nbatch bounding time:  2.466987371444702\nCurrent worst splitting domains lb-rhs (depth):\n-0.26939 (18), -0.26832 (18), -0.26504 (19), -0.26475 (19), -0.26431 (19), -0.26400 (19), -0.26327 (19), -0.26019 (18), -0.25964 (18), -0.25881 (18), -0.25834 (18), -0.25742 (19), -0.25731 (18), -0.25717 (19), -0.25709 (19), -0.25661 (19), -0.25660 (19), -0.25602 (19), -0.25579 (19), -0.25579 (19), \nlength of domains: 885\nTotal time: 6.4448\t pickout: 0.0157\t decision: 3.8247\t get_bound: 2.4671\t add_domain: 0.1372\nAccumulated time:\t pickout: 0.0850\t decision: 6.1065\t get_bound: 17.4873\t add_domain: 0.6236\nCurrent (lb-rhs): -0.2693946361541748\n1682 domains visited\nCumulative time: 24.338659048080444\n\nbatch:  torch.Size([512, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([512, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [3, 230] [3, 230] [2, 1963] [2, 5139] [3, 230] [3, 230] [3, 56] [3, 126] [2, 2190] [3, 56] \n(1024, 3, 32, 32) torch.Size([1024, 1, 10]) torch.Size([1024, 1])\npruning_in_iteration open status: True\nratio of positive domain = 363 / 1024 = 0.3544921875\npruning-in-iteration extra time: 0.052978515625\nTensors transferred: pre=96.4883M lA=31.1420M alpha=5.3145M beta=0.0234M\nThis batch time : update_bounds func: 2.3490\t prepare: 0.0532\t bound: 2.1304\t transfer: 0.1405\t finalize: 0.0239\nAccumulated time: update_bounds func: 19.8472\t prepare: 0.4667\t bound: 18.2114\t transfer: 1.0438\t finalize: 0.1166\nbatch bounding time:  2.3493032455444336\nCurrent worst splitting domains lb-rhs (depth):\n-0.26939 (18), -0.26832 (18), -0.26400 (19), -0.26327 (19), -0.26019 (18), -0.25999 (20), -0.25984 (20), -0.25964 (18), -0.25964 (20), -0.25881 (18), -0.25842 (20), -0.25834 (18), -0.25793 (20), -0.25731 (18), -0.25602 (19), -0.25579 (19), -0.25507 (18), -0.25496 (19), -0.25362 (19), -0.25348 (18), \nlength of domains: 1034\nTotal time: 3.6978\t pickout: 0.0146\t decision: 0.8712\t get_bound: 2.3494\t add_domain: 0.4625\nAccumulated time:\t pickout: 0.0996\t decision: 6.9777\t get_bound: 19.8367\t add_domain: 1.0861\nCurrent (lb-rhs): -0.2693946361541748\n2045 domains visited\nCumulative time: 28.039958000183105\n\nbatch:  torch.Size([512, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([512, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [2, 4715] [3, 230] [2, 5139] [3, 56] [2, 2732] [3, 230] [3, 230] [2, 2190] [2, 5139] [3, 56] \n(1024, 3, 32, 32) torch.Size([1024, 1, 10]) torch.Size([1024, 1])\npruning_in_iteration open status: True\nratio of positive domain = 365 / 1024 = 0.3564453125\npruning-in-iteration extra time: 0.06606769561767578\nTensors transferred: pre=96.4883M lA=31.0949M alpha=5.3145M beta=0.0244M\nThis batch time : update_bounds func: 2.6941\t prepare: 0.0572\t bound: 2.4423\t transfer: 0.1807\t finalize: 0.0123\nAccumulated time: update_bounds func: 22.5412\t prepare: 0.5239\t bound: 20.6537\t transfer: 1.2245\t finalize: 0.1289\nbatch bounding time:  2.694322347640991\nCurrent worst splitting domains lb-rhs (depth):\n-0.26939 (18), -0.26832 (18), -0.26400 (19), -0.26327 (19), -0.26019 (18), -0.25964 (18), -0.25881 (18), -0.25842 (20), -0.25834 (18), -0.25793 (20), -0.25731 (18), -0.25602 (19), -0.25579 (19), -0.25546 (21), -0.25525 (21), -0.25507 (18), -0.25496 (19), -0.25486 (21), -0.25362 (19), -0.25348 (18), \nlength of domains: 1181\nTotal time: 4.1025\t pickout: 0.0166\t decision: 1.2715\t get_bound: 2.6944\t add_domain: 0.1201\nAccumulated time:\t pickout: 0.1162\t decision: 8.2492\t get_bound: 22.5311\t add_domain: 1.2062\nCurrent (lb-rhs): -0.2693946361541748\n2410 domains visited\nCumulative time: 32.14678120613098\n\nbatch:  torch.Size([512, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([512, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [3, 126] [2, 1204] [2, 7475] [3, 20] [2, 6379] [3, 230] [2, 5965] [3, 227] [3, 84] [3, 227] \n(1024, 3, 32, 32) torch.Size([1024, 1, 10]) torch.Size([1024, 1])\npruning_in_iteration open status: True\nratio of positive domain = 286 / 1024 = 0.279296875\npruning-in-iteration extra time: 0.05639791488647461\nTensors transferred: pre=96.4883M lA=34.8168M alpha=5.3145M beta=0.0264M\nThis batch time : update_bounds func: 2.8418\t prepare: 0.0763\t bound: 2.5500\t transfer: 0.1946\t finalize: 0.0192\nAccumulated time: update_bounds func: 25.3830\t prepare: 0.6002\t bound: 23.2037\t transfer: 1.4191\t finalize: 0.1481\nbatch bounding time:  2.842087984085083\nCurrent worst splitting domains lb-rhs (depth):\n-0.26939 (18), -0.26832 (18), -0.26400 (19), -0.26327 (19), -0.26019 (18), -0.25964 (18), -0.25881 (18), -0.25842 (20), -0.25834 (18), -0.25793 (20), -0.25731 (18), -0.25602 (19), -0.25579 (19), -0.25507 (18), -0.25496 (19), -0.25362 (19), -0.25348 (18), -0.25341 (21), -0.25311 (19), -0.25219 (19), \nlength of domains: 1407\nTotal time: 4.0827\t pickout: 0.0166\t decision: 1.0272\t get_bound: 2.8422\t add_domain: 0.1967\nAccumulated time:\t pickout: 0.1328\t decision: 9.2764\t get_bound: 25.3733\t add_domain: 1.4029\nCurrent (lb-rhs): -0.2693946361541748\n2696 domains visited\nCumulative time: 36.2341570854187\n\nbatch:  torch.Size([512, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([512, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [2, 4715] [2, 5518] [2, 1206] [3, 84] [3, 84] [3, 20] [3, 227] [2, 1963] [3, 84] [2, 1242] \n(1024, 3, 32, 32) torch.Size([1024, 1, 10]) torch.Size([1024, 1])\npruning_in_iteration open status: True\nratio of positive domain = 259 / 1024 = 0.2529296875\npruning-in-iteration extra time: 0.05217456817626953\nTensors transferred: pre=96.4883M lA=36.0418M alpha=5.3145M beta=0.0264M\nThis batch time : update_bounds func: 2.6518\t prepare: 0.0576\t bound: 2.3784\t transfer: 0.2006\t finalize: 0.0141\nAccumulated time: update_bounds func: 28.0348\t prepare: 0.6578\t bound: 25.5821\t transfer: 1.6198\t finalize: 0.1623\nbatch bounding time:  2.652092695236206\nCurrent worst splitting domains lb-rhs (depth):\n-0.26939 (18), -0.26832 (18), -0.26400 (19), -0.26327 (19), -0.26019 (18), -0.25964 (18), -0.25881 (18), -0.25842 (20), -0.25834 (18), -0.25793 (20), -0.25731 (18), -0.25602 (19), -0.25579 (19), -0.25507 (18), -0.25496 (19), -0.25362 (19), -0.25348 (18), -0.25341 (21), -0.25311 (19), -0.25219 (19), \nlength of domains: 1660\nTotal time: 3.7724\t pickout: 0.0150\t decision: 0.9557\t get_bound: 2.6522\t add_domain: 0.1495\nAccumulated time:\t pickout: 0.1478\t decision: 10.2321\t get_bound: 28.0255\t add_domain: 1.5524\nCurrent (lb-rhs): -0.2693946361541748\n2955 domains visited\nCumulative time: 40.0115180015564\n\nbatch:  torch.Size([512, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([512, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [3, 84] [2, 6307] [3, 20] [2, 7140] [3, 20] [2, 2190] [2, 5518] [2, 7054] [2, 3889] [2, 2454] \n(1024, 3, 32, 32) torch.Size([1024, 1, 10]) torch.Size([1024, 1])\npruning_in_iteration open status: True\nratio of positive domain = 250 / 1024 = 0.244140625\npruning-in-iteration extra time: 0.05416417121887207\nTensors transferred: pre=96.4883M lA=36.4658M alpha=5.3145M beta=0.0264M\nThis batch time : update_bounds func: 2.5623\t prepare: 0.0560\t bound: 2.3325\t transfer: 0.1567\t finalize: 0.0153\nAccumulated time: update_bounds func: 30.5970\t prepare: 0.7138\t bound: 27.9147\t transfer: 1.7764\t finalize: 0.1776\nbatch bounding time:  2.56272029876709\nCurrent worst splitting domains lb-rhs (depth):\n-0.26939 (18), -0.26832 (18), -0.26400 (19), -0.26327 (19), -0.26019 (18), -0.25964 (18), -0.25881 (18), -0.25842 (20), -0.25834 (18), -0.25793 (20), -0.25731 (18), -0.25602 (19), -0.25579 (19), -0.25507 (18), -0.25496 (19), -0.25362 (19), -0.25348 (18), -0.25341 (21), -0.25311 (19), -0.25219 (19), \nlength of domains: 1922\nTotal time: 4.0066\t pickout: 0.0165\t decision: 1.2182\t get_bound: 2.5628\t add_domain: 0.2092\nAccumulated time:\t pickout: 0.1643\t decision: 11.4503\t get_bound: 30.5883\t add_domain: 1.7616\nCurrent (lb-rhs): -0.2693946361541748\n3205 domains visited\nCumulative time: 44.02162218093872\n\nbatch:  torch.Size([512, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([512, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [2, 5965] [2, 7064] [2, 2190] [2, 7054] [2, 5518] [2, 3931] [2, 7064] [3, 84] [2, 6379] [2, 7140] \n(1024, 3, 32, 32) torch.Size([1024, 1, 10]) torch.Size([1024, 1])\npruning_in_iteration open status: True\nratio of positive domain = 269 / 1024 = 0.2626953125\npruning-in-iteration extra time: 0.052596092224121094\nTensors transferred: pre=96.4883M lA=35.5706M alpha=5.3145M beta=0.0273M\nThis batch time : update_bounds func: 2.7604\t prepare: 0.0661\t bound: 2.5131\t transfer: 0.1496\t finalize: 0.0297\nAccumulated time: update_bounds func: 33.3574\t prepare: 0.7799\t bound: 30.4278\t transfer: 1.9260\t finalize: 0.2072\nbatch bounding time:  2.7609148025512695\nCurrent worst splitting domains lb-rhs (depth):\n-0.26939 (18), -0.26832 (18), -0.26400 (19), -0.26327 (19), -0.26019 (18), -0.25964 (18), -0.25881 (18), -0.25842 (20), -0.25834 (18), -0.25793 (20), -0.25731 (18), -0.25602 (19), -0.25579 (19), -0.25507 (18), -0.25496 (19), -0.25362 (19), -0.25348 (18), -0.25341 (21), -0.25311 (19), -0.25219 (19), \nlength of domains: 2165\nTotal time: 7.2756\t pickout: 0.0161\t decision: 0.8871\t get_bound: 2.7611\t add_domain: 3.6113\nAccumulated time:\t pickout: 0.1804\t decision: 12.3374\t get_bound: 33.3493\t add_domain: 5.3729\nCurrent (lb-rhs): -0.2693946361541748\n3474 domains visited\nCumulative time: 51.3028347492218\n\nbatch:  torch.Size([512, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([512, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [3, 227] [2, 7064] [2, 500] [2, 7064] [2, 7054] [2, 7064] [2, 2454] [3, 227] [2, 2454] [3, 20] \n(1024, 3, 32, 32) torch.Size([1024, 1, 10]) torch.Size([1024, 1])\npruning_in_iteration open status: True\nratio of positive domain = 253 / 1024 = 0.2470703125\npruning-in-iteration extra time: 0.050319671630859375\nTensors transferred: pre=96.4883M lA=36.3244M alpha=5.3145M beta=0.0283M\nThis batch time : update_bounds func: 3.0642\t prepare: 0.0594\t bound: 2.7051\t transfer: 0.2119\t finalize: 0.0330\nAccumulated time: update_bounds func: 36.4217\t prepare: 0.8393\t bound: 33.1329\t transfer: 2.1380\t finalize: 0.2403\nbatch bounding time:  3.0646328926086426\nCurrent worst splitting domains lb-rhs (depth):\n-0.26939 (18), -0.26832 (18), -0.26400 (19), -0.26327 (19), -0.26019 (18), -0.25964 (18), -0.25881 (18), -0.25842 (20), -0.25834 (18), -0.25793 (20), -0.25731 (18), -0.25602 (19), -0.25579 (19), -0.25507 (18), -0.25496 (19), -0.25362 (19), -0.25348 (18), -0.25341 (21), -0.25311 (19), -0.25219 (19), \nlength of domains: 2424\nTotal time: 4.6737\t pickout: 0.0173\t decision: 1.4192\t get_bound: 3.0647\t add_domain: 0.1725\nAccumulated time:\t pickout: 0.1977\t decision: 13.7566\t get_bound: 36.4141\t add_domain: 5.5454\nCurrent (lb-rhs): -0.2693946361541748\n3727 domains visited\nCumulative time: 55.98031401634216\n\nbatch:  torch.Size([512, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([512, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [2, 4883] [2, 4883] [3, 84] [2, 7054] [2, 4883] [2, 7054] [2, 2454] [2, 7064] [2, 6379] [3, 20] \n(1024, 3, 32, 32) torch.Size([1024, 1, 10]) torch.Size([1024, 1])\npruning_in_iteration open status: True\nratio of positive domain = 293 / 1024 = 0.2861328125\npruning-in-iteration extra time: 0.05536532402038574\nTensors transferred: pre=96.4883M lA=34.4399M alpha=5.3145M beta=0.0293M\nThis batch time : update_bounds func: 2.7487\t prepare: 0.0633\t bound: 2.5312\t transfer: 0.1406\t finalize: 0.0119\nAccumulated time: update_bounds func: 39.1703\t prepare: 0.9026\t bound: 35.6641\t transfer: 2.2785\t finalize: 0.2522\nbatch bounding time:  2.7489867210388184\nCurrent worst splitting domains lb-rhs (depth):\n-0.26939 (18), -0.26832 (18), -0.26400 (19), -0.26327 (19), -0.26019 (18), -0.25964 (18), -0.25881 (18), -0.25842 (20), -0.25834 (18), -0.25793 (20), -0.25731 (18), -0.25602 (19), -0.25579 (19), -0.25507 (18), -0.25496 (19), -0.25362 (19), -0.25348 (18), -0.25341 (21), -0.25311 (19), -0.25219 (19), \nlength of domains: 2643\nTotal time: 3.8842\t pickout: 0.0167\t decision: 0.9751\t get_bound: 2.7491\t add_domain: 0.1433\nAccumulated time:\t pickout: 0.2143\t decision: 14.7317\t get_bound: 39.1632\t add_domain: 5.6887\nCurrent (lb-rhs): -0.2693946361541748\n4020 domains visited\nCumulative time: 59.86992645263672\n\nbatch:  torch.Size([512, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([512, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [2, 500] [2, 2454] [2, 1961] [2, 1961] [2, 5654] [3, 84] [2, 1961] [2, 1961] [2, 2454] [3, 84] \n(1024, 3, 32, 32) torch.Size([1024, 1, 10]) torch.Size([1024, 1])\npruning_in_iteration open status: True\nratio of positive domain = 316 / 1024 = 0.30859375\npruning-in-iteration extra time: 0.06290912628173828\nTensors transferred: pre=96.4883M lA=33.3563M alpha=5.3145M beta=0.0303M\nThis batch time : update_bounds func: 3.0653\t prepare: 0.0604\t bound: 2.5546\t transfer: 0.4267\t finalize: 0.0226\nAccumulated time: update_bounds func: 42.2356\t prepare: 0.9630\t bound: 38.2187\t transfer: 2.7052\t finalize: 0.2747\nbatch bounding time:  3.0691428184509277\nCurrent worst splitting domains lb-rhs (depth):\n-0.26939 (18), -0.26832 (18), -0.26400 (19), -0.26327 (19), -0.26019 (18), -0.25964 (18), -0.25881 (18), -0.25842 (20), -0.25834 (18), -0.25793 (20), -0.25731 (18), -0.25602 (19), -0.25579 (19), -0.25507 (18), -0.25496 (19), -0.25362 (19), -0.25348 (18), -0.25341 (21), -0.25311 (19), -0.25219 (19), \nlength of domains: 2839\nTotal time: 4.3061\t pickout: 0.0185\t decision: 1.0072\t get_bound: 3.0692\t add_domain: 0.2111\nAccumulated time:\t pickout: 0.2328\t decision: 15.7389\t get_bound: 42.2324\t add_domain: 5.8999\nCurrent (lb-rhs): -0.2693946361541748\n4336 domains visited\nCumulative time: 64.1956398487091\n\nbatch:  torch.Size([512, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([512, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [2, 4883] [2, 4883] [2, 5654] [2, 6307] [3, 227] [2, 5518] [2, 2190] [3, 84] [2, 2190] [2, 5654] \n(1024, 3, 32, 32) torch.Size([1024, 1, 10]) torch.Size([1024, 1])\npruning_in_iteration open status: True\nratio of positive domain = 339 / 1024 = 0.3310546875\npruning-in-iteration extra time: 0.06217145919799805\nTensors transferred: pre=96.4883M lA=32.2727M alpha=5.3145M beta=0.0332M\nThis batch time : update_bounds func: 3.0398\t prepare: 0.0552\t bound: 2.6436\t transfer: 0.3193\t finalize: 0.0206\nAccumulated time: update_bounds func: 45.2754\t prepare: 1.0181\t bound: 40.8623\t transfer: 3.0245\t finalize: 0.2954\nbatch bounding time:  3.0443966388702393\nCurrent worst splitting domains lb-rhs (depth):\n-0.26939 (18), -0.26832 (18), -0.26400 (19), -0.26327 (19), -0.26019 (18), -0.25964 (18), -0.25881 (18), -0.25842 (20), -0.25834 (18), -0.25793 (20), -0.25731 (18), -0.25602 (19), -0.25579 (19), -0.25507 (18), -0.25496 (19), -0.25362 (19), -0.25348 (18), -0.25341 (21), -0.25311 (19), -0.25219 (19), \nlength of domains: 3012\nTotal time: 4.5301\t pickout: 0.0167\t decision: 1.1672\t get_bound: 3.0445\t add_domain: 0.3017\nAccumulated time:\t pickout: 0.2495\t decision: 16.9061\t get_bound: 45.2769\t add_domain: 6.2015\nCurrent (lb-rhs): -0.2693946361541748\n4675 domains visited\nCumulative time: 68.7480878829956\n\nbatch:  torch.Size([512, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([512, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [3, 227] [3, 227] [2, 6330] [3, 84] [3, 84] [2, 4883] [2, 5139] [3, 84] [2, 2772] [2, 2870] \n(1024, 3, 32, 32) torch.Size([1024, 1, 10]) torch.Size([1024, 1])\npruning_in_iteration open status: True\nratio of positive domain = 325 / 1024 = 0.3173828125\npruning-in-iteration extra time: 0.07141542434692383\nTensors transferred: pre=96.4883M lA=32.9323M alpha=5.3145M beta=0.0352M\nThis batch time : update_bounds func: 3.1574\t prepare: 0.0719\t bound: 2.6881\t transfer: 0.3701\t finalize: 0.0255\nAccumulated time: update_bounds func: 48.4329\t prepare: 1.0900\t bound: 43.5504\t transfer: 3.3946\t finalize: 0.3209\nbatch bounding time:  3.1616053581237793\nCurrent worst splitting domains lb-rhs (depth):\n-0.26939 (18), -0.26832 (18), -0.26400 (19), -0.26327 (19), -0.26019 (18), -0.25964 (18), -0.25881 (18), -0.25842 (20), -0.25834 (18), -0.25793 (20), -0.25731 (18), -0.25602 (19), -0.25579 (19), -0.25507 (18), -0.25496 (19), -0.25362 (19), -0.25348 (18), -0.25341 (21), -0.25311 (19), -0.25219 (19), \nlength of domains: 3199\nTotal time: 4.6300\t pickout: 0.0158\t decision: 1.2358\t get_bound: 3.1618\t add_domain: 0.2165\nAccumulated time:\t pickout: 0.2654\t decision: 18.1419\t get_bound: 48.4387\t add_domain: 6.4180\nCurrent (lb-rhs): -0.2693946361541748\n5000 domains visited\nCumulative time: 73.393470287323\n\nbatch:  torch.Size([512, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([512, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [3, 227] [3, 227] [2, 7064] [2, 5139] [2, 6330] [2, 7064] [2, 7054] [2, 1242] [2, 7054] [2, 6330] \n(1024, 3, 32, 32) torch.Size([1024, 1, 10]) torch.Size([1024, 1])\npruning_in_iteration open status: True\nratio of positive domain = 295 / 1024 = 0.2880859375\npruning-in-iteration extra time: 0.06586432456970215\nTensors transferred: pre=96.4883M lA=34.3457M alpha=5.3145M beta=0.0361M\nThis batch time : update_bounds func: 3.0814\t prepare: 0.0464\t bound: 2.7626\t transfer: 0.2506\t finalize: 0.0209\nAccumulated time: update_bounds func: 51.5143\t prepare: 1.1364\t bound: 46.3129\t transfer: 3.6452\t finalize: 0.3418\nbatch bounding time:  3.084151029586792\nCurrent worst splitting domains lb-rhs (depth):\n-0.26939 (18), -0.26832 (18), -0.26400 (19), -0.26327 (19), -0.26019 (18), -0.25964 (18), -0.25881 (18), -0.25842 (20), -0.25834 (18), -0.25793 (20), -0.25731 (18), -0.25602 (19), -0.25579 (19), -0.25507 (18), -0.25496 (19), -0.25362 (19), -0.25348 (18), -0.25341 (21), -0.25311 (19), -0.25219 (19), \nlength of domains: 3416\nTotal time: 4.5458\t pickout: 0.0167\t decision: 1.2146\t get_bound: 3.0844\t add_domain: 0.2300\nAccumulated time:\t pickout: 0.2821\t decision: 19.3565\t get_bound: 51.5231\t add_domain: 6.6481\nCurrent (lb-rhs): -0.2693946361541748\n5295 domains visited\nCumulative time: 77.95658612251282\n\nbatch:  torch.Size([512, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([512, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [2, 1961] [3, 104] [2, 7054] [3, 84] [2, 7054] [2, 500] [2, 6380] [2, 500] [2, 8123] [2, 5518] \n(1024, 3, 32, 32) torch.Size([1024, 1, 10]) torch.Size([1024, 1])\npruning_in_iteration open status: True\nratio of positive domain = 252 / 1024 = 0.24609375\npruning-in-iteration extra time: 0.06382036209106445\nTensors transferred: pre=96.4883M lA=36.3716M alpha=5.3145M beta=0.0371M\nThis batch time : update_bounds func: 3.0913\t prepare: 0.0596\t bound: 2.7932\t transfer: 0.2071\t finalize: 0.0297\nAccumulated time: update_bounds func: 54.6057\t prepare: 1.1959\t bound: 49.1061\t transfer: 3.8523\t finalize: 0.3714\nbatch bounding time:  3.096867084503174\nCurrent worst splitting domains lb-rhs (depth):\n-0.26939 (18), -0.26832 (18), -0.26400 (19), -0.26327 (19), -0.26019 (18), -0.25964 (18), -0.25881 (18), -0.25842 (20), -0.25834 (18), -0.25793 (20), -0.25731 (18), -0.25602 (19), -0.25579 (19), -0.25507 (18), -0.25496 (19), -0.25362 (19), -0.25348 (18), -0.25341 (21), -0.25311 (19), -0.25219 (19), \nlength of domains: 3676\nTotal time: 4.4918\t pickout: 0.0165\t decision: 1.1252\t get_bound: 3.0970\t add_domain: 0.2531\nAccumulated time:\t pickout: 0.2986\t decision: 20.4817\t get_bound: 54.6201\t add_domain: 6.9012\nCurrent (lb-rhs): -0.2693946361541748\n5547 domains visited\nCumulative time: 82.46633124351501\n\nbatch:  torch.Size([512, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([512, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [2, 4715] [3, 227] [2, 3889] [2, 6330] [2, 3870] [2, 7534] [2, 7064] [2, 6330] [3, 84] [2, 2732] \n(1024, 3, 32, 32) torch.Size([1024, 1, 10]) torch.Size([1024, 1])\npruning_in_iteration open status: False\nratio of positive domain = 180 / 1024 = 0.17578125\npruning-in-iteration extra time: 0.0002720355987548828\nTensors transferred: pre=96.4883M lA=48.2441M alpha=5.3145M beta=0.0381M\nThis batch time : update_bounds func: 3.8701\t prepare: 0.0695\t bound: 3.4941\t transfer: 0.2799\t finalize: 0.0248\nAccumulated time: update_bounds func: 58.4758\t prepare: 1.2655\t bound: 52.6003\t transfer: 4.1321\t finalize: 0.3962\nbatch bounding time:  3.877948522567749\nCurrent worst splitting domains lb-rhs (depth):\n-0.26939 (18), -0.26832 (18), -0.26400 (19), -0.26327 (19), -0.26019 (18), -0.25964 (18), -0.25881 (18), -0.25842 (20), -0.25834 (18), -0.25793 (20), -0.25731 (18), -0.25602 (19), -0.25579 (19), -0.25507 (18), -0.25496 (19), -0.25362 (19), -0.25348 (18), -0.25341 (21), -0.25311 (19), -0.25219 (19), \nlength of domains: 4008\nTotal time: 5.3108\t pickout: 0.0164\t decision: 1.1534\t get_bound: 3.8781\t add_domain: 0.2629\nAccumulated time:\t pickout: 0.3150\t decision: 21.6351\t get_bound: 58.4982\t add_domain: 7.1641\nCurrent (lb-rhs): -0.2693946361541748\n5727 domains visited\nCumulative time: 87.79716491699219\n\nbatch:  torch.Size([512, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([512, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [2, 7064] [3, 84] [2, 4715] [3, 73] [2, 1250] [2, 4715] [2, 4715] [2, 5518] [2, 3931] [2, 7054] \n(1024, 3, 32, 32) torch.Size([1024, 1, 10]) torch.Size([1024, 1])\npruning_in_iteration open status: True\nratio of positive domain = 215 / 1024 = 0.2099609375\npruning-in-iteration extra time: 0.03629446029663086\nTensors transferred: pre=96.4883M lA=38.1148M alpha=5.3145M beta=0.0391M\nThis batch time : update_bounds func: 3.5777\t prepare: 0.0640\t bound: 3.2641\t transfer: 0.2311\t finalize: 0.0169\nAccumulated time: update_bounds func: 62.0535\t prepare: 1.3295\t bound: 55.8643\t transfer: 4.3632\t finalize: 0.4132\nbatch bounding time:  3.58060622215271\nCurrent worst splitting domains lb-rhs (depth):\n-0.26939 (18), -0.26832 (18), -0.26400 (19), -0.26327 (19), -0.26019 (18), -0.25964 (18), -0.25881 (18), -0.25842 (20), -0.25834 (18), -0.25793 (20), -0.25731 (18), -0.25602 (19), -0.25579 (19), -0.25507 (18), -0.25496 (19), -0.25362 (19), -0.25348 (18), -0.25341 (21), -0.25311 (19), -0.25219 (19), \nlength of domains: 4305\nTotal time: 11.0034\t pickout: 0.0165\t decision: 1.6980\t get_bound: 3.5807\t add_domain: 5.7080\nAccumulated time:\t pickout: 0.3315\t decision: 23.3331\t get_bound: 62.0789\t add_domain: 12.8721\nCurrent (lb-rhs): -0.2693946361541748\n5942 domains visited\nCumulative time: 98.82125234603882\n\nbatch:  torch.Size([512, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([512, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [2, 4715] [2, 1250] [3, 219] [3, 104] [2, 7054] [2, 6330] [3, 104] [3, 84] [2, 1250] [3, 84] \n(1024, 3, 32, 32) torch.Size([1024, 1, 10]) torch.Size([1024, 1])\npruning_in_iteration open status: True\nratio of positive domain = 241 / 1024 = 0.2353515625\npruning-in-iteration extra time: 0.04825639724731445\nTensors transferred: pre=96.4883M lA=36.8898M alpha=5.3145M beta=0.0391M\nThis batch time : update_bounds func: 3.1912\t prepare: 0.0505\t bound: 2.9385\t transfer: 0.1864\t finalize: 0.0141\nAccumulated time: update_bounds func: 65.2447\t prepare: 1.3799\t bound: 58.8028\t transfer: 4.5497\t finalize: 0.4273\nbatch bounding time:  3.196626663208008\nCurrent worst splitting domains lb-rhs (depth):\n-0.26939 (18), -0.26832 (18), -0.26400 (19), -0.26327 (19), -0.26019 (18), -0.25964 (18), -0.25881 (18), -0.25842 (20), -0.25834 (18), -0.25793 (20), -0.25731 (18), -0.25602 (19), -0.25579 (19), -0.25507 (18), -0.25496 (19), -0.25362 (19), -0.25348 (18), -0.25341 (21), -0.25311 (19), -0.25219 (19), \nlength of domains: 4576\nTotal time: 5.1145\t pickout: 0.0304\t decision: 1.6434\t get_bound: 3.1968\t add_domain: 0.2440\nAccumulated time:\t pickout: 0.3619\t decision: 24.9765\t get_bound: 65.2757\t add_domain: 13.1161\nCurrent (lb-rhs): -0.2693946361541748\n6183 domains visited\nCumulative time: 103.94456934928894\n\nbatch:  torch.Size([512, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([512, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [2, 5518] [2, 3870] [3, 84] [2, 3889] [2, 3870] [2, 5518] [2, 3889] [2, 3870] [3, 104] [2, 3870] \n(1024, 3, 32, 32) torch.Size([1024, 1, 10]) torch.Size([1024, 1])\npruning_in_iteration open status: True\nratio of positive domain = 224 / 1024 = 0.21875\npruning-in-iteration extra time: 0.04944944381713867\nTensors transferred: pre=96.4883M lA=37.6907M alpha=5.3145M beta=0.0391M\nThis batch time : update_bounds func: 3.6244\t prepare: 0.0676\t bound: 3.0491\t transfer: 0.3763\t finalize: 0.0353\nAccumulated time: update_bounds func: 68.8691\t prepare: 1.4476\t bound: 61.8519\t transfer: 4.9260\t finalize: 0.4626\nbatch bounding time:  3.6331703662872314\nCurrent worst splitting domains lb-rhs (depth):\n-0.26939 (18), -0.26832 (18), -0.26400 (19), -0.26327 (19), -0.26019 (18), -0.25964 (18), -0.25881 (18), -0.25842 (20), -0.25834 (18), -0.25793 (20), -0.25731 (18), -0.25602 (19), -0.25579 (19), -0.25507 (18), -0.25496 (19), -0.25362 (19), -0.25348 (18), -0.25341 (21), -0.25311 (19), -0.25219 (19), \nlength of domains: 4864\nTotal time: 5.3178\t pickout: 0.0172\t decision: 1.2121\t get_bound: 3.6333\t add_domain: 0.4551\nAccumulated time:\t pickout: 0.3791\t decision: 26.1886\t get_bound: 68.9090\t add_domain: 13.5712\nCurrent (lb-rhs): -0.2693946361541748\n6407 domains visited\nCumulative time: 109.29492568969727\n\nbatch:  torch.Size([512, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([512, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [2, 4715] [2, 7054] [2, 7064] [2, 3931] [2, 4883] [3, 84] [3, 84] [2, 5518] [3, 84] [2, 5518] \n(1024, 3, 32, 32) torch.Size([1024, 1, 10]) torch.Size([1024, 1])\npruning_in_iteration open status: True\nratio of positive domain = 209 / 1024 = 0.2041015625\npruning-in-iteration extra time: 0.03501296043395996\nTensors transferred: pre=96.4883M lA=38.3974M alpha=5.3145M beta=0.0391M\nThis batch time : update_bounds func: 3.3042\t prepare: 0.0999\t bound: 3.0156\t transfer: 0.1670\t finalize: 0.0197\nAccumulated time: update_bounds func: 72.1733\t prepare: 1.5474\t bound: 64.8674\t transfer: 5.0930\t finalize: 0.4823\nbatch bounding time:  3.3081116676330566\nCurrent worst splitting domains lb-rhs (depth):\n-0.26939 (18), -0.26832 (18), -0.26400 (19), -0.26327 (19), -0.26019 (18), -0.25964 (18), -0.25881 (18), -0.25842 (20), -0.25834 (18), -0.25793 (20), -0.25731 (18), -0.25602 (19), -0.25579 (19), -0.25507 (18), -0.25496 (19), -0.25362 (19), -0.25348 (18), -0.25341 (21), -0.25311 (19), -0.25219 (19), \nlength of domains: 5167\nTotal time: 4.7012\t pickout: 0.0212\t decision: 1.0243\t get_bound: 3.3083\t add_domain: 0.3475\nAccumulated time:\t pickout: 0.4003\t decision: 27.2129\t get_bound: 72.2173\t add_domain: 13.9187\nCurrent (lb-rhs): -0.2693946361541748\n6616 domains visited\nCumulative time: 114.01805210113525\n\nbatch:  torch.Size([512, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([512, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [2, 5518] [3, 84] [2, 7064] [2, 3931] [2, 3931] [3, 73] [2, 6033] [2, 6330] [3, 84] [3, 84] \n(1024, 3, 32, 32) torch.Size([1024, 1, 10]) torch.Size([1024, 1])\n"
        },
        {
            "network": "cifar10_2_255_simplified",
            "property": "cifar10_spec_idx_27_eps_0.00784_n1",
            "timeout": "300",
            "verifier": "nnenum",
            "config": "Configuration(values={\n  'BRANCH_MODE': 0,\n  'COMPRESS_INIT_BOX': True,\n  'CONTRACT_LP_OPTIMIZED': True,\n  'CONTRACT_LP_TRACK_WITNESSES': True,\n  'CONTRACT_ZONOTOPE': False,\n  'CONTRACT_ZONOTOPE_LP': True,\n  'EAGER_BOUNDS': True,\n  'GLPK_FIRST_PRIMAL': True,\n  'GLPK_RESET_BEFORE_MINIMIZE': False,\n  'GLPK_TIMEOUT': 60,\n  'INF_OVERAPPROX_LP_TIMEOUT': False,\n  'INF_OVERAPPROX_MIN_GEN_LIMIT': False,\n  'OFFLOAD_CLOSEST_TO_ROOT': True,\n  'OVERAPPROX_BOTH_BOUNDS': False,\n  'OVERAPPROX_GEN_LIMIT_MULTIPLIER': 1.5,\n  'OVERAPPROX_LP_TIMEOUT': 1.0,\n  'OVERAPPROX_MIN_GEN_LIMIT': 50,\n  'OVERAPPROX_NEAR_ROOT_MAX_SPLITS': 2,\n  'SINGLE_SET': False,\n  'SKIP_COMPRESSED_CHECK': False,\n  'SKIP_CONSTRAINT_NORMALIZATION': False,\n  'SPLIT_IF_IDLE': True,\n  'SPLIT_ORDER': 1,\n  'SPLIT_TOLERANCE': 1e-08,\n  'TRY_QUICK_OVERAPPROX': True,\n})",
            "success": "OK",
            "result": "TIMEOUT",
            "took": "300",
            "stderr": "",
            "stdout": "Running in parallel with 12 processes\nOverapprox Round 1/3 has 1 set(s)\nLayer 1/7: LinearOnnxSubnetworkLayer (zono shape: (32768, 4509))... 1.29 sec\nLayer 2/7: ReluLayer (zono shape: (8192, 4509))... 0.552 sec\nLayer 3/7: LinearOnnxSubnetworkLayer (zono shape: (8192, 5191))... 0.825 sec\nLayer 4/7: ReluLayer (zono shape: (8192, 5191))... 0.697 sec\nLayer 5/7: LinearOnnxSubnetworkLayer (zono shape: (8192, 5762))... 1.199 sec\nLayer 6/7: ReluLayer (zono shape: (250, 5762))... 0.008 sec\nLayer 7/7: LinearOnnxSubnetworkLayer (zono shape: (250, 5820))... 0.063 sec\nOverapprox Round 2/3 has 3 set(s)\nLayer 1/7: LinearOnnxSubnetworkLayer (zono shape: (32768, 4509))... 3.674 sec\nLayer 2/7: ReluLayer (zono shape: (8192, 4509))... 1.479 sec\nLayer 3/7: LinearOnnxSubnetworkLayer (zono shape: (8192, 5189))... 2.567 sec\nLayer 4/7: ReluLayer (zono shape: (8192, 5189))... 1.934 sec\nLayer 5/7: LinearOnnxSubnetworkLayer (zono shape: (8192, 5759))... 3.517 sec\nLayer 6/7: ReluLayer (zono shape: (250, 5759))... 0.023 sec\nLayer 7/7: LinearOnnxSubnetworkLayer (zono shape: (250, 5817))... 0.257 sec\nOverapprox Round 3/3 has 4 set(s)\nLayer 1/7: LinearOnnxSubnetworkLayer (zono shape: (32768, 4509))... 7.306 sec\nLayer 2/7: ReluLayer (zono shape: (8192, 4509))...\nUsing LP to check 680/8192 potential ReLU splits... 8.279 sec\nLayer 3/7: LinearOnnxSubnetworkLayer (zono shape: (8192, 5174))... 3.59 sec\nLayer 4/7: ReluLayer (zono shape: (8192, 5174))...\nUsing LP to check 569/8192 potential ReLU splits... 17.779 sec\nLayer 5/7: LinearOnnxSubnetworkLayer (zono shape: (8192, 5715))... 5.067 sec\nLayer 6/7: ReluLayer (zono shape: (250, 5715))...\nUsing LP to check 57/250 potential ReLU splits... 41.989 sec\nLayer 7/7: LinearOnnxSubnetworkLayer (zono shape: (250, 5767))... 0.32 sec\n"
        },
        {
            "network": "cifar10_2_255_simplified",
            "property": "cifar10_spec_idx_36_eps_0.00784_n1",
            "timeout": "300",
            "verifier": "abcrown",
            "config": "Configuration(values={\n  'attack__attack_mode': 'PGD',\n  'attack__enable_mip_attack': False,\n  'attack__pgd_order': 'before',\n  'bab__branching__input_split__enable': False,\n  'bab__branching__method': 'kfsb',\n  'bab__branching__reduceop': 'min',\n  'general__complete_verifier': 'bab',\n  'general__enable_incomplete_verification': True,\n  'general__loss_reduction_func': 'sum',\n  'solver__bound_prop_method': 'alpha-crown',\n})",
            "success": "OK",
            "result": "SAT",
            "took": "11.231682300567627",
            "stderr": "",
            "stdout": "/bin/bash: /home/tristan/miniconda3/envs/__av__abcrown/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nConfigurations:\n\ngeneral:\n  device: cuda\n  seed: 100\n  conv_mode: patches\n  deterministic: false\n  double_fp: false\n  loss_reduction_func: sum\n  record_bounds: false\n  sparse_alpha: true\n  save_adv_example: true\n  precompile_jit: false\n  complete_verifier: bab\n  enable_incomplete_verification: true\n  csv_name: null\n  results_file: /tmp/tmp_x28xand.txt\n  root_path: ''\nmodel:\n  name: null\n  path: null\n  onnx_path: /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/cifar10_2_255_simplified.onnx\n  onnx_path_prefix: ''\n  cache_onnx_conversion: false\n  onnx_quirks: null\n  input_shape: null\n  onnx_loader: default_onnx_and_vnnlib_loader\n  onnx_optimization_flags: none\ndata:\n  start: 0\n  end: 10000\n  select_instance: null\n  num_outputs: 10\n  mean: 0.0\n  std: 1.0\n  pkl_path: null\n  dataset: CIFAR\n  data_filter_path: null\n  data_idx_file: null\nspecification:\n  type: lp\n  robustness_type: verified-acc\n  norm: .inf\n  epsilon: null\n  vnnlib_path: /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_36_eps_0.00784_n1.vnnlib\n  vnnlib_path_prefix: ''\nsolver:\n  batch_size: 512\n  min_batch_size_ratio: 0.1\n  use_float64_in_last_iteration: false\n  early_stop_patience: 10\n  start_save_best: 0.5\n  bound_prop_method: alpha-crown\n  prune_after_crown: false\n  crown:\n    batch_size: 1000000000\n    max_crown_size: 1000000000\n  alpha-crown:\n    alpha: true\n    lr_alpha: 0.1\n    iteration: 100\n    share_slopes: false\n    no_joint_opt: false\n    lr_decay: 0.98\n    full_conv_alpha: true\n  beta-crown:\n    lr_alpha: 0.01\n    lr_beta: 0.05\n    lr_decay: 0.98\n    optimizer: adam\n    iteration: 50\n    beta: true\n    beta_warmup: true\n    enable_opt_interm_bounds: false\n    all_node_split_LP: false\n  forward:\n    refine: false\n    dynamic: false\n    max_dim: 10000\n  multi_class:\n    multi_class_method: allclass_domain\n    label_batch_size: 32\n    skip_with_refined_bound: true\n  mip:\n    parallel_solvers: null\n    solver_threads: 1\n    refine_neuron_timeout: 15\n    refine_neuron_time_percentage: 0.8\n    early_stop: true\n    adv_warmup: true\n    mip_solver: gurobi\nbab:\n  initial_max_domains: 1\n  max_domains: .inf\n  decision_thresh: 0\n  timeout: 300.0\n  timeout_scale: 1\n  override_timeout: null\n  get_upper_bound: false\n  dfs_percent: 0.0\n  pruning_in_iteration: true\n  pruning_in_iteration_ratio: 0.2\n  sort_targets: false\n  batched_domain_list: true\n  optimized_intermediate_layers: ''\n  interm_transfer: true\n  cut:\n    enabled: false\n    bab_cut: false\n    lp_cut: false\n    method: null\n    lr: 0.01\n    lr_decay: 1.0\n    iteration: 100\n    bab_iteration: -1\n    early_stop_patience: -1\n    lr_beta: 0.02\n    number_cuts: 50\n    topk_cuts_in_filter: 100\n    batch_size_primal: 100\n    max_num: 1000000000\n    patches_cut: false\n    cplex_cuts: false\n    cplex_cuts_wait: 0\n    cplex_cuts_revpickup: true\n    cut_reference_bounds: true\n    fix_intermediate_bounds: false\n  branching:\n    method: kfsb\n    candidates: 3\n    reduceop: min\n    sb_coeff_thresh: 0.001\n    input_split:\n      enable: false\n      enhanced_bound_prop_method: alpha-crown\n      enhanced_branching_method: naive\n      enhanced_bound_patience: 100000000.0\n      attack_patience: 100000000.0\n      adv_check: 0\n      sort_domain_interval: -1\n  attack:\n    enabled: false\n    beam_candidates: 8\n    beam_depth: 7\n    max_dive_fix_ratio: 0.8\n    min_local_free_ratio: 0.2\n    mip_start_iteration: 5\n    mip_timeout: 30.0\n    adv_pool_threshold: null\n    refined_mip_attacker: false\n    refined_batch_size: null\nattack:\n  pgd_order: before\n  pgd_steps: 100\n  pgd_restarts: 30\n  pgd_early_stop: true\n  pgd_lr_decay: 0.99\n  pgd_alpha: auto\n  pgd_loss_mode: null\n  enable_mip_attack: false\n  cex_path: ./test_cex.txt\n  attack_mode: PGD\n  gama_lambda: 10.0\n  gama_decay: 0.9\n  check_clean: false\n  input_split:\n    pgd_steps: 100\n    pgd_restarts: 30\n    pgd_alpha: auto\n  input_split_enhanced:\n    pgd_steps: 200\n    pgd_restarts: 5000000\n    pgd_alpha: auto\n  input_split_check_adv:\n    pgd_steps: 5\n    pgd_restarts: 5\n    pgd_alpha: auto\ndebug:\n  lp_test: null\n\nExperiments at Mon May 13 21:13:17 2024 on Cerberus\nInternal results will be saved to /tmp/tmp_x28xand.txt.\n\n %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nUsing onnx /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/cifar10_2_255_simplified.onnx\nUsing vnnlib /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_36_eps_0.00784_n1.vnnlib\nPrecompiled vnnlib file found at /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_36_eps_0.00784_n1.vnnlib.compiled\nLoading onnx /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/cifar10_2_255_simplified.onnx wih quirks {}\n/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/onnx2pytorch/convert/layer.py:30: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_numpy.cpp:178.)\n  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))\n/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/onnx2pytorch/convert/model.py:154: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.\n  \"Using experimental implementation that allows 'batch_size > 1'.\"\nAttack parameters: initialization=uniform, steps=100, restarts=30, alpha=0.0098334401845932, initialization=uniform, GAMA=False\nModel output of first 5 examples:\n tensor([[-1.96812832, -6.49893856,  1.24639082,  1.69520974,  4.02628088,\n          2.75464153,  2.39966416,  3.83796740, -4.41950607, -2.72571588]],\n       device='cuda:0')\nAdv example prediction (first 2 examples and 2 restarts):\n tensor([[[-2.01335669, -6.61650658,  1.13246620,  1.72124791,  3.89798760,\n           2.86626458,  2.36144567,  4.41441536, -4.41264629, -2.79052591],\n         [-2.01335669, -6.61650658,  1.13246620,  1.72124791,  3.89798760,\n           2.86626458,  2.36144567,  4.41441536, -4.41264629, -2.79052591]]],\n       device='cuda:0')\nPGD attack margin (first 2 examles and 10 specs):\n tensor([[[ 5.91134453, 10.51449394,  2.76552153,  2.17673969,  1.03172302,\n           1.53654194, -0.51642776,  8.31063366,  6.68851376]]],\n       device='cuda:0')\nnumber of violation:  1\nAttack finished in 2.9129 seconds.\nPGD attack succeeded!\nResult: sat\nTime: 7.910510540008545\n"
        },
        {
            "network": "cifar10_2_255_simplified",
            "property": "cifar10_spec_idx_44_eps_0.00784_n1",
            "timeout": "300",
            "verifier": "nnenum",
            "config": "Configuration(values={\n  'BRANCH_MODE': 0,\n  'COMPRESS_INIT_BOX': True,\n  'CONTRACT_LP_OPTIMIZED': True,\n  'CONTRACT_LP_TRACK_WITNESSES': True,\n  'CONTRACT_ZONOTOPE': False,\n  'CONTRACT_ZONOTOPE_LP': True,\n  'EAGER_BOUNDS': True,\n  'GLPK_FIRST_PRIMAL': True,\n  'GLPK_RESET_BEFORE_MINIMIZE': False,\n  'GLPK_TIMEOUT': 60,\n  'INF_OVERAPPROX_LP_TIMEOUT': False,\n  'INF_OVERAPPROX_MIN_GEN_LIMIT': False,\n  'OFFLOAD_CLOSEST_TO_ROOT': True,\n  'OVERAPPROX_BOTH_BOUNDS': False,\n  'OVERAPPROX_GEN_LIMIT_MULTIPLIER': 1.5,\n  'OVERAPPROX_LP_TIMEOUT': 1.0,\n  'OVERAPPROX_MIN_GEN_LIMIT': 50,\n  'OVERAPPROX_NEAR_ROOT_MAX_SPLITS': 2,\n  'SINGLE_SET': False,\n  'SKIP_COMPRESSED_CHECK': False,\n  'SKIP_CONSTRAINT_NORMALIZATION': False,\n  'SPLIT_IF_IDLE': True,\n  'SPLIT_ORDER': 1,\n  'SPLIT_TOLERANCE': 1e-08,\n  'TRY_QUICK_OVERAPPROX': True,\n})",
            "success": "OK",
            "result": "UNSAT",
            "took": "8.810494899749756",
            "stderr": "",
            "stdout": "Running in parallel with 12 processes\nOverapprox Round 1/3 has 1 set(s)\nLayer 1/7: LinearOnnxSubnetworkLayer (zono shape: (32768, 4058))... 1.132 sec\nLayer 2/7: ReluLayer (zono shape: (8192, 4058))... 0.568 sec\nLayer 3/7: LinearOnnxSubnetworkLayer (zono shape: (8192, 4494))... 0.737 sec\nLayer 4/7: ReluLayer (zono shape: (8192, 4494))... 0.616 sec\nLayer 5/7: LinearOnnxSubnetworkLayer (zono shape: (8192, 4916))... 1.113 sec\nLayer 6/7: ReluLayer (zono shape: (250, 4916))... 0.006 sec\nLayer 7/7: LinearOnnxSubnetworkLayer (zono shape: (250, 4948))... 0.06 sec\n\n\n\nTotal Stars: 1 (0 exact, 1 approx)\nRuntime: 7.8 sec\nCompleted work frac: 1.0\nNum Stars Copied Between Processes: 0\nNum Lps During Enumeration: 0\nTotal Num Lps: 0\n\nResult: network is SAFE\n"
        },
        {
            "network": "cifar10_2_255_simplified",
            "property": "cifar10_spec_idx_55_eps_0.00784_n1",
            "timeout": "300",
            "verifier": "nnenum",
            "config": "Configuration(values={\n  'BRANCH_MODE': 0,\n  'COMPRESS_INIT_BOX': True,\n  'CONTRACT_LP_OPTIMIZED': True,\n  'CONTRACT_LP_TRACK_WITNESSES': True,\n  'CONTRACT_ZONOTOPE': False,\n  'CONTRACT_ZONOTOPE_LP': True,\n  'EAGER_BOUNDS': True,\n  'GLPK_FIRST_PRIMAL': True,\n  'GLPK_RESET_BEFORE_MINIMIZE': False,\n  'GLPK_TIMEOUT': 60,\n  'INF_OVERAPPROX_LP_TIMEOUT': False,\n  'INF_OVERAPPROX_MIN_GEN_LIMIT': False,\n  'OFFLOAD_CLOSEST_TO_ROOT': True,\n  'OVERAPPROX_BOTH_BOUNDS': False,\n  'OVERAPPROX_GEN_LIMIT_MULTIPLIER': 1.5,\n  'OVERAPPROX_LP_TIMEOUT': 1.0,\n  'OVERAPPROX_MIN_GEN_LIMIT': 50,\n  'OVERAPPROX_NEAR_ROOT_MAX_SPLITS': 2,\n  'SINGLE_SET': False,\n  'SKIP_COMPRESSED_CHECK': False,\n  'SKIP_CONSTRAINT_NORMALIZATION': False,\n  'SPLIT_IF_IDLE': True,\n  'SPLIT_ORDER': 1,\n  'SPLIT_TOLERANCE': 1e-08,\n  'TRY_QUICK_OVERAPPROX': True,\n})",
            "success": "OK",
            "result": "UNSAT",
            "took": "9.034502506256104",
            "stderr": "",
            "stdout": "Running in parallel with 12 processes\nOverapprox Round 1/3 has 1 set(s)\nLayer 1/7: LinearOnnxSubnetworkLayer (zono shape: (32768, 4030))... 1.175 sec\nLayer 2/7: ReluLayer (zono shape: (8192, 4030))... 0.542 sec\nLayer 3/7: LinearOnnxSubnetworkLayer (zono shape: (8192, 4535))... 0.761 sec\nLayer 4/7: ReluLayer (zono shape: (8192, 4535))... 0.688 sec\nLayer 5/7: LinearOnnxSubnetworkLayer (zono shape: (8192, 4966))... 1.191 sec\nLayer 6/7: ReluLayer (zono shape: (250, 4966))... 0.008 sec\nLayer 7/7: LinearOnnxSubnetworkLayer (zono shape: (250, 5025))... 0.064 sec\n\n\n\nTotal Stars: 1 (0 exact, 1 approx)\nRuntime: 8.1 sec\nCompleted work frac: 1.0\nNum Stars Copied Between Processes: 0\nNum Lps During Enumeration: 0\nTotal Num Lps: 0\n\nResult: network is SAFE\n"
        },
        {
            "network": "cifar10_2_255_simplified",
            "property": "cifar10_spec_idx_71_eps_0.00784_n1",
            "timeout": "300",
            "verifier": "abcrown",
            "config": "Configuration(values={\n  'attack__attack_mode': 'PGD',\n  'attack__enable_mip_attack': False,\n  'attack__pgd_order': 'before',\n  'bab__branching__input_split__enable': False,\n  'bab__branching__method': 'kfsb',\n  'bab__branching__reduceop': 'min',\n  'general__complete_verifier': 'bab',\n  'general__enable_incomplete_verification': True,\n  'general__loss_reduction_func': 'sum',\n  'solver__bound_prop_method': 'alpha-crown',\n})",
            "success": "OK",
            "result": "UNSAT",
            "took": "23.46356725692749",
            "stderr": "",
            "stdout": "/bin/bash: /home/tristan/miniconda3/envs/__av__abcrown/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nConfigurations:\n\ngeneral:\n  device: cuda\n  seed: 100\n  conv_mode: patches\n  deterministic: false\n  double_fp: false\n  loss_reduction_func: sum\n  record_bounds: false\n  sparse_alpha: true\n  save_adv_example: true\n  precompile_jit: false\n  complete_verifier: bab\n  enable_incomplete_verification: true\n  csv_name: null\n  results_file: /tmp/tmpukynwrcz.txt\n  root_path: ''\nmodel:\n  name: null\n  path: null\n  onnx_path: /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/cifar10_2_255_simplified.onnx\n  onnx_path_prefix: ''\n  cache_onnx_conversion: false\n  onnx_quirks: null\n  input_shape: null\n  onnx_loader: default_onnx_and_vnnlib_loader\n  onnx_optimization_flags: none\ndata:\n  start: 0\n  end: 10000\n  select_instance: null\n  num_outputs: 10\n  mean: 0.0\n  std: 1.0\n  pkl_path: null\n  dataset: CIFAR\n  data_filter_path: null\n  data_idx_file: null\nspecification:\n  type: lp\n  robustness_type: verified-acc\n  norm: .inf\n  epsilon: null\n  vnnlib_path: /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_71_eps_0.00784_n1.vnnlib\n  vnnlib_path_prefix: ''\nsolver:\n  batch_size: 512\n  min_batch_size_ratio: 0.1\n  use_float64_in_last_iteration: false\n  early_stop_patience: 10\n  start_save_best: 0.5\n  bound_prop_method: alpha-crown\n  prune_after_crown: false\n  crown:\n    batch_size: 1000000000\n    max_crown_size: 1000000000\n  alpha-crown:\n    alpha: true\n    lr_alpha: 0.1\n    iteration: 100\n    share_slopes: false\n    no_joint_opt: false\n    lr_decay: 0.98\n    full_conv_alpha: true\n  beta-crown:\n    lr_alpha: 0.01\n    lr_beta: 0.05\n    lr_decay: 0.98\n    optimizer: adam\n    iteration: 50\n    beta: true\n    beta_warmup: true\n    enable_opt_interm_bounds: false\n    all_node_split_LP: false\n  forward:\n    refine: false\n    dynamic: false\n    max_dim: 10000\n  multi_class:\n    multi_class_method: allclass_domain\n    label_batch_size: 32\n    skip_with_refined_bound: true\n  mip:\n    parallel_solvers: null\n    solver_threads: 1\n    refine_neuron_timeout: 15\n    refine_neuron_time_percentage: 0.8\n    early_stop: true\n    adv_warmup: true\n    mip_solver: gurobi\nbab:\n  initial_max_domains: 1\n  max_domains: .inf\n  decision_thresh: 0\n  timeout: 300.0\n  timeout_scale: 1\n  override_timeout: null\n  get_upper_bound: false\n  dfs_percent: 0.0\n  pruning_in_iteration: true\n  pruning_in_iteration_ratio: 0.2\n  sort_targets: false\n  batched_domain_list: true\n  optimized_intermediate_layers: ''\n  interm_transfer: true\n  cut:\n    enabled: false\n    bab_cut: false\n    lp_cut: false\n    method: null\n    lr: 0.01\n    lr_decay: 1.0\n    iteration: 100\n    bab_iteration: -1\n    early_stop_patience: -1\n    lr_beta: 0.02\n    number_cuts: 50\n    topk_cuts_in_filter: 100\n    batch_size_primal: 100\n    max_num: 1000000000\n    patches_cut: false\n    cplex_cuts: false\n    cplex_cuts_wait: 0\n    cplex_cuts_revpickup: true\n    cut_reference_bounds: true\n    fix_intermediate_bounds: false\n  branching:\n    method: kfsb\n    candidates: 3\n    reduceop: min\n    sb_coeff_thresh: 0.001\n    input_split:\n      enable: false\n      enhanced_bound_prop_method: alpha-crown\n      enhanced_branching_method: naive\n      enhanced_bound_patience: 100000000.0\n      attack_patience: 100000000.0\n      adv_check: 0\n      sort_domain_interval: -1\n  attack:\n    enabled: false\n    beam_candidates: 8\n    beam_depth: 7\n    max_dive_fix_ratio: 0.8\n    min_local_free_ratio: 0.2\n    mip_start_iteration: 5\n    mip_timeout: 30.0\n    adv_pool_threshold: null\n    refined_mip_attacker: false\n    refined_batch_size: null\nattack:\n  pgd_order: before\n  pgd_steps: 100\n  pgd_restarts: 30\n  pgd_early_stop: true\n  pgd_lr_decay: 0.99\n  pgd_alpha: auto\n  pgd_loss_mode: null\n  enable_mip_attack: false\n  cex_path: ./test_cex.txt\n  attack_mode: PGD\n  gama_lambda: 10.0\n  gama_decay: 0.9\n  check_clean: false\n  input_split:\n    pgd_steps: 100\n    pgd_restarts: 30\n    pgd_alpha: auto\n  input_split_enhanced:\n    pgd_steps: 200\n    pgd_restarts: 5000000\n    pgd_alpha: auto\n  input_split_check_adv:\n    pgd_steps: 5\n    pgd_restarts: 5\n    pgd_alpha: auto\ndebug:\n  lp_test: null\n\nExperiments at Mon May 13 21:13:48 2024 on Cerberus\nInternal results will be saved to /tmp/tmpukynwrcz.txt.\n\n %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nUsing onnx /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/cifar10_2_255_simplified.onnx\nUsing vnnlib /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_71_eps_0.00784_n1.vnnlib\nPrecompiled vnnlib file found at /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_71_eps_0.00784_n1.vnnlib.compiled\nLoading onnx /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/cifar10_2_255_simplified.onnx wih quirks {}\n/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/onnx2pytorch/convert/layer.py:30: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_numpy.cpp:178.)\n  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))\n/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/onnx2pytorch/convert/model.py:154: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.\n  \"Using experimental implementation that allows 'batch_size > 1'.\"\nAttack parameters: initialization=uniform, steps=100, restarts=30, alpha=0.0098334401845932, initialization=uniform, GAMA=False\nModel output of first 5 examples:\n tensor([[-2.00457525, -1.67054403,  0.72028756,  2.41133142,  1.22753203,\n          1.47416234,  3.83728242,  0.14393537, -3.74496412, -0.80569816]],\n       device='cuda:0')\nAdv example prediction (first 2 examples and 2 restarts):\n tensor([[[-1.91160369, -1.75271857,  0.69264895,  2.51886392,  1.29905379,\n           1.52446699,  3.16162252,  0.31408176, -3.63012004, -0.84955752],\n         [-1.91160369, -1.75271857,  0.69264895,  2.51886392,  1.29905379,\n           1.52446699,  3.16162252,  0.31408176, -3.63012004, -0.84955752]]],\n       device='cuda:0')\nPGD attack margin (first 2 examles and 10 specs):\n tensor([[[5.07322598, 4.91434097, 2.46897364, 0.64275861, 1.86256874,\n          1.63715553, 2.84754086, 6.79174232, 4.01117992]]], device='cuda:0')\nnumber of violation:  0\nAttack finished in 1.9566 seconds.\nPGD attack failed\nModel prediction is: tensor([[-2.00457525, -1.67054403,  0.72028756,  2.41133142,  1.22753203,\n          1.47416234,  3.83728242,  0.14393537, -3.74496412, -0.80569816]],\n       device='cuda:0')\nlayer /22 using sparse-features alpha with shape [1915]; unstable size 1915; total size 32768 (torch.Size([1, 32, 32, 32]))\nlayer /22 start_node /input.4 using full alpha with unstable size 32 total_size 32 output_shape 32\nlayer /22 start_node /input.8 using sparse-spec alpha with unstable size 111 total_size 128 output_shape 128\nlayer /22 start_node /input.12 using sparse-spec alpha with unstable size 67 total_size 250 output_shape torch.Size([250])\nlayer /22 start_node /30 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /24 using sparse-features alpha with shape [772]; unstable size 772; total size 8192 (torch.Size([1, 32, 16, 16]))\nlayer /24 start_node /input.8 using sparse-spec alpha with unstable size 111 total_size 128 output_shape 128\nlayer /24 start_node /input.12 using sparse-spec alpha with unstable size 67 total_size 250 output_shape torch.Size([250])\nlayer /24 start_node /30 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /26 using sparse-features alpha with shape [630]; unstable size 630; total size 8192 (torch.Size([1, 128, 8, 8]))\nlayer /26 start_node /input.12 using sparse-spec alpha with unstable size 67 total_size 250 output_shape torch.Size([250])\nlayer /26 start_node /30 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /29 using sparse-features alpha with shape [67]; unstable size 67; total size 250 (torch.Size([1, 250]))\nlayer /29 start_node /30 using full alpha with unstable size None total_size 9 output_shape 9\nOptimizable variables initialized.\ninitial CROWN bounds: tensor([[ 2.80871940,  2.45961523,  0.37849665, -0.61176729,  0.52175808,\n          0.03984809,  0.67119026,  4.57306957,  1.52069569]], device='cuda:0') None\nbest_l after optimization: 14.235381126403809 with beta sum per layer: []\nalpha/beta optimization time: 8.5503568649292\ninitial alpha-CROWN bounds: tensor([[ 3.03656101,  2.69559598,  0.59893465, -0.46514297,  0.67544174,\n          0.21066689,  0.89655781,  4.81512547,  1.77164078]], device='cuda:0')\nWorst class: (+ rhs) -0.46514296531677246\nTotal VNNLIB file length: 9, max property batch size: 1, total number of batches: 9\nlA shape: [torch.Size([1, 9, 32, 32, 32]), torch.Size([1, 9, 32, 16, 16]), torch.Size([1, 9, 128, 8, 8]), torch.Size([1, 9, 250])]\n\nProperties batch 0, size 1\nRemaining timeout: 284.8770594596863\n##### Instance 0 first 10 spec matrices: [[[-1.  0.  0.  0.  0.  0.  1.  0.  0.  0.]]]\nthresholds: [0.] ######\nInitial alpha-CROWN verified for spec index [0] with bound 3.0365610122680664.\n\nProperties batch 1, size 1\nRemaining timeout: 284.8184304237366\n##### Instance 0 first 10 spec matrices: [[[ 0. -1.  0.  0.  0.  0.  1.  0.  0.  0.]]]\nthresholds: [0.] ######\nInitial alpha-CROWN verified for spec index [0] with bound 2.6955959796905518.\n\nProperties batch 2, size 1\nRemaining timeout: 284.7665309906006\n##### Instance 0 first 10 spec matrices: [[[ 0.  0. -1.  0.  0.  0.  1.  0.  0.  0.]]]\nthresholds: [0.] ######\nInitial alpha-CROWN verified for spec index [0] with bound 0.5989346504211426.\n\nProperties batch 3, size 1\nRemaining timeout: 284.71837973594666\n##### Instance 0 first 10 spec matrices: [[[ 0.  0.  0. -1.  0.  0.  1.  0.  0.  0.]]]\nthresholds: [0.] ######\nRemaining spec index [0] with bounds tensor([[-0.46514297]], device='cuda:0') need to verify.\nModel prediction is: tensor([-2.00457525, -1.67054403,  0.72028756,  2.41133142,  1.22753203,\n         1.47416234,  3.83728242,  0.14393537, -3.74496412, -0.80569816],\n       device='cuda:0')\nbuild_the_model_with_refined_bounds batch [0/1]\nsetting alpha for layer /22 start_node /30 with alignment adjustment\nsetting alpha for layer /24 start_node /30 with alignment adjustment\nsetting alpha for layer /26 start_node /30 with alignment adjustment\nsetting alpha for layer /29 start_node /30 with alignment adjustment\nall slope initialized\ndirectly get lb and ub from refined bounds\nlA shapes: [torch.Size([1, 1, 32, 32, 32]), torch.Size([1, 1, 32, 16, 16]), torch.Size([1, 1, 128, 8, 8]), torch.Size([1, 1, 250])]\nc shape: torch.Size([1, 1, 10])\nalpha-CROWN with fixed intermediate bounds: tensor([[-0.46514297]], device='cuda:0') tensor([[inf]], device='cuda:0')\nKeeping slopes for these layers: ['/30']\nKeeping slopes for these layers: ['/30']\nlayer 0 size torch.Size([32768]) unstable 1915\nlayer 1 size torch.Size([8192]) unstable 749\nlayer 2 size torch.Size([8192]) unstable 614\nlayer 3 size torch.Size([250]) unstable 63\n-----------------\n# of unstable neurons: 3341\n-----------------\n\nbatch:  torch.Size([1, 32, 32, 32]) pre split depth:  5\nbatch:  torch.Size([1, 32, 32, 32]) post split depth:  5\nsplitting decisions: \nsplit level 0: [3, 189] \nsplit level 1: [3, 236] \nsplit level 2: [3, 76] \nsplit level 3: [3, 238] \nsplit level 4: [3, 44] \n(32, 3, 32, 32) torch.Size([32, 1, 10]) torch.Size([32, 1])\npruning_in_iteration open status: True\nratio of positive domain = 7 / 32 = 0.21875\npruning-in-iteration extra time: 0.032843589782714844\nTensors transferred: pre=3.0153M lA=1.1778M alpha=0.2065M beta=0.0002M\nThis batch time : update_bounds func: 1.4507\t prepare: 0.0047\t bound: 1.4386\t transfer: 0.0061\t finalize: 0.0012\nAccumulated time: update_bounds func: 1.4507\t prepare: 0.0047\t bound: 1.4386\t transfer: 0.0061\t finalize: 0.0012\nbatch bounding time:  1.450939655303955\nCurrent worst splitting domains lb-rhs (depth):\n-0.14887 (5), -0.14311 (5), -0.13851 (5), -0.13621 (5), -0.10090 (5), -0.09864 (5), -0.09558 (5), -0.09537 (5), -0.09237 (5), -0.09080 (5), -0.08998 (5), -0.08598 (5), -0.06068 (5), -0.05457 (5), -0.05413 (5), -0.05390 (5), -0.05302 (5), -0.04999 (5), -0.04704 (5), -0.04550 (5), \nlength of domains: 25\nTotal time: 1.8827\t pickout: 0.0018\t decision: 0.4157\t get_bound: 1.4579\t add_domain: 0.0074\nAccumulated time:\t pickout: 0.0018\t decision: 0.4157\t get_bound: 1.4579\t add_domain: 0.0074\nCurrent (lb-rhs): -0.14886927604675293\n7 domains visited\nCumulative time: 2.1341447830200195\n\nbatch:  torch.Size([25, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([25, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [3, 40] [3, 40] [3, 40] [3, 40] [3, 40] [3, 40] [3, 40] [3, 40] [3, 40] [3, 40] \n(50, 3, 32, 32) torch.Size([50, 1, 10]) torch.Size([50, 1])\npruning_in_iteration open status: False\nratio of positive domain = 10 / 50 = 0.19999999999999996\npruning-in-iteration extra time: 0.00020837783813476562\nTensors transferred: pre=4.7113M lA=2.3557M alpha=0.3227M beta=0.0003M\nThis batch time : update_bounds func: 0.8182\t prepare: 0.0027\t bound: 0.8090\t transfer: 0.0051\t finalize: 0.0012\nAccumulated time: update_bounds func: 2.2689\t prepare: 0.0074\t bound: 2.2477\t transfer: 0.0112\t finalize: 0.0024\nbatch bounding time:  0.8182423114776611\nCurrent worst splitting domains lb-rhs (depth):\n-0.11342 (6), -0.10721 (6), -0.10490 (6), -0.10249 (6), -0.10028 (6), -0.09935 (6), -0.09675 (6), -0.09581 (6), -0.06432 (6), -0.06324 (6), -0.06069 (6), -0.05826 (6), -0.05811 (6), -0.05549 (6), -0.05466 (6), -0.05458 (6), -0.05426 (6), -0.05199 (6), -0.05098 (6), -0.05045 (6), \nlength of domains: 40\nTotal time: 0.8743\t pickout: 0.0018\t decision: 0.0448\t get_bound: 0.8183\t add_domain: 0.0094\nAccumulated time:\t pickout: 0.0035\t decision: 0.4606\t get_bound: 2.2762\t add_domain: 0.0168\nCurrent (lb-rhs): -0.11342120170593262\n17 domains visited\nCumulative time: 3.00901198387146\n\nbatch:  torch.Size([40, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([40, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [3, 86] [3, 119] [3, 119] [3, 119] [3, 86] [3, 86] [3, 119] [3, 119] [3, 86] [3, 119] \n(80, 3, 32, 32) torch.Size([80, 1, 10]) torch.Size([80, 1])\npruning_in_iteration open status: True\nratio of positive domain = 40 / 80 = 0.5\npruning-in-iteration extra time: 0.048748016357421875\nTensors transferred: pre=7.5381M lA=1.8845M alpha=0.5164M beta=0.0005M\nThis batch time : update_bounds func: 0.9020\t prepare: 0.0070\t bound: 0.8855\t transfer: 0.0083\t finalize: 0.0009\nAccumulated time: update_bounds func: 3.1709\t prepare: 0.0145\t bound: 3.1332\t transfer: 0.0195\t finalize: 0.0034\nbatch bounding time:  0.9021158218383789\nCurrent worst splitting domains lb-rhs (depth):\n-0.07957 (7), -0.07407 (7), -0.07299 (7), -0.07111 (7), -0.06887 (7), -0.06856 (7), -0.06591 (7), -0.06535 (7), -0.06301 (7), -0.06225 (7), -0.06194 (7), -0.03045 (7), -0.02705 (7), -0.02641 (7), -0.02465 (7), -0.02439 (7), -0.02411 (7), -0.02389 (7), -0.02070 (7), -0.01987 (7), \nlength of domains: 40\nTotal time: 0.9744\t pickout: 0.0022\t decision: 0.0644\t get_bound: 0.9022\t add_domain: 0.0055\nAccumulated time:\t pickout: 0.0058\t decision: 0.5250\t get_bound: 3.1784\t add_domain: 0.0223\nCurrent (lb-rhs): -0.07957196235656738\n57 domains visited\nCumulative time: 3.9838180541992188\n\nbatch:  torch.Size([40, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([40, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [3, 119] [3, 86] [3, 86] [3, 86] [3, 119] [3, 86] [3, 86] [3, 86] [3, 86] [3, 119] \n(80, 3, 32, 32) torch.Size([80, 1, 10]) torch.Size([80, 1])\npruning_in_iteration open status: True\nratio of positive domain = 64 / 80 = 0.8\npruning-in-iteration extra time: 0.047211408615112305\nTensors transferred: pre=7.5381M lA=0.7538M alpha=0.5164M beta=0.0006M\nThis batch time : update_bounds func: 0.8432\t prepare: 0.0071\t bound: 0.8209\t transfer: 0.0133\t finalize: 0.0018\nAccumulated time: update_bounds func: 4.0141\t prepare: 0.0216\t bound: 3.9541\t transfer: 0.0327\t finalize: 0.0052\nbatch bounding time:  0.843334436416626\nCurrent worst splitting domains lb-rhs (depth):\n-0.04667 (8), -0.04101 (8), -0.03977 (8), -0.03795 (8), -0.03642 (8), -0.03548 (8), -0.03271 (8), -0.03257 (8), -0.03241 (8), -0.03021 (8), -0.02907 (8), -0.02898 (8), -0.02764 (8), -0.02535 (8), -0.02335 (8), -0.02225 (8), \nlength of domains: 16\nTotal time: 0.8952\t pickout: 0.0020\t decision: 0.0453\t get_bound: 0.8434\t add_domain: 0.0044\nAccumulated time:\t pickout: 0.0078\t decision: 0.5703\t get_bound: 4.0218\t add_domain: 0.0267\nCurrent (lb-rhs): -0.04667329788208008\n121 domains visited\nCumulative time: 4.879569053649902\n\nbatch:  torch.Size([16, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([16, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [3, 186] [3, 186] [3, 186] [3, 186] [3, 186] [3, 186] [3, 186] [3, 186] [3, 186] [3, 186] \n(32, 3, 32, 32) torch.Size([32, 1, 10]) torch.Size([32, 1])\npruning_in_iteration open status: True\nratio of positive domain = 21 / 32 = 0.65625\npruning-in-iteration extra time: 0.04961991310119629\nTensors transferred: pre=3.0153M lA=0.5182M alpha=0.2065M beta=0.0003M\nThis batch time : update_bounds func: 0.8943\t prepare: 0.0037\t bound: 0.8831\t transfer: 0.0065\t finalize: 0.0010\nAccumulated time: update_bounds func: 4.9084\t prepare: 0.0253\t bound: 4.8372\t transfer: 0.0392\t finalize: 0.0061\nbatch bounding time:  0.8944425582885742\nCurrent worst splitting domains lb-rhs (depth):\n-0.01575 (9), -0.01069 (9), -0.00833 (9), -0.00693 (9), -0.00548 (9), -0.00480 (9), -0.00447 (9), -0.00222 (9), -0.00112 (9), -0.00060 (9), -0.00032 (9), \nlength of domains: 11\nTotal time: 0.9318\t pickout: 0.0014\t decision: 0.0318\t get_bound: 0.8945\t add_domain: 0.0041\nAccumulated time:\t pickout: 0.0092\t decision: 0.6021\t get_bound: 4.9164\t add_domain: 0.0308\nCurrent (lb-rhs): -0.015746116638183594\n142 domains visited\nCumulative time: 5.811811923980713\n\nbatch:  torch.Size([11, 32, 32, 32]) pre split depth:  2\nbatch:  torch.Size([11, 32, 32, 32]) post split depth:  2\nsplitting decisions: \nsplit level 0: [3, 91] [3, 91] [3, 91] [3, 91] [3, 91] [3, 91] [3, 91] [3, 91] [3, 91] [3, 91] \nsplit level 1: [3, 207] [3, 207] [3, 207] [3, 207] [3, 179] [3, 207] [3, 207] [3, 207] [3, 207] [3, 207] \n(44, 3, 32, 32) torch.Size([44, 1, 10]) torch.Size([44, 1])\n\nall verified at 0th iter\npruning_in_iteration open status: False\nratio of positive domain = 44 / 44 = 1.0\npruning-in-iteration extra time: 0.00017905235290527344\nTensors transferred: pre=4.1460M lA=2.0730M alpha=0.2840M beta=0.0005M\nThis batch time : update_bounds func: 0.0225\t prepare: 0.0048\t bound: 0.0085\t transfer: 0.0070\t finalize: 0.0021\nAccumulated time: update_bounds func: 4.9309\t prepare: 0.0301\t bound: 4.8457\t transfer: 0.0463\t finalize: 0.0082\nbatch bounding time:  0.02259063720703125\nlength of domains: 0\nTotal time: 0.0656\t pickout: 0.0015\t decision: 0.0353\t get_bound: 0.0268\t add_domain: 0.0020\nAccumulated time:\t pickout: 0.0108\t decision: 0.6373\t get_bound: 4.9432\t add_domain: 0.0328\nNo domains left, verification finished!\n186 domains visited\n/home/tristan/.local/share/autoverify/verifiers/abcrown/tool/complete_verifier/batch_branch_and_bound.py:321: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  return torch.tensor(arguments.Config[\"bab\"][\"decision_thresh\"] + 1e-7), np.inf\nCumulative time: 5.878615140914917\n\n\nProperties batch 4, size 1\nRemaining timeout: 278.68338680267334\n##### Instance 0 first 10 spec matrices: [[[ 0.  0.  0.  0. -1.  0.  1.  0.  0.  0.]]]\nthresholds: [0.] ######\nInitial alpha-CROWN verified for spec index [0] with bound 0.6754417419433594.\n\nProperties batch 5, size 1\nRemaining timeout: 278.6245205402374\n##### Instance 0 first 10 spec matrices: [[[ 0.  0.  0.  0.  0. -1.  1.  0.  0.  0.]]]\nthresholds: [0.] ######\nInitial alpha-CROWN verified for spec index [0] with bound 0.21066689491271973.\n\nProperties batch 6, size 1\nRemaining timeout: 278.57482409477234\n##### Instance 0 first 10 spec matrices: [[[ 0.  0.  0.  0.  0.  0.  1. -1.  0.  0.]]]\nthresholds: [0.] ######\nInitial alpha-CROWN verified for spec index [0] with bound 0.8965578079223633.\n\nProperties batch 7, size 1\nRemaining timeout: 278.5230987071991\n##### Instance 0 first 10 spec matrices: [[[ 0.  0.  0.  0.  0.  0.  1.  0. -1.  0.]]]\nthresholds: [0.] ######\nInitial alpha-CROWN verified for spec index [0] with bound 4.815125465393066.\n\nProperties batch 8, size 1\nRemaining timeout: 278.4737913608551\n##### Instance 0 first 10 spec matrices: [[[ 0.  0.  0.  0.  0.  0.  1.  0.  0. -1.]]]\nthresholds: [0.] ######\nInitial alpha-CROWN verified for spec index [0] with bound 1.7716407775878906.\nResult: unsat\nTime: 21.57204031944275\n"
        },
        {
            "network": "cifar10_2_255_simplified",
            "property": "cifar10_spec_idx_79_eps_0.00784_n1",
            "timeout": "300",
            "verifier": "nnenum",
            "config": "Configuration(values={\n  'BRANCH_MODE': 0,\n  'COMPRESS_INIT_BOX': True,\n  'CONTRACT_LP_OPTIMIZED': True,\n  'CONTRACT_LP_TRACK_WITNESSES': True,\n  'CONTRACT_ZONOTOPE': False,\n  'CONTRACT_ZONOTOPE_LP': True,\n  'EAGER_BOUNDS': True,\n  'GLPK_FIRST_PRIMAL': True,\n  'GLPK_RESET_BEFORE_MINIMIZE': False,\n  'GLPK_TIMEOUT': 60,\n  'INF_OVERAPPROX_LP_TIMEOUT': False,\n  'INF_OVERAPPROX_MIN_GEN_LIMIT': False,\n  'OFFLOAD_CLOSEST_TO_ROOT': True,\n  'OVERAPPROX_BOTH_BOUNDS': False,\n  'OVERAPPROX_GEN_LIMIT_MULTIPLIER': 1.5,\n  'OVERAPPROX_LP_TIMEOUT': 1.0,\n  'OVERAPPROX_MIN_GEN_LIMIT': 50,\n  'OVERAPPROX_NEAR_ROOT_MAX_SPLITS': 2,\n  'SINGLE_SET': False,\n  'SKIP_COMPRESSED_CHECK': False,\n  'SKIP_CONSTRAINT_NORMALIZATION': False,\n  'SPLIT_IF_IDLE': True,\n  'SPLIT_ORDER': 1,\n  'SPLIT_TOLERANCE': 1e-08,\n  'TRY_QUICK_OVERAPPROX': True,\n})",
            "success": "OK",
            "result": "UNSAT",
            "took": "8.982885837554932",
            "stderr": "",
            "stdout": "Running in parallel with 12 processes\nOverapprox Round 1/3 has 1 set(s)\nLayer 1/7: LinearOnnxSubnetworkLayer (zono shape: (32768, 3723))... 1.177 sec\nLayer 2/7: ReluLayer (zono shape: (8192, 3723))... 0.531 sec\nLayer 3/7: LinearOnnxSubnetworkLayer (zono shape: (8192, 4134))... 0.78 sec\nLayer 4/7: ReluLayer (zono shape: (8192, 4134))... 0.693 sec\nLayer 5/7: LinearOnnxSubnetworkLayer (zono shape: (8192, 4456))... 0.962 sec\nLayer 6/7: ReluLayer (zono shape: (250, 4456))... 0.006 sec\nLayer 7/7: LinearOnnxSubnetworkLayer (zono shape: (250, 4489))... 0.063 sec\n\n\n\nTotal Stars: 1 (0 exact, 1 approx)\nRuntime: 7.9 sec\nCompleted work frac: 1.0\nNum Stars Copied Between Processes: 0\nNum Lps During Enumeration: 0\nTotal Num Lps: 0\n\nResult: network is SAFE\n"
        },
        {
            "network": "cifar10_2_255_simplified",
            "property": "cifar10_spec_idx_89_eps_0.00784_n1",
            "timeout": "300",
            "verifier": "abcrown",
            "config": "Configuration(values={\n  'attack__attack_mode': 'PGD',\n  'attack__enable_mip_attack': False,\n  'attack__pgd_order': 'before',\n  'bab__branching__input_split__enable': False,\n  'bab__branching__method': 'kfsb',\n  'bab__branching__reduceop': 'min',\n  'general__complete_verifier': 'bab',\n  'general__enable_incomplete_verification': True,\n  'general__loss_reduction_func': 'sum',\n  'solver__bound_prop_method': 'alpha-crown',\n})",
            "success": "OK",
            "result": "UNSAT",
            "took": "9.101082801818848",
            "stderr": "",
            "stdout": "/bin/bash: /home/tristan/miniconda3/envs/__av__abcrown/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nConfigurations:\n\ngeneral:\n  device: cuda\n  seed: 100\n  conv_mode: patches\n  deterministic: false\n  double_fp: false\n  loss_reduction_func: sum\n  record_bounds: false\n  sparse_alpha: true\n  save_adv_example: true\n  precompile_jit: false\n  complete_verifier: bab\n  enable_incomplete_verification: true\n  csv_name: null\n  results_file: /tmp/tmpgqr0xs5u.txt\n  root_path: ''\nmodel:\n  name: null\n  path: null\n  onnx_path: /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/cifar10_2_255_simplified.onnx\n  onnx_path_prefix: ''\n  cache_onnx_conversion: false\n  onnx_quirks: null\n  input_shape: null\n  onnx_loader: default_onnx_and_vnnlib_loader\n  onnx_optimization_flags: none\ndata:\n  start: 0\n  end: 10000\n  select_instance: null\n  num_outputs: 10\n  mean: 0.0\n  std: 1.0\n  pkl_path: null\n  dataset: CIFAR\n  data_filter_path: null\n  data_idx_file: null\nspecification:\n  type: lp\n  robustness_type: verified-acc\n  norm: .inf\n  epsilon: null\n  vnnlib_path: /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_89_eps_0.00784_n1.vnnlib\n  vnnlib_path_prefix: ''\nsolver:\n  batch_size: 512\n  min_batch_size_ratio: 0.1\n  use_float64_in_last_iteration: false\n  early_stop_patience: 10\n  start_save_best: 0.5\n  bound_prop_method: alpha-crown\n  prune_after_crown: false\n  crown:\n    batch_size: 1000000000\n    max_crown_size: 1000000000\n  alpha-crown:\n    alpha: true\n    lr_alpha: 0.1\n    iteration: 100\n    share_slopes: false\n    no_joint_opt: false\n    lr_decay: 0.98\n    full_conv_alpha: true\n  beta-crown:\n    lr_alpha: 0.01\n    lr_beta: 0.05\n    lr_decay: 0.98\n    optimizer: adam\n    iteration: 50\n    beta: true\n    beta_warmup: true\n    enable_opt_interm_bounds: false\n    all_node_split_LP: false\n  forward:\n    refine: false\n    dynamic: false\n    max_dim: 10000\n  multi_class:\n    multi_class_method: allclass_domain\n    label_batch_size: 32\n    skip_with_refined_bound: true\n  mip:\n    parallel_solvers: null\n    solver_threads: 1\n    refine_neuron_timeout: 15\n    refine_neuron_time_percentage: 0.8\n    early_stop: true\n    adv_warmup: true\n    mip_solver: gurobi\nbab:\n  initial_max_domains: 1\n  max_domains: .inf\n  decision_thresh: 0\n  timeout: 300.0\n  timeout_scale: 1\n  override_timeout: null\n  get_upper_bound: false\n  dfs_percent: 0.0\n  pruning_in_iteration: true\n  pruning_in_iteration_ratio: 0.2\n  sort_targets: false\n  batched_domain_list: true\n  optimized_intermediate_layers: ''\n  interm_transfer: true\n  cut:\n    enabled: false\n    bab_cut: false\n    lp_cut: false\n    method: null\n    lr: 0.01\n    lr_decay: 1.0\n    iteration: 100\n    bab_iteration: -1\n    early_stop_patience: -1\n    lr_beta: 0.02\n    number_cuts: 50\n    topk_cuts_in_filter: 100\n    batch_size_primal: 100\n    max_num: 1000000000\n    patches_cut: false\n    cplex_cuts: false\n    cplex_cuts_wait: 0\n    cplex_cuts_revpickup: true\n    cut_reference_bounds: true\n    fix_intermediate_bounds: false\n  branching:\n    method: kfsb\n    candidates: 3\n    reduceop: min\n    sb_coeff_thresh: 0.001\n    input_split:\n      enable: false\n      enhanced_bound_prop_method: alpha-crown\n      enhanced_branching_method: naive\n      enhanced_bound_patience: 100000000.0\n      attack_patience: 100000000.0\n      adv_check: 0\n      sort_domain_interval: -1\n  attack:\n    enabled: false\n    beam_candidates: 8\n    beam_depth: 7\n    max_dive_fix_ratio: 0.8\n    min_local_free_ratio: 0.2\n    mip_start_iteration: 5\n    mip_timeout: 30.0\n    adv_pool_threshold: null\n    refined_mip_attacker: false\n    refined_batch_size: null\nattack:\n  pgd_order: before\n  pgd_steps: 100\n  pgd_restarts: 30\n  pgd_early_stop: true\n  pgd_lr_decay: 0.99\n  pgd_alpha: auto\n  pgd_loss_mode: null\n  enable_mip_attack: false\n  cex_path: ./test_cex.txt\n  attack_mode: PGD\n  gama_lambda: 10.0\n  gama_decay: 0.9\n  check_clean: false\n  input_split:\n    pgd_steps: 100\n    pgd_restarts: 30\n    pgd_alpha: auto\n  input_split_enhanced:\n    pgd_steps: 200\n    pgd_restarts: 5000000\n    pgd_alpha: auto\n  input_split_check_adv:\n    pgd_steps: 5\n    pgd_restarts: 5\n    pgd_alpha: auto\ndebug:\n  lp_test: null\n\nExperiments at Mon May 13 21:14:23 2024 on Cerberus\nInternal results will be saved to /tmp/tmpgqr0xs5u.txt.\n\n %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nUsing onnx /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/cifar10_2_255_simplified.onnx\nUsing vnnlib /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_89_eps_0.00784_n1.vnnlib\nPrecompiled vnnlib file found at /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_89_eps_0.00784_n1.vnnlib.compiled\nLoading onnx /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/cifar10_2_255_simplified.onnx wih quirks {}\n/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/onnx2pytorch/convert/layer.py:30: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_numpy.cpp:178.)\n  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))\n/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/onnx2pytorch/convert/model.py:154: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.\n  \"Using experimental implementation that allows 'batch_size > 1'.\"\nAttack parameters: initialization=uniform, steps=100, restarts=30, alpha=0.0098334401845932, initialization=uniform, GAMA=False\nModel output of first 5 examples:\n tensor([[ 4.45820999,  7.45845509, -3.23980594, -2.27957010, -2.48054481,\n         -2.96445680, -1.49695182,  0.53347808,  2.00121641, 12.13869095]],\n       device='cuda:0')\nAdv example prediction (first 2 examples and 2 restarts):\n tensor([[[ 4.48702860,  8.27062798, -3.10395789, -2.26830912, -2.43770671,\n          -3.00064445, -1.41095793,  0.37030119,  2.13667798, 11.57998276],\n         [ 4.48702860,  8.27062798, -3.10395789, -2.26830912, -2.43770671,\n          -3.00064445, -1.41095793,  0.37030119,  2.13667798, 11.57998276]]],\n       device='cuda:0')\nPGD attack margin (first 2 examles and 10 specs):\n tensor([[[ 7.09295416,  3.30935478, 14.68394089, 13.84829140, 14.01768970,\n          14.58062744, 12.99094105, 11.20968151,  9.44330502]]],\n       device='cuda:0')\nnumber of violation:  0\nAttack finished in 1.9859 seconds.\nPGD attack failed\nModel prediction is: tensor([[ 4.45820999,  7.45845509, -3.23980594, -2.27957010, -2.48054481,\n         -2.96445680, -1.49695182,  0.53347808,  2.00121641, 12.13869095]],\n       device='cuda:0')\nlayer /22 using sparse-features alpha with shape [1424]; unstable size 1424; total size 32768 (torch.Size([1, 32, 32, 32]))\nlayer /22 start_node /input.4 using full alpha with unstable size 32 total_size 32 output_shape 32\nlayer /22 start_node /input.8 using full alpha with unstable size 119 total_size 128 output_shape 128\nlayer /22 start_node /input.12 using sparse-spec alpha with unstable size 72 total_size 250 output_shape torch.Size([250])\nlayer /22 start_node /30 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /24 using sparse-features alpha with shape [779]; unstable size 779; total size 8192 (torch.Size([1, 32, 16, 16]))\nlayer /24 start_node /input.8 using full alpha with unstable size 119 total_size 128 output_shape 128\nlayer /24 start_node /input.12 using sparse-spec alpha with unstable size 72 total_size 250 output_shape torch.Size([250])\nlayer /24 start_node /30 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /26 using sparse-features alpha with shape [711]; unstable size 711; total size 8192 (torch.Size([1, 128, 8, 8]))\nlayer /26 start_node /input.12 using sparse-spec alpha with unstable size 72 total_size 250 output_shape torch.Size([250])\nlayer /26 start_node /30 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /29 using sparse-features alpha with shape [72]; unstable size 72; total size 250 (torch.Size([1, 250]))\nlayer /29 start_node /30 using full alpha with unstable size None total_size 9 output_shape 9\nOptimizable variables initialized.\ninitial CROWN bounds: tensor([[ 3.64581966,  1.50040698, 10.60078907, 10.46342564,  9.78866577,\n         10.80334854,  9.39673805,  6.79292297,  5.55253601]], device='cuda:0') None\nverified with init bound!\nResult: unsat\nTime: 7.062808513641357\n"
        },
        {
            "network": "cifar10_2_255_simplified",
            "property": "cifar10_spec_idx_98_eps_0.00784_n1",
            "timeout": "300",
            "verifier": "nnenum",
            "config": "Configuration(values={\n  'BRANCH_MODE': 0,\n  'COMPRESS_INIT_BOX': True,\n  'CONTRACT_LP_OPTIMIZED': True,\n  'CONTRACT_LP_TRACK_WITNESSES': True,\n  'CONTRACT_ZONOTOPE': False,\n  'CONTRACT_ZONOTOPE_LP': True,\n  'EAGER_BOUNDS': True,\n  'GLPK_FIRST_PRIMAL': True,\n  'GLPK_RESET_BEFORE_MINIMIZE': False,\n  'GLPK_TIMEOUT': 60,\n  'INF_OVERAPPROX_LP_TIMEOUT': False,\n  'INF_OVERAPPROX_MIN_GEN_LIMIT': False,\n  'OFFLOAD_CLOSEST_TO_ROOT': True,\n  'OVERAPPROX_BOTH_BOUNDS': False,\n  'OVERAPPROX_GEN_LIMIT_MULTIPLIER': 1.5,\n  'OVERAPPROX_LP_TIMEOUT': 1.0,\n  'OVERAPPROX_MIN_GEN_LIMIT': 50,\n  'OVERAPPROX_NEAR_ROOT_MAX_SPLITS': 2,\n  'SINGLE_SET': False,\n  'SKIP_COMPRESSED_CHECK': False,\n  'SKIP_CONSTRAINT_NORMALIZATION': False,\n  'SPLIT_IF_IDLE': True,\n  'SPLIT_ORDER': 1,\n  'SPLIT_TOLERANCE': 1e-08,\n  'TRY_QUICK_OVERAPPROX': True,\n})",
            "success": "OK",
            "result": "UNSAT",
            "took": "7.867374420166016",
            "stderr": "",
            "stdout": "Running in parallel with 12 processes\nOverapprox Round 1/3 has 1 set(s)\nLayer 1/7: LinearOnnxSubnetworkLayer (zono shape: (32768, 3525))... 1.036 sec\nLayer 2/7: ReluLayer (zono shape: (8192, 3525))... 0.48 sec\nLayer 3/7: LinearOnnxSubnetworkLayer (zono shape: (8192, 3783))... 0.683 sec\nLayer 4/7: ReluLayer (zono shape: (8192, 3783))... 0.421 sec\nLayer 5/7: LinearOnnxSubnetworkLayer (zono shape: (8192, 3971))... 0.923 sec\nLayer 6/7: ReluLayer (zono shape: (250, 3971))... 0.004 sec\nLayer 7/7: LinearOnnxSubnetworkLayer (zono shape: (250, 3989))... 0.04 sec\n\n\n\nTotal Stars: 1 (0 exact, 1 approx)\nRuntime: 7.0 sec\nCompleted work frac: 1.0\nNum Stars Copied Between Processes: 0\nNum Lps During Enumeration: 0\nTotal Num Lps: 0\n\nResult: network is SAFE\n"
        },
        {
            "network": "cifar10_8_255_simplified",
            "property": "cifar10_spec_idx_11_eps_0.03137_n1",
            "timeout": "300",
            "verifier": "abcrown",
            "config": "Configuration(values={\n  'attack__attack_mode': 'PGD',\n  'attack__enable_mip_attack': False,\n  'attack__pgd_order': 'before',\n  'bab__branching__input_split__enable': False,\n  'bab__branching__method': 'kfsb',\n  'bab__branching__reduceop': 'min',\n  'general__complete_verifier': 'bab',\n  'general__enable_incomplete_verification': True,\n  'general__loss_reduction_func': 'sum',\n  'solver__bound_prop_method': 'alpha-crown',\n})",
            "success": "OK",
            "result": "UNSAT",
            "took": "11.529115438461304",
            "stderr": "",
            "stdout": "/bin/bash: /home/tristan/miniconda3/envs/__av__abcrown/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nConfigurations:\n\ngeneral:\n  device: cuda\n  seed: 100\n  conv_mode: patches\n  deterministic: false\n  double_fp: false\n  loss_reduction_func: sum\n  record_bounds: false\n  sparse_alpha: true\n  save_adv_example: true\n  precompile_jit: false\n  complete_verifier: bab\n  enable_incomplete_verification: true\n  csv_name: null\n  results_file: /tmp/tmpk7hq8tyz.txt\n  root_path: ''\nmodel:\n  name: null\n  path: null\n  onnx_path: /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/cifar10_8_255_simplified.onnx\n  onnx_path_prefix: ''\n  cache_onnx_conversion: false\n  onnx_quirks: null\n  input_shape: null\n  onnx_loader: default_onnx_and_vnnlib_loader\n  onnx_optimization_flags: none\ndata:\n  start: 0\n  end: 10000\n  select_instance: null\n  num_outputs: 10\n  mean: 0.0\n  std: 1.0\n  pkl_path: null\n  dataset: CIFAR\n  data_filter_path: null\n  data_idx_file: null\nspecification:\n  type: lp\n  robustness_type: verified-acc\n  norm: .inf\n  epsilon: null\n  vnnlib_path: /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_11_eps_0.03137_n1.vnnlib\n  vnnlib_path_prefix: ''\nsolver:\n  batch_size: 512\n  min_batch_size_ratio: 0.1\n  use_float64_in_last_iteration: false\n  early_stop_patience: 10\n  start_save_best: 0.5\n  bound_prop_method: alpha-crown\n  prune_after_crown: false\n  crown:\n    batch_size: 1000000000\n    max_crown_size: 1000000000\n  alpha-crown:\n    alpha: true\n    lr_alpha: 0.1\n    iteration: 100\n    share_slopes: false\n    no_joint_opt: false\n    lr_decay: 0.98\n    full_conv_alpha: true\n  beta-crown:\n    lr_alpha: 0.01\n    lr_beta: 0.05\n    lr_decay: 0.98\n    optimizer: adam\n    iteration: 50\n    beta: true\n    beta_warmup: true\n    enable_opt_interm_bounds: false\n    all_node_split_LP: false\n  forward:\n    refine: false\n    dynamic: false\n    max_dim: 10000\n  multi_class:\n    multi_class_method: allclass_domain\n    label_batch_size: 32\n    skip_with_refined_bound: true\n  mip:\n    parallel_solvers: null\n    solver_threads: 1\n    refine_neuron_timeout: 15\n    refine_neuron_time_percentage: 0.8\n    early_stop: true\n    adv_warmup: true\n    mip_solver: gurobi\nbab:\n  initial_max_domains: 1\n  max_domains: .inf\n  decision_thresh: 0\n  timeout: 300.0\n  timeout_scale: 1\n  override_timeout: null\n  get_upper_bound: false\n  dfs_percent: 0.0\n  pruning_in_iteration: true\n  pruning_in_iteration_ratio: 0.2\n  sort_targets: false\n  batched_domain_list: true\n  optimized_intermediate_layers: ''\n  interm_transfer: true\n  cut:\n    enabled: false\n    bab_cut: false\n    lp_cut: false\n    method: null\n    lr: 0.01\n    lr_decay: 1.0\n    iteration: 100\n    bab_iteration: -1\n    early_stop_patience: -1\n    lr_beta: 0.02\n    number_cuts: 50\n    topk_cuts_in_filter: 100\n    batch_size_primal: 100\n    max_num: 1000000000\n    patches_cut: false\n    cplex_cuts: false\n    cplex_cuts_wait: 0\n    cplex_cuts_revpickup: true\n    cut_reference_bounds: true\n    fix_intermediate_bounds: false\n  branching:\n    method: kfsb\n    candidates: 3\n    reduceop: min\n    sb_coeff_thresh: 0.001\n    input_split:\n      enable: false\n      enhanced_bound_prop_method: alpha-crown\n      enhanced_branching_method: naive\n      enhanced_bound_patience: 100000000.0\n      attack_patience: 100000000.0\n      adv_check: 0\n      sort_domain_interval: -1\n  attack:\n    enabled: false\n    beam_candidates: 8\n    beam_depth: 7\n    max_dive_fix_ratio: 0.8\n    min_local_free_ratio: 0.2\n    mip_start_iteration: 5\n    mip_timeout: 30.0\n    adv_pool_threshold: null\n    refined_mip_attacker: false\n    refined_batch_size: null\nattack:\n  pgd_order: before\n  pgd_steps: 100\n  pgd_restarts: 30\n  pgd_early_stop: true\n  pgd_lr_decay: 0.99\n  pgd_alpha: auto\n  pgd_loss_mode: null\n  enable_mip_attack: false\n  cex_path: ./test_cex.txt\n  attack_mode: PGD\n  gama_lambda: 10.0\n  gama_decay: 0.9\n  check_clean: false\n  input_split:\n    pgd_steps: 100\n    pgd_restarts: 30\n    pgd_alpha: auto\n  input_split_enhanced:\n    pgd_steps: 200\n    pgd_restarts: 5000000\n    pgd_alpha: auto\n  input_split_check_adv:\n    pgd_steps: 5\n    pgd_restarts: 5\n    pgd_alpha: auto\ndebug:\n  lp_test: null\n\nExperiments at Mon May 13 21:14:42 2024 on Cerberus\nInternal results will be saved to /tmp/tmpk7hq8tyz.txt.\n\n %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nUsing onnx /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/cifar10_8_255_simplified.onnx\nUsing vnnlib /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_11_eps_0.03137_n1.vnnlib\nPrecompiled vnnlib file found at /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_11_eps_0.03137_n1.vnnlib.compiled\nLoading onnx /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/cifar10_8_255_simplified.onnx wih quirks {}\n/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/onnx2pytorch/convert/layer.py:30: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_numpy.cpp:178.)\n  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))\n/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/onnx2pytorch/convert/model.py:154: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.\n  \"Using experimental implementation that allows 'batch_size > 1'.\"\nAttack parameters: initialization=uniform, steps=100, restarts=30, alpha=0.039333730936050415, initialization=uniform, GAMA=False\nModel output of first 5 examples:\n tensor([[ 0.21427953,  1.82282424, -0.95329773, -0.56605446, -0.84413540,\n         -1.23256934, -1.73097754, -0.13519278,  1.34799814,  2.77015758]],\n       device='cuda:0')\nAdv example prediction (first 2 examples and 2 restarts):\n tensor([[[ 0.29628807,  2.17531061, -1.04846025, -0.64505720, -0.91715002,\n          -1.33519125, -1.74386621, -0.27812806,  1.57999504,  2.65876412],\n         [ 0.29628807,  2.17531061, -1.04846025, -0.64505720, -0.91715002,\n          -1.33519125, -1.74386621, -0.27812806,  1.57999504,  2.65876412]]],\n       device='cuda:0')\nPGD attack margin (first 2 examles and 10 specs):\n tensor([[[2.36247611, 0.48345351, 3.70722437, 3.30382133, 3.57591414,\n          3.99395537, 4.40263033, 2.93689227, 1.07876909]]], device='cuda:0')\nnumber of violation:  0\nAttack finished in 1.6105 seconds.\nPGD attack failed\nModel prediction is: tensor([[ 0.21427953,  1.82282424, -0.95329773, -0.56605446, -0.84413540,\n         -1.23256934, -1.73097754, -0.13519278,  1.34799814,  2.77015758]],\n       device='cuda:0')\nlayer /18 using sparse-features alpha with shape [271]; unstable size 271; total size 8192 (torch.Size([1, 32, 16, 16]))\nlayer /18 start_node /input.4 using sparse-spec alpha with unstable size 72 total_size 128 output_shape 128\nlayer /18 start_node /input.8 using sparse-spec alpha with unstable size 104 total_size 250 output_shape torch.Size([250])\nlayer /18 start_node /24 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /20 using sparse-features alpha with shape [764]; unstable size 764; total size 8192 (torch.Size([1, 128, 8, 8]))\nlayer /20 start_node /input.8 using sparse-spec alpha with unstable size 104 total_size 250 output_shape torch.Size([250])\nlayer /20 start_node /24 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /23 using sparse-features alpha with shape [104]; unstable size 104; total size 250 (torch.Size([1, 250]))\nlayer /23 start_node /24 using full alpha with unstable size None total_size 9 output_shape 9\nOptimizable variables initialized.\ninitial CROWN bounds: tensor([[ 1.12246096, -0.09214254,  2.15115285,  1.82449341,  2.04218793,\n          2.28744054,  2.44691086,  0.59095830, -0.05210555]], device='cuda:0') None\n\nall verified at 15th iter\nbest_l after optimization: 13.648921012878418 with beta sum per layer: []\nalpha/beta optimization time: 3.1402878761291504\ninitial alpha-CROWN bounds: tensor([[1.25593853e+00, 6.02900982e-05, 2.30788612e+00, 1.95581317e+00,\n         2.18180203e+00, 2.43680477e+00, 2.61702108e+00, 8.00340354e-01,\n         9.32550728e-02]], device='cuda:0')\nWorst class: (+ rhs) 6.029009819030762e-05\nverified with init bound!\nResult: unsat\nTime: 9.685075521469116\n"
        },
        {
            "network": "cifar10_8_255_simplified",
            "property": "cifar10_spec_idx_23_eps_0.03137_n1",
            "timeout": "300",
            "verifier": "abcrown",
            "config": "Configuration(values={\n  'attack__attack_mode': 'PGD',\n  'attack__enable_mip_attack': False,\n  'attack__pgd_order': 'before',\n  'bab__branching__input_split__enable': False,\n  'bab__branching__method': 'kfsb',\n  'bab__branching__reduceop': 'min',\n  'general__complete_verifier': 'bab',\n  'general__enable_incomplete_verification': True,\n  'general__loss_reduction_func': 'sum',\n  'solver__bound_prop_method': 'alpha-crown',\n})",
            "success": "OK",
            "result": "SAT",
            "took": "8.174737453460693",
            "stderr": "",
            "stdout": "/bin/bash: /home/tristan/miniconda3/envs/__av__abcrown/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nConfigurations:\n\ngeneral:\n  device: cuda\n  seed: 100\n  conv_mode: patches\n  deterministic: false\n  double_fp: false\n  loss_reduction_func: sum\n  record_bounds: false\n  sparse_alpha: true\n  save_adv_example: true\n  precompile_jit: false\n  complete_verifier: bab\n  enable_incomplete_verification: true\n  csv_name: null\n  results_file: /tmp/tmpfgjkotrm.txt\n  root_path: ''\nmodel:\n  name: null\n  path: null\n  onnx_path: /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/cifar10_8_255_simplified.onnx\n  onnx_path_prefix: ''\n  cache_onnx_conversion: false\n  onnx_quirks: null\n  input_shape: null\n  onnx_loader: default_onnx_and_vnnlib_loader\n  onnx_optimization_flags: none\ndata:\n  start: 0\n  end: 10000\n  select_instance: null\n  num_outputs: 10\n  mean: 0.0\n  std: 1.0\n  pkl_path: null\n  dataset: CIFAR\n  data_filter_path: null\n  data_idx_file: null\nspecification:\n  type: lp\n  robustness_type: verified-acc\n  norm: .inf\n  epsilon: null\n  vnnlib_path: /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_23_eps_0.03137_n1.vnnlib\n  vnnlib_path_prefix: ''\nsolver:\n  batch_size: 512\n  min_batch_size_ratio: 0.1\n  use_float64_in_last_iteration: false\n  early_stop_patience: 10\n  start_save_best: 0.5\n  bound_prop_method: alpha-crown\n  prune_after_crown: false\n  crown:\n    batch_size: 1000000000\n    max_crown_size: 1000000000\n  alpha-crown:\n    alpha: true\n    lr_alpha: 0.1\n    iteration: 100\n    share_slopes: false\n    no_joint_opt: false\n    lr_decay: 0.98\n    full_conv_alpha: true\n  beta-crown:\n    lr_alpha: 0.01\n    lr_beta: 0.05\n    lr_decay: 0.98\n    optimizer: adam\n    iteration: 50\n    beta: true\n    beta_warmup: true\n    enable_opt_interm_bounds: false\n    all_node_split_LP: false\n  forward:\n    refine: false\n    dynamic: false\n    max_dim: 10000\n  multi_class:\n    multi_class_method: allclass_domain\n    label_batch_size: 32\n    skip_with_refined_bound: true\n  mip:\n    parallel_solvers: null\n    solver_threads: 1\n    refine_neuron_timeout: 15\n    refine_neuron_time_percentage: 0.8\n    early_stop: true\n    adv_warmup: true\n    mip_solver: gurobi\nbab:\n  initial_max_domains: 1\n  max_domains: .inf\n  decision_thresh: 0\n  timeout: 300.0\n  timeout_scale: 1\n  override_timeout: null\n  get_upper_bound: false\n  dfs_percent: 0.0\n  pruning_in_iteration: true\n  pruning_in_iteration_ratio: 0.2\n  sort_targets: false\n  batched_domain_list: true\n  optimized_intermediate_layers: ''\n  interm_transfer: true\n  cut:\n    enabled: false\n    bab_cut: false\n    lp_cut: false\n    method: null\n    lr: 0.01\n    lr_decay: 1.0\n    iteration: 100\n    bab_iteration: -1\n    early_stop_patience: -1\n    lr_beta: 0.02\n    number_cuts: 50\n    topk_cuts_in_filter: 100\n    batch_size_primal: 100\n    max_num: 1000000000\n    patches_cut: false\n    cplex_cuts: false\n    cplex_cuts_wait: 0\n    cplex_cuts_revpickup: true\n    cut_reference_bounds: true\n    fix_intermediate_bounds: false\n  branching:\n    method: kfsb\n    candidates: 3\n    reduceop: min\n    sb_coeff_thresh: 0.001\n    input_split:\n      enable: false\n      enhanced_bound_prop_method: alpha-crown\n      enhanced_branching_method: naive\n      enhanced_bound_patience: 100000000.0\n      attack_patience: 100000000.0\n      adv_check: 0\n      sort_domain_interval: -1\n  attack:\n    enabled: false\n    beam_candidates: 8\n    beam_depth: 7\n    max_dive_fix_ratio: 0.8\n    min_local_free_ratio: 0.2\n    mip_start_iteration: 5\n    mip_timeout: 30.0\n    adv_pool_threshold: null\n    refined_mip_attacker: false\n    refined_batch_size: null\nattack:\n  pgd_order: before\n  pgd_steps: 100\n  pgd_restarts: 30\n  pgd_early_stop: true\n  pgd_lr_decay: 0.99\n  pgd_alpha: auto\n  pgd_loss_mode: null\n  enable_mip_attack: false\n  cex_path: ./test_cex.txt\n  attack_mode: PGD\n  gama_lambda: 10.0\n  gama_decay: 0.9\n  check_clean: false\n  input_split:\n    pgd_steps: 100\n    pgd_restarts: 30\n    pgd_alpha: auto\n  input_split_enhanced:\n    pgd_steps: 200\n    pgd_restarts: 5000000\n    pgd_alpha: auto\n  input_split_check_adv:\n    pgd_steps: 5\n    pgd_restarts: 5\n    pgd_alpha: auto\ndebug:\n  lp_test: null\n\nExperiments at Mon May 13 21:14:55 2024 on Cerberus\nInternal results will be saved to /tmp/tmpfgjkotrm.txt.\n\n %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nUsing onnx /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/cifar10_8_255_simplified.onnx\nUsing vnnlib /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_23_eps_0.03137_n1.vnnlib\nPrecompiled vnnlib file found at /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_23_eps_0.03137_n1.vnnlib.compiled\nLoading onnx /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/cifar10_8_255_simplified.onnx wih quirks {}\n/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/onnx2pytorch/convert/layer.py:30: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_numpy.cpp:178.)\n  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))\n/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/onnx2pytorch/convert/model.py:154: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.\n  \"Using experimental implementation that allows 'batch_size > 1'.\"\nAttack parameters: initialization=uniform, steps=100, restarts=30, alpha=0.039333708584308624, initialization=uniform, GAMA=False\nModel output of first 5 examples:\n tensor([[-1.15086710,  3.25605297, -1.23933947, -0.37451699, -0.90260547,\n         -0.36854154, -0.54609567, -0.02293947, -1.39983487,  3.49594378]],\n       device='cuda:0')\nAdv example prediction (first 2 examples and 2 restarts):\n tensor([[[-1.04514432,  3.73228550, -1.37737966, -0.42511427, -1.09885812,\n          -0.39768636, -0.55368650, -0.32959464, -1.25875306,  3.67082763],\n         [-1.04514432,  3.73228550, -1.37737966, -0.42511427, -1.09885812,\n          -0.39768636, -0.55368650, -0.32959464, -1.25875306,  3.67082763]]],\n       device='cuda:0')\nPGD attack margin (first 2 examles and 10 specs):\n tensor([[[ 4.71597195, -0.06145787,  5.04820728,  4.09594202,  4.76968575,\n           4.06851387,  4.22451401,  4.00042248,  4.92958069]]],\n       device='cuda:0')\nnumber of violation:  1\nAttack finished in 2.1138 seconds.\nPGD attack succeeded!\nResult: sat\nTime: 6.228155136108398\n"
        },
        {
            "network": "cifar10_8_255_simplified",
            "property": "cifar10_spec_idx_39_eps_0.03137_n1",
            "timeout": "300",
            "verifier": "abcrown",
            "config": "Configuration(values={\n  'attack__attack_mode': 'PGD',\n  'attack__enable_mip_attack': False,\n  'attack__pgd_order': 'before',\n  'bab__branching__input_split__enable': False,\n  'bab__branching__method': 'kfsb',\n  'bab__branching__reduceop': 'min',\n  'general__complete_verifier': 'bab',\n  'general__enable_incomplete_verification': True,\n  'general__loss_reduction_func': 'sum',\n  'solver__bound_prop_method': 'alpha-crown',\n})",
            "success": "OK",
            "result": "SAT",
            "took": "7.363300561904907",
            "stderr": "",
            "stdout": "/bin/bash: /home/tristan/miniconda3/envs/__av__abcrown/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nConfigurations:\n\ngeneral:\n  device: cuda\n  seed: 100\n  conv_mode: patches\n  deterministic: false\n  double_fp: false\n  loss_reduction_func: sum\n  record_bounds: false\n  sparse_alpha: true\n  save_adv_example: true\n  precompile_jit: false\n  complete_verifier: bab\n  enable_incomplete_verification: true\n  csv_name: null\n  results_file: /tmp/tmpjkq7p_tq.txt\n  root_path: ''\nmodel:\n  name: null\n  path: null\n  onnx_path: /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/cifar10_8_255_simplified.onnx\n  onnx_path_prefix: ''\n  cache_onnx_conversion: false\n  onnx_quirks: null\n  input_shape: null\n  onnx_loader: default_onnx_and_vnnlib_loader\n  onnx_optimization_flags: none\ndata:\n  start: 0\n  end: 10000\n  select_instance: null\n  num_outputs: 10\n  mean: 0.0\n  std: 1.0\n  pkl_path: null\n  dataset: CIFAR\n  data_filter_path: null\n  data_idx_file: null\nspecification:\n  type: lp\n  robustness_type: verified-acc\n  norm: .inf\n  epsilon: null\n  vnnlib_path: /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_39_eps_0.03137_n1.vnnlib\n  vnnlib_path_prefix: ''\nsolver:\n  batch_size: 512\n  min_batch_size_ratio: 0.1\n  use_float64_in_last_iteration: false\n  early_stop_patience: 10\n  start_save_best: 0.5\n  bound_prop_method: alpha-crown\n  prune_after_crown: false\n  crown:\n    batch_size: 1000000000\n    max_crown_size: 1000000000\n  alpha-crown:\n    alpha: true\n    lr_alpha: 0.1\n    iteration: 100\n    share_slopes: false\n    no_joint_opt: false\n    lr_decay: 0.98\n    full_conv_alpha: true\n  beta-crown:\n    lr_alpha: 0.01\n    lr_beta: 0.05\n    lr_decay: 0.98\n    optimizer: adam\n    iteration: 50\n    beta: true\n    beta_warmup: true\n    enable_opt_interm_bounds: false\n    all_node_split_LP: false\n  forward:\n    refine: false\n    dynamic: false\n    max_dim: 10000\n  multi_class:\n    multi_class_method: allclass_domain\n    label_batch_size: 32\n    skip_with_refined_bound: true\n  mip:\n    parallel_solvers: null\n    solver_threads: 1\n    refine_neuron_timeout: 15\n    refine_neuron_time_percentage: 0.8\n    early_stop: true\n    adv_warmup: true\n    mip_solver: gurobi\nbab:\n  initial_max_domains: 1\n  max_domains: .inf\n  decision_thresh: 0\n  timeout: 300.0\n  timeout_scale: 1\n  override_timeout: null\n  get_upper_bound: false\n  dfs_percent: 0.0\n  pruning_in_iteration: true\n  pruning_in_iteration_ratio: 0.2\n  sort_targets: false\n  batched_domain_list: true\n  optimized_intermediate_layers: ''\n  interm_transfer: true\n  cut:\n    enabled: false\n    bab_cut: false\n    lp_cut: false\n    method: null\n    lr: 0.01\n    lr_decay: 1.0\n    iteration: 100\n    bab_iteration: -1\n    early_stop_patience: -1\n    lr_beta: 0.02\n    number_cuts: 50\n    topk_cuts_in_filter: 100\n    batch_size_primal: 100\n    max_num: 1000000000\n    patches_cut: false\n    cplex_cuts: false\n    cplex_cuts_wait: 0\n    cplex_cuts_revpickup: true\n    cut_reference_bounds: true\n    fix_intermediate_bounds: false\n  branching:\n    method: kfsb\n    candidates: 3\n    reduceop: min\n    sb_coeff_thresh: 0.001\n    input_split:\n      enable: false\n      enhanced_bound_prop_method: alpha-crown\n      enhanced_branching_method: naive\n      enhanced_bound_patience: 100000000.0\n      attack_patience: 100000000.0\n      adv_check: 0\n      sort_domain_interval: -1\n  attack:\n    enabled: false\n    beam_candidates: 8\n    beam_depth: 7\n    max_dive_fix_ratio: 0.8\n    min_local_free_ratio: 0.2\n    mip_start_iteration: 5\n    mip_timeout: 30.0\n    adv_pool_threshold: null\n    refined_mip_attacker: false\n    refined_batch_size: null\nattack:\n  pgd_order: before\n  pgd_steps: 100\n  pgd_restarts: 30\n  pgd_early_stop: true\n  pgd_lr_decay: 0.99\n  pgd_alpha: auto\n  pgd_loss_mode: null\n  enable_mip_attack: false\n  cex_path: ./test_cex.txt\n  attack_mode: PGD\n  gama_lambda: 10.0\n  gama_decay: 0.9\n  check_clean: false\n  input_split:\n    pgd_steps: 100\n    pgd_restarts: 30\n    pgd_alpha: auto\n  input_split_enhanced:\n    pgd_steps: 200\n    pgd_restarts: 5000000\n    pgd_alpha: auto\n  input_split_check_adv:\n    pgd_steps: 5\n    pgd_restarts: 5\n    pgd_alpha: auto\ndebug:\n  lp_test: null\n\nExperiments at Mon May 13 21:15:05 2024 on Cerberus\nInternal results will be saved to /tmp/tmpjkq7p_tq.txt.\n\n %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nUsing onnx /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/cifar10_8_255_simplified.onnx\nUsing vnnlib /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_39_eps_0.03137_n1.vnnlib\nPrecompiled vnnlib file found at /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_39_eps_0.03137_n1.vnnlib.compiled\nLoading onnx /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/cifar10_8_255_simplified.onnx wih quirks {}\n/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/onnx2pytorch/convert/layer.py:30: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_numpy.cpp:178.)\n  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))\n/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/onnx2pytorch/convert/model.py:154: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.\n  \"Using experimental implementation that allows 'batch_size > 1'.\"\nAttack parameters: initialization=uniform, steps=100, restarts=30, alpha=0.039333708584308624, initialization=uniform, GAMA=False\nModel output of first 5 examples:\n tensor([[-0.85258293,  0.00403488, -0.37607461,  0.47144255, -0.00784957,\n          1.03636110, -0.47195727, -0.07978809,  0.87156272, -0.89035553]],\n       device='cuda:0')\nAdv example prediction (first 2 examples and 2 restarts):\n tensor([[[-0.85305285,  0.83073950, -0.57770157,  0.24319662, -0.20337465,\n           0.67435169, -0.66313702, -0.24651816,  0.99708223, -0.31799167],\n         [-0.85305285,  0.83073950, -0.57770157,  0.24319662, -0.20337465,\n           0.67435169, -0.66313702, -0.24651816,  0.99708223, -0.31799167]]],\n       device='cuda:0')\nPGD attack margin (first 2 examles and 10 specs):\n tensor([[[ 1.52740455, -0.15638781,  1.25205326,  0.43115509,  0.87772632,\n           1.33748865,  0.92086983, -0.32273054,  0.99234337]]],\n       device='cuda:0')\nnumber of violation:  2\nAttack finished in 1.7594 seconds.\nPGD attack succeeded!\nResult: sat\nTime: 5.429743528366089\n"
        },
        {
            "network": "cifar10_8_255_simplified",
            "property": "cifar10_spec_idx_55_eps_0.03137_n1",
            "timeout": "300",
            "verifier": "abcrown",
            "config": "Configuration(values={\n  'attack__attack_mode': 'PGD',\n  'attack__enable_mip_attack': False,\n  'attack__pgd_order': 'before',\n  'bab__branching__input_split__enable': False,\n  'bab__branching__method': 'kfsb',\n  'bab__branching__reduceop': 'min',\n  'general__complete_verifier': 'bab',\n  'general__enable_incomplete_verification': True,\n  'general__loss_reduction_func': 'sum',\n  'solver__bound_prop_method': 'alpha-crown',\n})",
            "success": "OK",
            "result": "UNSAT",
            "took": "10.967787265777588",
            "stderr": "",
            "stdout": "/bin/bash: /home/tristan/miniconda3/envs/__av__abcrown/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nConfigurations:\n\ngeneral:\n  device: cuda\n  seed: 100\n  conv_mode: patches\n  deterministic: false\n  double_fp: false\n  loss_reduction_func: sum\n  record_bounds: false\n  sparse_alpha: true\n  save_adv_example: true\n  precompile_jit: false\n  complete_verifier: bab\n  enable_incomplete_verification: true\n  csv_name: null\n  results_file: /tmp/tmpfyfib5s5.txt\n  root_path: ''\nmodel:\n  name: null\n  path: null\n  onnx_path: /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/cifar10_8_255_simplified.onnx\n  onnx_path_prefix: ''\n  cache_onnx_conversion: false\n  onnx_quirks: null\n  input_shape: null\n  onnx_loader: default_onnx_and_vnnlib_loader\n  onnx_optimization_flags: none\ndata:\n  start: 0\n  end: 10000\n  select_instance: null\n  num_outputs: 10\n  mean: 0.0\n  std: 1.0\n  pkl_path: null\n  dataset: CIFAR\n  data_filter_path: null\n  data_idx_file: null\nspecification:\n  type: lp\n  robustness_type: verified-acc\n  norm: .inf\n  epsilon: null\n  vnnlib_path: /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_55_eps_0.03137_n1.vnnlib\n  vnnlib_path_prefix: ''\nsolver:\n  batch_size: 512\n  min_batch_size_ratio: 0.1\n  use_float64_in_last_iteration: false\n  early_stop_patience: 10\n  start_save_best: 0.5\n  bound_prop_method: alpha-crown\n  prune_after_crown: false\n  crown:\n    batch_size: 1000000000\n    max_crown_size: 1000000000\n  alpha-crown:\n    alpha: true\n    lr_alpha: 0.1\n    iteration: 100\n    share_slopes: false\n    no_joint_opt: false\n    lr_decay: 0.98\n    full_conv_alpha: true\n  beta-crown:\n    lr_alpha: 0.01\n    lr_beta: 0.05\n    lr_decay: 0.98\n    optimizer: adam\n    iteration: 50\n    beta: true\n    beta_warmup: true\n    enable_opt_interm_bounds: false\n    all_node_split_LP: false\n  forward:\n    refine: false\n    dynamic: false\n    max_dim: 10000\n  multi_class:\n    multi_class_method: allclass_domain\n    label_batch_size: 32\n    skip_with_refined_bound: true\n  mip:\n    parallel_solvers: null\n    solver_threads: 1\n    refine_neuron_timeout: 15\n    refine_neuron_time_percentage: 0.8\n    early_stop: true\n    adv_warmup: true\n    mip_solver: gurobi\nbab:\n  initial_max_domains: 1\n  max_domains: .inf\n  decision_thresh: 0\n  timeout: 300.0\n  timeout_scale: 1\n  override_timeout: null\n  get_upper_bound: false\n  dfs_percent: 0.0\n  pruning_in_iteration: true\n  pruning_in_iteration_ratio: 0.2\n  sort_targets: false\n  batched_domain_list: true\n  optimized_intermediate_layers: ''\n  interm_transfer: true\n  cut:\n    enabled: false\n    bab_cut: false\n    lp_cut: false\n    method: null\n    lr: 0.01\n    lr_decay: 1.0\n    iteration: 100\n    bab_iteration: -1\n    early_stop_patience: -1\n    lr_beta: 0.02\n    number_cuts: 50\n    topk_cuts_in_filter: 100\n    batch_size_primal: 100\n    max_num: 1000000000\n    patches_cut: false\n    cplex_cuts: false\n    cplex_cuts_wait: 0\n    cplex_cuts_revpickup: true\n    cut_reference_bounds: true\n    fix_intermediate_bounds: false\n  branching:\n    method: kfsb\n    candidates: 3\n    reduceop: min\n    sb_coeff_thresh: 0.001\n    input_split:\n      enable: false\n      enhanced_bound_prop_method: alpha-crown\n      enhanced_branching_method: naive\n      enhanced_bound_patience: 100000000.0\n      attack_patience: 100000000.0\n      adv_check: 0\n      sort_domain_interval: -1\n  attack:\n    enabled: false\n    beam_candidates: 8\n    beam_depth: 7\n    max_dive_fix_ratio: 0.8\n    min_local_free_ratio: 0.2\n    mip_start_iteration: 5\n    mip_timeout: 30.0\n    adv_pool_threshold: null\n    refined_mip_attacker: false\n    refined_batch_size: null\nattack:\n  pgd_order: before\n  pgd_steps: 100\n  pgd_restarts: 30\n  pgd_early_stop: true\n  pgd_lr_decay: 0.99\n  pgd_alpha: auto\n  pgd_loss_mode: null\n  enable_mip_attack: false\n  cex_path: ./test_cex.txt\n  attack_mode: PGD\n  gama_lambda: 10.0\n  gama_decay: 0.9\n  check_clean: false\n  input_split:\n    pgd_steps: 100\n    pgd_restarts: 30\n    pgd_alpha: auto\n  input_split_enhanced:\n    pgd_steps: 200\n    pgd_restarts: 5000000\n    pgd_alpha: auto\n  input_split_check_adv:\n    pgd_steps: 5\n    pgd_restarts: 5\n    pgd_alpha: auto\ndebug:\n  lp_test: null\n\nExperiments at Mon May 13 21:15:14 2024 on Cerberus\nInternal results will be saved to /tmp/tmpfyfib5s5.txt.\n\n %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nUsing onnx /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/cifar10_8_255_simplified.onnx\nUsing vnnlib /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_55_eps_0.03137_n1.vnnlib\nPrecompiled vnnlib file found at /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_55_eps_0.03137_n1.vnnlib.compiled\nLoading onnx /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/cifar10_8_255_simplified.onnx wih quirks {}\n/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/onnx2pytorch/convert/layer.py:30: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_numpy.cpp:178.)\n  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))\n/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/onnx2pytorch/convert/model.py:154: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.\n  \"Using experimental implementation that allows 'batch_size > 1'.\"\nAttack parameters: initialization=uniform, steps=100, restarts=30, alpha=0.039333704859018326, initialization=uniform, GAMA=False\nModel output of first 5 examples:\n tensor([[ 1.42585230,  0.08431870, -0.01928085, -0.90985799,  0.06956941,\n         -1.05303371, -0.86464828, -0.79066396,  2.44238663,  0.17502323]],\n       device='cuda:0')\nAdv example prediction (first 2 examples and 2 restarts):\n tensor([[[ 1.44630742,  0.24157470, -0.05671391, -0.90471673,  0.04474342,\n          -0.98103559, -0.92129189, -0.63299358,  2.13165689,  0.16863680],\n         [ 1.44630742,  0.24157470, -0.05671391, -0.90471673,  0.04474342,\n          -0.98103559, -0.92129189, -0.63299358,  2.13165689,  0.16863680]]],\n       device='cuda:0')\nPGD attack margin (first 2 examles and 10 specs):\n tensor([[[0.68534946, 1.89008212, 2.18837070, 3.03637362, 2.08691359,\n          3.11269236, 3.05294871, 2.76465034, 1.96302009]]], device='cuda:0')\nnumber of violation:  0\nAttack finished in 1.8107 seconds.\nPGD attack failed\nModel prediction is: tensor([[ 1.42585230,  0.08431870, -0.01928085, -0.90985799,  0.06956941,\n         -1.05303371, -0.86464828, -0.79066396,  2.44238663,  0.17502323]],\n       device='cuda:0')\nlayer /18 using sparse-features alpha with shape [239]; unstable size 239; total size 8192 (torch.Size([1, 32, 16, 16]))\nlayer /18 start_node /input.4 using sparse-spec alpha with unstable size 65 total_size 128 output_shape 128\nlayer /18 start_node /input.8 using sparse-spec alpha with unstable size 109 total_size 250 output_shape torch.Size([250])\nlayer /18 start_node /24 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /20 using sparse-features alpha with shape [1126]; unstable size 1126; total size 8192 (torch.Size([1, 128, 8, 8]))\nlayer /20 start_node /input.8 using sparse-spec alpha with unstable size 109 total_size 250 output_shape torch.Size([250])\nlayer /20 start_node /24 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /23 using sparse-features alpha with shape [109]; unstable size 109; total size 250 (torch.Size([1, 250]))\nlayer /23 start_node /24 using full alpha with unstable size None total_size 9 output_shape 9\nOptimizable variables initialized.\ninitial CROWN bounds: tensor([[-0.02372192,  0.26599938,  0.59504104,  1.23817921,  0.60576916,\n          1.16680086,  1.19513106,  0.77421379,  0.18742990]], device='cuda:0') None\n\nall verified at 2th iter\nbest_l after optimization: 6.494163990020752 with beta sum per layer: []\nalpha/beta optimization time: 2.1890456676483154\ninitial alpha-CROWN bounds: tensor([[0.01864126, 0.32097566, 0.64471424, 1.29487813, 0.65704846, 1.22855020,\n         1.24993300, 0.84288299, 0.23654032]], device='cuda:0')\nWorst class: (+ rhs) 0.018641263246536255\nverified with init bound!\nResult: unsat\nTime: 9.027301549911499\n"
        },
        {
            "network": "cifar10_8_255_simplified",
            "property": "cifar10_spec_idx_74_eps_0.03137_n1",
            "timeout": "300",
            "verifier": "abcrown",
            "config": "Configuration(values={\n  'attack__attack_mode': 'PGD',\n  'attack__enable_mip_attack': False,\n  'attack__pgd_order': 'before',\n  'bab__branching__input_split__enable': False,\n  'bab__branching__method': 'kfsb',\n  'bab__branching__reduceop': 'min',\n  'general__complete_verifier': 'bab',\n  'general__enable_incomplete_verification': True,\n  'general__loss_reduction_func': 'sum',\n  'solver__bound_prop_method': 'alpha-crown',\n})",
            "success": "OK",
            "result": "SAT",
            "took": "8.467296838760376",
            "stderr": "",
            "stdout": "/bin/bash: /home/tristan/miniconda3/envs/__av__abcrown/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nConfigurations:\n\ngeneral:\n  device: cuda\n  seed: 100\n  conv_mode: patches\n  deterministic: false\n  double_fp: false\n  loss_reduction_func: sum\n  record_bounds: false\n  sparse_alpha: true\n  save_adv_example: true\n  precompile_jit: false\n  complete_verifier: bab\n  enable_incomplete_verification: true\n  csv_name: null\n  results_file: /tmp/tmp8xw02hpq.txt\n  root_path: ''\nmodel:\n  name: null\n  path: null\n  onnx_path: /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/cifar10_8_255_simplified.onnx\n  onnx_path_prefix: ''\n  cache_onnx_conversion: false\n  onnx_quirks: null\n  input_shape: null\n  onnx_loader: default_onnx_and_vnnlib_loader\n  onnx_optimization_flags: none\ndata:\n  start: 0\n  end: 10000\n  select_instance: null\n  num_outputs: 10\n  mean: 0.0\n  std: 1.0\n  pkl_path: null\n  dataset: CIFAR\n  data_filter_path: null\n  data_idx_file: null\nspecification:\n  type: lp\n  robustness_type: verified-acc\n  norm: .inf\n  epsilon: null\n  vnnlib_path: /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_74_eps_0.03137_n1.vnnlib\n  vnnlib_path_prefix: ''\nsolver:\n  batch_size: 512\n  min_batch_size_ratio: 0.1\n  use_float64_in_last_iteration: false\n  early_stop_patience: 10\n  start_save_best: 0.5\n  bound_prop_method: alpha-crown\n  prune_after_crown: false\n  crown:\n    batch_size: 1000000000\n    max_crown_size: 1000000000\n  alpha-crown:\n    alpha: true\n    lr_alpha: 0.1\n    iteration: 100\n    share_slopes: false\n    no_joint_opt: false\n    lr_decay: 0.98\n    full_conv_alpha: true\n  beta-crown:\n    lr_alpha: 0.01\n    lr_beta: 0.05\n    lr_decay: 0.98\n    optimizer: adam\n    iteration: 50\n    beta: true\n    beta_warmup: true\n    enable_opt_interm_bounds: false\n    all_node_split_LP: false\n  forward:\n    refine: false\n    dynamic: false\n    max_dim: 10000\n  multi_class:\n    multi_class_method: allclass_domain\n    label_batch_size: 32\n    skip_with_refined_bound: true\n  mip:\n    parallel_solvers: null\n    solver_threads: 1\n    refine_neuron_timeout: 15\n    refine_neuron_time_percentage: 0.8\n    early_stop: true\n    adv_warmup: true\n    mip_solver: gurobi\nbab:\n  initial_max_domains: 1\n  max_domains: .inf\n  decision_thresh: 0\n  timeout: 300.0\n  timeout_scale: 1\n  override_timeout: null\n  get_upper_bound: false\n  dfs_percent: 0.0\n  pruning_in_iteration: true\n  pruning_in_iteration_ratio: 0.2\n  sort_targets: false\n  batched_domain_list: true\n  optimized_intermediate_layers: ''\n  interm_transfer: true\n  cut:\n    enabled: false\n    bab_cut: false\n    lp_cut: false\n    method: null\n    lr: 0.01\n    lr_decay: 1.0\n    iteration: 100\n    bab_iteration: -1\n    early_stop_patience: -1\n    lr_beta: 0.02\n    number_cuts: 50\n    topk_cuts_in_filter: 100\n    batch_size_primal: 100\n    max_num: 1000000000\n    patches_cut: false\n    cplex_cuts: false\n    cplex_cuts_wait: 0\n    cplex_cuts_revpickup: true\n    cut_reference_bounds: true\n    fix_intermediate_bounds: false\n  branching:\n    method: kfsb\n    candidates: 3\n    reduceop: min\n    sb_coeff_thresh: 0.001\n    input_split:\n      enable: false\n      enhanced_bound_prop_method: alpha-crown\n      enhanced_branching_method: naive\n      enhanced_bound_patience: 100000000.0\n      attack_patience: 100000000.0\n      adv_check: 0\n      sort_domain_interval: -1\n  attack:\n    enabled: false\n    beam_candidates: 8\n    beam_depth: 7\n    max_dive_fix_ratio: 0.8\n    min_local_free_ratio: 0.2\n    mip_start_iteration: 5\n    mip_timeout: 30.0\n    adv_pool_threshold: null\n    refined_mip_attacker: false\n    refined_batch_size: null\nattack:\n  pgd_order: before\n  pgd_steps: 100\n  pgd_restarts: 30\n  pgd_early_stop: true\n  pgd_lr_decay: 0.99\n  pgd_alpha: auto\n  pgd_loss_mode: null\n  enable_mip_attack: false\n  cex_path: ./test_cex.txt\n  attack_mode: PGD\n  gama_lambda: 10.0\n  gama_decay: 0.9\n  check_clean: false\n  input_split:\n    pgd_steps: 100\n    pgd_restarts: 30\n    pgd_alpha: auto\n  input_split_enhanced:\n    pgd_steps: 200\n    pgd_restarts: 5000000\n    pgd_alpha: auto\n  input_split_check_adv:\n    pgd_steps: 5\n    pgd_restarts: 5\n    pgd_alpha: auto\ndebug:\n  lp_test: null\n\nExperiments at Mon May 13 21:15:26 2024 on Cerberus\nInternal results will be saved to /tmp/tmp8xw02hpq.txt.\n\n %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nUsing onnx /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/cifar10_8_255_simplified.onnx\nUsing vnnlib /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_74_eps_0.03137_n1.vnnlib\nPrecompiled vnnlib file found at /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_74_eps_0.03137_n1.vnnlib.compiled\nLoading onnx /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/cifar10_8_255_simplified.onnx wih quirks {}\n/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/onnx2pytorch/convert/layer.py:30: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_numpy.cpp:178.)\n  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))\n/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/onnx2pytorch/convert/model.py:154: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.\n  \"Using experimental implementation that allows 'batch_size > 1'.\"\nAttack parameters: initialization=uniform, steps=100, restarts=30, alpha=0.039333708584308624, initialization=uniform, GAMA=False\nModel output of first 5 examples:\n tensor([[ 1.99456906,  0.92221719, -0.18530147, -1.26380289,  0.52791083,\n         -2.13896990, -2.99637532,  0.54190046,  1.94590044,  1.81956339]],\n       device='cuda:0')\nAdv example prediction (first 2 examples and 2 restarts):\n tensor([[[ 1.79191017,  0.95040131, -0.33032101, -1.12356019,  0.31390333,\n          -1.99346793, -2.62409258,  0.25408816,  2.13896036,  1.78995204],\n         [ 1.79191017,  0.95040131, -0.33032101, -1.12356019,  0.31390333,\n          -1.99346793, -2.62409258,  0.25408816,  2.13896036,  1.78995204]]],\n       device='cuda:0')\nPGD attack margin (first 2 examles and 10 specs):\n tensor([[[ 8.41508865e-01,  2.12223125e+00,  2.91547036e+00,  1.47800684e+00,\n           3.78537798e+00,  4.41600275e+00,  1.53782201e+00, -3.47050190e-01,\n           1.95813179e-03]]], device='cuda:0')\nnumber of violation:  1\nAttack finished in 2.2030 seconds.\nPGD attack succeeded!\nResult: sat\nTime: 6.597902059555054\n"
        },
        {
            "network": "cifar10_8_255_simplified",
            "property": "cifar10_spec_idx_86_eps_0.03137_n1",
            "timeout": "300",
            "verifier": "abcrown",
            "config": "Configuration(values={\n  'attack__attack_mode': 'PGD',\n  'attack__enable_mip_attack': False,\n  'attack__pgd_order': 'before',\n  'bab__branching__input_split__enable': False,\n  'bab__branching__method': 'kfsb',\n  'bab__branching__reduceop': 'min',\n  'general__complete_verifier': 'bab',\n  'general__enable_incomplete_verification': True,\n  'general__loss_reduction_func': 'sum',\n  'solver__bound_prop_method': 'alpha-crown',\n})",
            "success": "OK",
            "result": "SAT",
            "took": "8.06174373626709",
            "stderr": "",
            "stdout": "/bin/bash: /home/tristan/miniconda3/envs/__av__abcrown/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nConfigurations:\n\ngeneral:\n  device: cuda\n  seed: 100\n  conv_mode: patches\n  deterministic: false\n  double_fp: false\n  loss_reduction_func: sum\n  record_bounds: false\n  sparse_alpha: true\n  save_adv_example: true\n  precompile_jit: false\n  complete_verifier: bab\n  enable_incomplete_verification: true\n  csv_name: null\n  results_file: /tmp/tmpukh2_t63.txt\n  root_path: ''\nmodel:\n  name: null\n  path: null\n  onnx_path: /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/cifar10_8_255_simplified.onnx\n  onnx_path_prefix: ''\n  cache_onnx_conversion: false\n  onnx_quirks: null\n  input_shape: null\n  onnx_loader: default_onnx_and_vnnlib_loader\n  onnx_optimization_flags: none\ndata:\n  start: 0\n  end: 10000\n  select_instance: null\n  num_outputs: 10\n  mean: 0.0\n  std: 1.0\n  pkl_path: null\n  dataset: CIFAR\n  data_filter_path: null\n  data_idx_file: null\nspecification:\n  type: lp\n  robustness_type: verified-acc\n  norm: .inf\n  epsilon: null\n  vnnlib_path: /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_86_eps_0.03137_n1.vnnlib\n  vnnlib_path_prefix: ''\nsolver:\n  batch_size: 512\n  min_batch_size_ratio: 0.1\n  use_float64_in_last_iteration: false\n  early_stop_patience: 10\n  start_save_best: 0.5\n  bound_prop_method: alpha-crown\n  prune_after_crown: false\n  crown:\n    batch_size: 1000000000\n    max_crown_size: 1000000000\n  alpha-crown:\n    alpha: true\n    lr_alpha: 0.1\n    iteration: 100\n    share_slopes: false\n    no_joint_opt: false\n    lr_decay: 0.98\n    full_conv_alpha: true\n  beta-crown:\n    lr_alpha: 0.01\n    lr_beta: 0.05\n    lr_decay: 0.98\n    optimizer: adam\n    iteration: 50\n    beta: true\n    beta_warmup: true\n    enable_opt_interm_bounds: false\n    all_node_split_LP: false\n  forward:\n    refine: false\n    dynamic: false\n    max_dim: 10000\n  multi_class:\n    multi_class_method: allclass_domain\n    label_batch_size: 32\n    skip_with_refined_bound: true\n  mip:\n    parallel_solvers: null\n    solver_threads: 1\n    refine_neuron_timeout: 15\n    refine_neuron_time_percentage: 0.8\n    early_stop: true\n    adv_warmup: true\n    mip_solver: gurobi\nbab:\n  initial_max_domains: 1\n  max_domains: .inf\n  decision_thresh: 0\n  timeout: 300.0\n  timeout_scale: 1\n  override_timeout: null\n  get_upper_bound: false\n  dfs_percent: 0.0\n  pruning_in_iteration: true\n  pruning_in_iteration_ratio: 0.2\n  sort_targets: false\n  batched_domain_list: true\n  optimized_intermediate_layers: ''\n  interm_transfer: true\n  cut:\n    enabled: false\n    bab_cut: false\n    lp_cut: false\n    method: null\n    lr: 0.01\n    lr_decay: 1.0\n    iteration: 100\n    bab_iteration: -1\n    early_stop_patience: -1\n    lr_beta: 0.02\n    number_cuts: 50\n    topk_cuts_in_filter: 100\n    batch_size_primal: 100\n    max_num: 1000000000\n    patches_cut: false\n    cplex_cuts: false\n    cplex_cuts_wait: 0\n    cplex_cuts_revpickup: true\n    cut_reference_bounds: true\n    fix_intermediate_bounds: false\n  branching:\n    method: kfsb\n    candidates: 3\n    reduceop: min\n    sb_coeff_thresh: 0.001\n    input_split:\n      enable: false\n      enhanced_bound_prop_method: alpha-crown\n      enhanced_branching_method: naive\n      enhanced_bound_patience: 100000000.0\n      attack_patience: 100000000.0\n      adv_check: 0\n      sort_domain_interval: -1\n  attack:\n    enabled: false\n    beam_candidates: 8\n    beam_depth: 7\n    max_dive_fix_ratio: 0.8\n    min_local_free_ratio: 0.2\n    mip_start_iteration: 5\n    mip_timeout: 30.0\n    adv_pool_threshold: null\n    refined_mip_attacker: false\n    refined_batch_size: null\nattack:\n  pgd_order: before\n  pgd_steps: 100\n  pgd_restarts: 30\n  pgd_early_stop: true\n  pgd_lr_decay: 0.99\n  pgd_alpha: auto\n  pgd_loss_mode: null\n  enable_mip_attack: false\n  cex_path: ./test_cex.txt\n  attack_mode: PGD\n  gama_lambda: 10.0\n  gama_decay: 0.9\n  check_clean: false\n  input_split:\n    pgd_steps: 100\n    pgd_restarts: 30\n    pgd_alpha: auto\n  input_split_enhanced:\n    pgd_steps: 200\n    pgd_restarts: 5000000\n    pgd_alpha: auto\n  input_split_check_adv:\n    pgd_steps: 5\n    pgd_restarts: 5\n    pgd_alpha: auto\ndebug:\n  lp_test: null\n\nExperiments at Mon May 13 21:15:37 2024 on Cerberus\nInternal results will be saved to /tmp/tmpukh2_t63.txt.\n\n %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nUsing onnx /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/cifar10_8_255_simplified.onnx\nUsing vnnlib /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_86_eps_0.03137_n1.vnnlib\nPrecompiled vnnlib file found at /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_86_eps_0.03137_n1.vnnlib.compiled\nLoading onnx /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/cifar10_8_255_simplified.onnx wih quirks {}\n/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/onnx2pytorch/convert/layer.py:30: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_numpy.cpp:178.)\n  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))\n/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/onnx2pytorch/convert/model.py:154: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.\n  \"Using experimental implementation that allows 'batch_size > 1'.\"\nAttack parameters: initialization=uniform, steps=100, restarts=30, alpha=0.039333708584308624, initialization=uniform, GAMA=False\nModel output of first 5 examples:\n tensor([[ 0.14482355,  0.42702734,  1.17975521,  0.42308298, -0.50366199,\n          0.39120865, -1.85243201, -0.93027544,  0.79907751,  0.54692328]],\n       device='cuda:0')\nAdv example prediction (first 2 examples and 2 restarts):\n tensor([[[ 0.13597828,  0.66834402,  0.47835025,  0.33799794, -0.37628934,\n           0.34226054, -1.88110042, -0.92241907,  0.90814900,  0.81491107],\n         [ 0.13597828,  0.66834402,  0.47835025,  0.33799794, -0.37628934,\n           0.34226054, -1.88110042, -0.92241907,  0.90814900,  0.81491107]]],\n       device='cuda:0')\nPGD attack margin (first 2 examles and 10 specs):\n tensor([[[ 0.34237197, -0.18999377,  0.14035231,  0.85463959,  0.13608971,\n           2.35945058,  1.40076935, -0.42979875, -0.33656082]]],\n       device='cuda:0')\nnumber of violation:  3\nAttack finished in 1.8423 seconds.\nPGD attack succeeded!\nResult: sat\nTime: 6.195707082748413\n"
        },
        {
            "network": "cifar10_8_255_simplified",
            "property": "cifar10_spec_idx_98_eps_0.03137_n1",
            "timeout": "300",
            "verifier": "nnenum",
            "config": "Configuration(values={\n  'BRANCH_MODE': 0,\n  'COMPRESS_INIT_BOX': True,\n  'CONTRACT_LP_OPTIMIZED': True,\n  'CONTRACT_LP_TRACK_WITNESSES': True,\n  'CONTRACT_ZONOTOPE': False,\n  'CONTRACT_ZONOTOPE_LP': True,\n  'EAGER_BOUNDS': True,\n  'GLPK_FIRST_PRIMAL': True,\n  'GLPK_RESET_BEFORE_MINIMIZE': False,\n  'GLPK_TIMEOUT': 60,\n  'INF_OVERAPPROX_LP_TIMEOUT': False,\n  'INF_OVERAPPROX_MIN_GEN_LIMIT': False,\n  'OFFLOAD_CLOSEST_TO_ROOT': True,\n  'OVERAPPROX_BOTH_BOUNDS': False,\n  'OVERAPPROX_GEN_LIMIT_MULTIPLIER': 1.5,\n  'OVERAPPROX_LP_TIMEOUT': 1.0,\n  'OVERAPPROX_MIN_GEN_LIMIT': 50,\n  'OVERAPPROX_NEAR_ROOT_MAX_SPLITS': 2,\n  'SINGLE_SET': False,\n  'SKIP_COMPRESSED_CHECK': False,\n  'SKIP_CONSTRAINT_NORMALIZATION': False,\n  'SPLIT_IF_IDLE': True,\n  'SPLIT_ORDER': 1,\n  'SPLIT_TOLERANCE': 1e-08,\n  'TRY_QUICK_OVERAPPROX': True,\n})",
            "success": "OK",
            "result": "UNSAT",
            "took": "4.368704080581665",
            "stderr": "",
            "stdout": "Running in parallel with 12 processes\nOverapprox Round 1/3 has 1 set(s)\nLayer 1/5: LinearOnnxSubnetworkLayer (zono shape: (8192, 3175))... 0.591 sec\nLayer 2/5: ReluLayer (zono shape: (8192, 3175))... 0.369 sec\nLayer 3/5: LinearOnnxSubnetworkLayer (zono shape: (8192, 3394))... 0.754 sec\nLayer 4/5: ReluLayer (zono shape: (250, 3394))... 0.005 sec\nLayer 5/5: LinearOnnxSubnetworkLayer (zono shape: (250, 3436))... 0.05 sec\n\n\n\nTotal Stars: 1 (0 exact, 1 approx)\nRuntime: 3.3 sec\nCompleted work frac: 1.0\nNum Stars Copied Between Processes: 0\nNum Lps During Enumeration: 0\nTotal Num Lps: 0\n\nResult: network is SAFE\n"
        },
        {
            "network": "convBigRELU__PGD",
            "property": "cifar10_spec_idx_10_eps_0.00784",
            "timeout": "300",
            "verifier": "nnenum",
            "config": "Configuration(values={\n  'BRANCH_MODE': 0,\n  'COMPRESS_INIT_BOX': True,\n  'CONTRACT_LP_OPTIMIZED': True,\n  'CONTRACT_LP_TRACK_WITNESSES': True,\n  'CONTRACT_ZONOTOPE': False,\n  'CONTRACT_ZONOTOPE_LP': True,\n  'EAGER_BOUNDS': True,\n  'GLPK_FIRST_PRIMAL': True,\n  'GLPK_RESET_BEFORE_MINIMIZE': False,\n  'GLPK_TIMEOUT': 60,\n  'INF_OVERAPPROX_LP_TIMEOUT': False,\n  'INF_OVERAPPROX_MIN_GEN_LIMIT': False,\n  'OFFLOAD_CLOSEST_TO_ROOT': True,\n  'OVERAPPROX_BOTH_BOUNDS': False,\n  'OVERAPPROX_GEN_LIMIT_MULTIPLIER': 1.5,\n  'OVERAPPROX_LP_TIMEOUT': 1.0,\n  'OVERAPPROX_MIN_GEN_LIMIT': 50,\n  'OVERAPPROX_NEAR_ROOT_MAX_SPLITS': 2,\n  'SINGLE_SET': False,\n  'SKIP_COMPRESSED_CHECK': False,\n  'SKIP_CONSTRAINT_NORMALIZATION': False,\n  'SPLIT_IF_IDLE': True,\n  'SPLIT_ORDER': 1,\n  'SPLIT_TOLERANCE': 1e-08,\n  'TRY_QUICK_OVERAPPROX': True,\n})",
            "success": "ERR",
            "result": "ERR",
            "took": "0.9197063446044922",
            "stderr": "",
            "stdout": "Traceback (most recent call last):\n  File \"/home/tristan/.local/share/autoverify/verifiers/nnenum/tool/src/nnenum/nnenum.py\", line 175, in main\n    network = load_onnx_network_optimized(onnx_filename)\n  File \"/home/tristan/.local/share/autoverify/verifiers/nnenum/tool/src/nnenum/onnx_network.py\", line 294, in load_onnx_network_optimized\n    init = init_map[cur_node.input[1]]\nKeyError: '15'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/tristan/miniconda3/envs/__av__nnenum/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/home/tristan/miniconda3/envs/__av__nnenum/lib/python3.9/runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"/home/tristan/.local/share/autoverify/verifiers/nnenum/tool/src/nnenum/nnenum.py\", line 262, in <module>\n    main()\n  File \"/home/tristan/.local/share/autoverify/verifiers/nnenum/tool/src/nnenum/nnenum.py\", line 178, in main\n    network = load_onnx_network(onnx_filename)\n  File \"/home/tristan/.local/share/autoverify/verifiers/nnenum/tool/src/nnenum/onnx_network.py\", line 764, in load_onnx_network\n    assert o in Settings.ONNX_WHITELIST, f\"Onnx model contains node with op {o}, which may not be a linear operation. \" + \\\nAssertionError: Onnx model contains node with op Div, which may not be a linear operation. Updated Settings.WHITELIST if you want to override this.\n"
        },
        {
            "network": "convBigRELU__PGD",
            "property": "cifar10_spec_idx_10_eps_0.00784",
            "timeout": "300",
            "verifier": "abcrown",
            "config": "Configuration(values={\n  'attack__attack_mode': 'PGD',\n  'attack__enable_mip_attack': False,\n  'attack__pgd_order': 'before',\n  'bab__branching__input_split__enable': False,\n  'bab__branching__method': 'kfsb',\n  'bab__branching__reduceop': 'min',\n  'general__complete_verifier': 'bab',\n  'general__enable_incomplete_verification': True,\n  'general__loss_reduction_func': 'sum',\n  'solver__bound_prop_method': 'alpha-crown',\n})",
            "success": "OK",
            "result": "UNSAT",
            "took": "7.157538652420044",
            "stderr": "",
            "stdout": "/bin/bash: /home/tristan/miniconda3/envs/__av__abcrown/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nConfigurations:\n\ngeneral:\n  device: cuda\n  seed: 100\n  conv_mode: patches\n  deterministic: false\n  double_fp: false\n  loss_reduction_func: sum\n  record_bounds: false\n  sparse_alpha: true\n  save_adv_example: true\n  precompile_jit: false\n  complete_verifier: bab\n  enable_incomplete_verification: true\n  csv_name: null\n  results_file: /tmp/tmpsn0djnfs.txt\n  root_path: ''\nmodel:\n  name: null\n  path: null\n  onnx_path: /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/convBigRELU__PGD.onnx\n  onnx_path_prefix: ''\n  cache_onnx_conversion: false\n  onnx_quirks: null\n  input_shape: null\n  onnx_loader: default_onnx_and_vnnlib_loader\n  onnx_optimization_flags: none\ndata:\n  start: 0\n  end: 10000\n  select_instance: null\n  num_outputs: 10\n  mean: 0.0\n  std: 1.0\n  pkl_path: null\n  dataset: CIFAR\n  data_filter_path: null\n  data_idx_file: null\nspecification:\n  type: lp\n  robustness_type: verified-acc\n  norm: .inf\n  epsilon: null\n  vnnlib_path: /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_10_eps_0.00784.vnnlib\n  vnnlib_path_prefix: ''\nsolver:\n  batch_size: 512\n  min_batch_size_ratio: 0.1\n  use_float64_in_last_iteration: false\n  early_stop_patience: 10\n  start_save_best: 0.5\n  bound_prop_method: alpha-crown\n  prune_after_crown: false\n  crown:\n    batch_size: 1000000000\n    max_crown_size: 1000000000\n  alpha-crown:\n    alpha: true\n    lr_alpha: 0.1\n    iteration: 100\n    share_slopes: false\n    no_joint_opt: false\n    lr_decay: 0.98\n    full_conv_alpha: true\n  beta-crown:\n    lr_alpha: 0.01\n    lr_beta: 0.05\n    lr_decay: 0.98\n    optimizer: adam\n    iteration: 50\n    beta: true\n    beta_warmup: true\n    enable_opt_interm_bounds: false\n    all_node_split_LP: false\n  forward:\n    refine: false\n    dynamic: false\n    max_dim: 10000\n  multi_class:\n    multi_class_method: allclass_domain\n    label_batch_size: 32\n    skip_with_refined_bound: true\n  mip:\n    parallel_solvers: null\n    solver_threads: 1\n    refine_neuron_timeout: 15\n    refine_neuron_time_percentage: 0.8\n    early_stop: true\n    adv_warmup: true\n    mip_solver: gurobi\nbab:\n  initial_max_domains: 1\n  max_domains: .inf\n  decision_thresh: 0\n  timeout: 300.0\n  timeout_scale: 1\n  override_timeout: null\n  get_upper_bound: false\n  dfs_percent: 0.0\n  pruning_in_iteration: true\n  pruning_in_iteration_ratio: 0.2\n  sort_targets: false\n  batched_domain_list: true\n  optimized_intermediate_layers: ''\n  interm_transfer: true\n  cut:\n    enabled: false\n    bab_cut: false\n    lp_cut: false\n    method: null\n    lr: 0.01\n    lr_decay: 1.0\n    iteration: 100\n    bab_iteration: -1\n    early_stop_patience: -1\n    lr_beta: 0.02\n    number_cuts: 50\n    topk_cuts_in_filter: 100\n    batch_size_primal: 100\n    max_num: 1000000000\n    patches_cut: false\n    cplex_cuts: false\n    cplex_cuts_wait: 0\n    cplex_cuts_revpickup: true\n    cut_reference_bounds: true\n    fix_intermediate_bounds: false\n  branching:\n    method: kfsb\n    candidates: 3\n    reduceop: min\n    sb_coeff_thresh: 0.001\n    input_split:\n      enable: false\n      enhanced_bound_prop_method: alpha-crown\n      enhanced_branching_method: naive\n      enhanced_bound_patience: 100000000.0\n      attack_patience: 100000000.0\n      adv_check: 0\n      sort_domain_interval: -1\n  attack:\n    enabled: false\n    beam_candidates: 8\n    beam_depth: 7\n    max_dive_fix_ratio: 0.8\n    min_local_free_ratio: 0.2\n    mip_start_iteration: 5\n    mip_timeout: 30.0\n    adv_pool_threshold: null\n    refined_mip_attacker: false\n    refined_batch_size: null\nattack:\n  pgd_order: before\n  pgd_steps: 100\n  pgd_restarts: 30\n  pgd_early_stop: true\n  pgd_lr_decay: 0.99\n  pgd_alpha: auto\n  pgd_loss_mode: null\n  enable_mip_attack: false\n  cex_path: ./test_cex.txt\n  attack_mode: PGD\n  gama_lambda: 10.0\n  gama_decay: 0.9\n  check_clean: false\n  input_split:\n    pgd_steps: 100\n    pgd_restarts: 30\n    pgd_alpha: auto\n  input_split_enhanced:\n    pgd_steps: 200\n    pgd_restarts: 5000000\n    pgd_alpha: auto\n  input_split_check_adv:\n    pgd_steps: 5\n    pgd_restarts: 5\n    pgd_alpha: auto\ndebug:\n  lp_test: null\n\nExperiments at Mon May 13 21:15:52 2024 on Cerberus\nInternal results will be saved to /tmp/tmpsn0djnfs.txt.\n\n %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nUsing onnx /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/convBigRELU__PGD.onnx\nUsing vnnlib /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_10_eps_0.00784.vnnlib\nPrecompiled vnnlib file found at /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_10_eps_0.00784.vnnlib.compiled\nLoading onnx /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/convBigRELU__PGD.onnx wih quirks {}\n/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/onnx2pytorch/convert/layer.py:30: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_numpy.cpp:178.)\n  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))\n/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/onnx2pytorch/convert/model.py:154: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.\n  \"Using experimental implementation that allows 'batch_size > 1'.\"\nAttack parameters: initialization=uniform, steps=100, restarts=30, alpha=0.001960787922143936, initialization=uniform, GAMA=False\nModel output of first 5 examples:\n tensor([[ 1.43827474, -5.26821756, -0.24924204, -1.00314927, -1.42481220,\n         -1.00641870, -2.44114733, -2.40455437,  0.35379457, -4.80686331]],\n       device='cuda:0')\nAdv example prediction (first 2 examples and 2 restarts):\n tensor([[[ 1.35088444, -5.26208687, -0.27259591, -0.93527448, -1.39557958,\n          -0.94545192, -2.31221080, -2.32778692,  0.55532157, -4.74117327],\n         [ 1.35088444, -5.26208687, -0.27259591, -0.93527448, -1.39557958,\n          -0.94545192, -2.31221080, -2.32778692,  0.55532157, -4.74117327]]],\n       device='cuda:0')\nPGD attack margin (first 2 examles and 10 specs):\n tensor([[[6.61297131, 1.62348032, 2.28615904, 2.74646401, 2.29633641,\n          3.66309524, 3.67867136, 0.79556286, 6.09205770]]], device='cuda:0')\nnumber of violation:  0\nAttack finished in 1.6917 seconds.\nPGD attack failed\nModel prediction is: tensor([[ 1.43827474, -5.26821756, -0.24924204, -1.00314927, -1.42481220,\n         -1.00641870, -2.44114733, -2.40455437,  0.35379457, -4.80686331]],\n       device='cuda:0')\nlayer /34 using sparse-features alpha with shape [3119]; unstable size 3119; total size 32768 (torch.Size([1, 32, 32, 32]))\nlayer /34 start_node /input.7 using sparse-spec alpha with unstable size 153 total_size 8192 output_shape (32, 16, 16)\nlayer /34 start_node /input.11 using sparse-spec alpha with unstable size 49 total_size 64 output_shape 64\nlayer /34 start_node /input.15 using sparse-spec alpha with unstable size 79 total_size 4096 output_shape (64, 8, 8)\nlayer /34 start_node /input.19 using sparse-spec alpha with unstable size 41 total_size 512 output_shape torch.Size([512])\nlayer /34 start_node /input.23 using sparse-spec alpha with unstable size 67 total_size 512 output_shape torch.Size([512])\nlayer /34 start_node /46 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /36 using sparse-features alpha with shape [153]; unstable size 153; total size 8192 (torch.Size([1, 32, 16, 16]))\nlayer /36 start_node /input.11 using sparse-spec alpha with unstable size 49 total_size 64 output_shape 64\nlayer /36 start_node /input.15 using sparse-spec alpha with unstable size 79 total_size 4096 output_shape (64, 8, 8)\nlayer /36 start_node /input.19 using sparse-spec alpha with unstable size 41 total_size 512 output_shape torch.Size([512])\nlayer /36 start_node /input.23 using sparse-spec alpha with unstable size 67 total_size 512 output_shape torch.Size([512])\nlayer /36 start_node /46 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /38 using sparse-features alpha with shape [1252]; unstable size 1252; total size 16384 (torch.Size([1, 64, 16, 16]))\nlayer /38 start_node /input.15 using sparse-spec alpha with unstable size 79 total_size 4096 output_shape (64, 8, 8)\nlayer /38 start_node /input.19 using sparse-spec alpha with unstable size 41 total_size 512 output_shape torch.Size([512])\nlayer /38 start_node /input.23 using sparse-spec alpha with unstable size 67 total_size 512 output_shape torch.Size([512])\nlayer /38 start_node /46 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /40 using sparse-features alpha with shape [79]; unstable size 79; total size 4096 (torch.Size([1, 64, 8, 8]))\nlayer /40 start_node /input.19 using sparse-spec alpha with unstable size 41 total_size 512 output_shape torch.Size([512])\nlayer /40 start_node /input.23 using sparse-spec alpha with unstable size 67 total_size 512 output_shape torch.Size([512])\nlayer /40 start_node /46 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /43 using sparse-features alpha with shape [41]; unstable size 41; total size 512 (torch.Size([1, 512]))\nlayer /43 start_node /input.23 using sparse-spec alpha with unstable size 67 total_size 512 output_shape torch.Size([512])\nlayer /43 start_node /46 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /45 using sparse-features alpha with shape [67]; unstable size 67; total size 512 (torch.Size([1, 512]))\nlayer /45 start_node /46 using full alpha with unstable size None total_size 9 output_shape 9\nOptimizable variables initialized.\ninitial CROWN bounds: tensor([[5.06930113, 0.73012829, 1.20832062, 1.51309657, 0.97737694, 2.18857479,\n         2.55259204, 0.01476780, 4.82836056]], device='cuda:0') None\nverified with init bound!\nResult: unsat\nTime: 5.493030071258545\n"
        },
        {
            "network": "convBigRELU__PGD",
            "property": "cifar10_spec_idx_21_eps_0.00784",
            "timeout": "300",
            "verifier": "nnenum",
            "config": "Configuration(values={\n  'BRANCH_MODE': 0,\n  'COMPRESS_INIT_BOX': True,\n  'CONTRACT_LP_OPTIMIZED': True,\n  'CONTRACT_LP_TRACK_WITNESSES': True,\n  'CONTRACT_ZONOTOPE': False,\n  'CONTRACT_ZONOTOPE_LP': True,\n  'EAGER_BOUNDS': True,\n  'GLPK_FIRST_PRIMAL': True,\n  'GLPK_RESET_BEFORE_MINIMIZE': False,\n  'GLPK_TIMEOUT': 60,\n  'INF_OVERAPPROX_LP_TIMEOUT': False,\n  'INF_OVERAPPROX_MIN_GEN_LIMIT': False,\n  'OFFLOAD_CLOSEST_TO_ROOT': True,\n  'OVERAPPROX_BOTH_BOUNDS': False,\n  'OVERAPPROX_GEN_LIMIT_MULTIPLIER': 1.5,\n  'OVERAPPROX_LP_TIMEOUT': 1.0,\n  'OVERAPPROX_MIN_GEN_LIMIT': 50,\n  'OVERAPPROX_NEAR_ROOT_MAX_SPLITS': 2,\n  'SINGLE_SET': False,\n  'SKIP_COMPRESSED_CHECK': False,\n  'SKIP_CONSTRAINT_NORMALIZATION': False,\n  'SPLIT_IF_IDLE': True,\n  'SPLIT_ORDER': 1,\n  'SPLIT_TOLERANCE': 1e-08,\n  'TRY_QUICK_OVERAPPROX': True,\n})",
            "success": "ERR",
            "result": "ERR",
            "took": "0.8256158828735352",
            "stderr": "",
            "stdout": "Traceback (most recent call last):\n  File \"/home/tristan/.local/share/autoverify/verifiers/nnenum/tool/src/nnenum/nnenum.py\", line 175, in main\n    network = load_onnx_network_optimized(onnx_filename)\n  File \"/home/tristan/.local/share/autoverify/verifiers/nnenum/tool/src/nnenum/onnx_network.py\", line 294, in load_onnx_network_optimized\n    init = init_map[cur_node.input[1]]\nKeyError: '15'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/tristan/miniconda3/envs/__av__nnenum/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/home/tristan/miniconda3/envs/__av__nnenum/lib/python3.9/runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"/home/tristan/.local/share/autoverify/verifiers/nnenum/tool/src/nnenum/nnenum.py\", line 262, in <module>\n    main()\n  File \"/home/tristan/.local/share/autoverify/verifiers/nnenum/tool/src/nnenum/nnenum.py\", line 178, in main\n    network = load_onnx_network(onnx_filename)\n  File \"/home/tristan/.local/share/autoverify/verifiers/nnenum/tool/src/nnenum/onnx_network.py\", line 764, in load_onnx_network\n    assert o in Settings.ONNX_WHITELIST, f\"Onnx model contains node with op {o}, which may not be a linear operation. \" + \\\nAssertionError: Onnx model contains node with op Div, which may not be a linear operation. Updated Settings.WHITELIST if you want to override this.\n"
        },
        {
            "network": "convBigRELU__PGD",
            "property": "cifar10_spec_idx_21_eps_0.00784",
            "timeout": "300",
            "verifier": "abcrown",
            "config": "Configuration(values={\n  'attack__attack_mode': 'PGD',\n  'attack__enable_mip_attack': False,\n  'attack__pgd_order': 'before',\n  'bab__branching__input_split__enable': False,\n  'bab__branching__method': 'kfsb',\n  'bab__branching__reduceop': 'min',\n  'general__complete_verifier': 'bab',\n  'general__enable_incomplete_verification': True,\n  'general__loss_reduction_func': 'sum',\n  'solver__bound_prop_method': 'alpha-crown',\n})",
            "success": "OK",
            "result": "UNSAT",
            "took": "7.004596471786499",
            "stderr": "",
            "stdout": "/bin/bash: /home/tristan/miniconda3/envs/__av__abcrown/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nConfigurations:\n\ngeneral:\n  device: cuda\n  seed: 100\n  conv_mode: patches\n  deterministic: false\n  double_fp: false\n  loss_reduction_func: sum\n  record_bounds: false\n  sparse_alpha: true\n  save_adv_example: true\n  precompile_jit: false\n  complete_verifier: bab\n  enable_incomplete_verification: true\n  csv_name: null\n  results_file: /tmp/tmp0pjngunq.txt\n  root_path: ''\nmodel:\n  name: null\n  path: null\n  onnx_path: /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/convBigRELU__PGD.onnx\n  onnx_path_prefix: ''\n  cache_onnx_conversion: false\n  onnx_quirks: null\n  input_shape: null\n  onnx_loader: default_onnx_and_vnnlib_loader\n  onnx_optimization_flags: none\ndata:\n  start: 0\n  end: 10000\n  select_instance: null\n  num_outputs: 10\n  mean: 0.0\n  std: 1.0\n  pkl_path: null\n  dataset: CIFAR\n  data_filter_path: null\n  data_idx_file: null\nspecification:\n  type: lp\n  robustness_type: verified-acc\n  norm: .inf\n  epsilon: null\n  vnnlib_path: /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_21_eps_0.00784.vnnlib\n  vnnlib_path_prefix: ''\nsolver:\n  batch_size: 512\n  min_batch_size_ratio: 0.1\n  use_float64_in_last_iteration: false\n  early_stop_patience: 10\n  start_save_best: 0.5\n  bound_prop_method: alpha-crown\n  prune_after_crown: false\n  crown:\n    batch_size: 1000000000\n    max_crown_size: 1000000000\n  alpha-crown:\n    alpha: true\n    lr_alpha: 0.1\n    iteration: 100\n    share_slopes: false\n    no_joint_opt: false\n    lr_decay: 0.98\n    full_conv_alpha: true\n  beta-crown:\n    lr_alpha: 0.01\n    lr_beta: 0.05\n    lr_decay: 0.98\n    optimizer: adam\n    iteration: 50\n    beta: true\n    beta_warmup: true\n    enable_opt_interm_bounds: false\n    all_node_split_LP: false\n  forward:\n    refine: false\n    dynamic: false\n    max_dim: 10000\n  multi_class:\n    multi_class_method: allclass_domain\n    label_batch_size: 32\n    skip_with_refined_bound: true\n  mip:\n    parallel_solvers: null\n    solver_threads: 1\n    refine_neuron_timeout: 15\n    refine_neuron_time_percentage: 0.8\n    early_stop: true\n    adv_warmup: true\n    mip_solver: gurobi\nbab:\n  initial_max_domains: 1\n  max_domains: .inf\n  decision_thresh: 0\n  timeout: 300.0\n  timeout_scale: 1\n  override_timeout: null\n  get_upper_bound: false\n  dfs_percent: 0.0\n  pruning_in_iteration: true\n  pruning_in_iteration_ratio: 0.2\n  sort_targets: false\n  batched_domain_list: true\n  optimized_intermediate_layers: ''\n  interm_transfer: true\n  cut:\n    enabled: false\n    bab_cut: false\n    lp_cut: false\n    method: null\n    lr: 0.01\n    lr_decay: 1.0\n    iteration: 100\n    bab_iteration: -1\n    early_stop_patience: -1\n    lr_beta: 0.02\n    number_cuts: 50\n    topk_cuts_in_filter: 100\n    batch_size_primal: 100\n    max_num: 1000000000\n    patches_cut: false\n    cplex_cuts: false\n    cplex_cuts_wait: 0\n    cplex_cuts_revpickup: true\n    cut_reference_bounds: true\n    fix_intermediate_bounds: false\n  branching:\n    method: kfsb\n    candidates: 3\n    reduceop: min\n    sb_coeff_thresh: 0.001\n    input_split:\n      enable: false\n      enhanced_bound_prop_method: alpha-crown\n      enhanced_branching_method: naive\n      enhanced_bound_patience: 100000000.0\n      attack_patience: 100000000.0\n      adv_check: 0\n      sort_domain_interval: -1\n  attack:\n    enabled: false\n    beam_candidates: 8\n    beam_depth: 7\n    max_dive_fix_ratio: 0.8\n    min_local_free_ratio: 0.2\n    mip_start_iteration: 5\n    mip_timeout: 30.0\n    adv_pool_threshold: null\n    refined_mip_attacker: false\n    refined_batch_size: null\nattack:\n  pgd_order: before\n  pgd_steps: 100\n  pgd_restarts: 30\n  pgd_early_stop: true\n  pgd_lr_decay: 0.99\n  pgd_alpha: auto\n  pgd_loss_mode: null\n  enable_mip_attack: false\n  cex_path: ./test_cex.txt\n  attack_mode: PGD\n  gama_lambda: 10.0\n  gama_decay: 0.9\n  check_clean: false\n  input_split:\n    pgd_steps: 100\n    pgd_restarts: 30\n    pgd_alpha: auto\n  input_split_enhanced:\n    pgd_steps: 200\n    pgd_restarts: 5000000\n    pgd_alpha: auto\n  input_split_check_adv:\n    pgd_steps: 5\n    pgd_restarts: 5\n    pgd_alpha: auto\ndebug:\n  lp_test: null\n\nExperiments at Mon May 13 21:16:00 2024 on Cerberus\nInternal results will be saved to /tmp/tmp0pjngunq.txt.\n\n %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nUsing onnx /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/convBigRELU__PGD.onnx\nUsing vnnlib /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_21_eps_0.00784.vnnlib\nPrecompiled vnnlib file found at /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_21_eps_0.00784.vnnlib.compiled\nLoading onnx /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/convBigRELU__PGD.onnx wih quirks {}\n/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/onnx2pytorch/convert/layer.py:30: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_numpy.cpp:178.)\n  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))\n/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/onnx2pytorch/convert/model.py:154: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.\n  \"Using experimental implementation that allows 'batch_size > 1'.\"\nAttack parameters: initialization=uniform, steps=100, restarts=30, alpha=0.001960787922143936, initialization=uniform, GAMA=False\nModel output of first 5 examples:\n tensor([[ 2.14061451, -7.58005762,  1.55118299, -0.69311768, -1.58620059,\n         -3.66751027, -4.57932281, -5.63344622, -4.01265717, -7.37496614]],\n       device='cuda:0')\nAdv example prediction (first 2 examples and 2 restarts):\n tensor([[[ 2.07994413, -7.58967447,  1.58834994, -0.70260131, -1.58201480,\n          -3.65404916, -4.56366301, -5.60641527, -4.04987907, -7.38536358],\n         [ 2.07994413, -7.58967447,  1.58834994, -0.70260131, -1.58201480,\n          -3.65404916, -4.56366301, -5.60641527, -4.04987907, -7.38536358]]],\n       device='cuda:0')\nPGD attack margin (first 2 examles and 10 specs):\n tensor([[[9.66961861, 0.49159420, 2.78254557, 3.66195893, 5.73399353,\n          6.64360714, 7.68635941, 6.12982321, 9.46530724]]], device='cuda:0')\nnumber of violation:  0\nAttack finished in 1.7111 seconds.\nPGD attack failed\nModel prediction is: tensor([[ 2.14061451, -7.58005762,  1.55118299, -0.69311768, -1.58620059,\n         -3.66751027, -4.57932281, -5.63344622, -4.01265717, -7.37496614]],\n       device='cuda:0')\nlayer /34 using sparse-features alpha with shape [3565]; unstable size 3565; total size 32768 (torch.Size([1, 32, 32, 32]))\nlayer /34 start_node /input.7 using sparse-spec alpha with unstable size 12 total_size 8192 output_shape (32, 16, 16)\nlayer /34 start_node /input.11 using sparse-spec alpha with unstable size 282 total_size 16384 output_shape (64, 16, 16)\nlayer /34 start_node /input.15 using sparse-spec alpha with unstable size 14 total_size 4096 output_shape (64, 8, 8)\nlayer /34 start_node /input.19 using sparse-spec alpha with unstable size 7 total_size 512 output_shape torch.Size([512])\nlayer /34 start_node /input.23 using sparse-spec alpha with unstable size 9 total_size 512 output_shape torch.Size([512])\nlayer /34 start_node /46 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /36 using sparse-features alpha with shape [12]; unstable size 12; total size 8192 (torch.Size([1, 32, 16, 16]))\nlayer /36 start_node /input.11 using sparse-spec alpha with unstable size 282 total_size 16384 output_shape (64, 16, 16)\nlayer /36 start_node /input.15 using sparse-spec alpha with unstable size 14 total_size 4096 output_shape (64, 8, 8)\nlayer /36 start_node /input.19 using sparse-spec alpha with unstable size 7 total_size 512 output_shape torch.Size([512])\nlayer /36 start_node /input.23 using sparse-spec alpha with unstable size 9 total_size 512 output_shape torch.Size([512])\nlayer /36 start_node /46 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /38 using sparse-features alpha with shape [282]; unstable size 282; total size 16384 (torch.Size([1, 64, 16, 16]))\nlayer /38 start_node /input.15 using sparse-spec alpha with unstable size 14 total_size 4096 output_shape (64, 8, 8)\nlayer /38 start_node /input.19 using sparse-spec alpha with unstable size 7 total_size 512 output_shape torch.Size([512])\nlayer /38 start_node /input.23 using sparse-spec alpha with unstable size 9 total_size 512 output_shape torch.Size([512])\nlayer /38 start_node /46 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /40 using sparse-features alpha with shape [14]; unstable size 14; total size 4096 (torch.Size([1, 64, 8, 8]))\nlayer /40 start_node /input.19 using sparse-spec alpha with unstable size 7 total_size 512 output_shape torch.Size([512])\nlayer /40 start_node /input.23 using sparse-spec alpha with unstable size 9 total_size 512 output_shape torch.Size([512])\nlayer /40 start_node /46 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /43 using sparse-features alpha with shape [7]; unstable size 7; total size 512 (torch.Size([1, 512]))\nlayer /43 start_node /input.23 using sparse-spec alpha with unstable size 9 total_size 512 output_shape torch.Size([512])\nlayer /43 start_node /46 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /45 using sparse-features alpha with shape [9]; unstable size 9; total size 512 (torch.Size([1, 512]))\nlayer /45 start_node /46 using full alpha with unstable size None total_size 9 output_shape 9\nOptimizable variables initialized.\ninitial CROWN bounds: tensor([[9.27486134, 0.43070394, 2.65081620, 3.50906706, 5.58280373, 6.43016958,\n         7.46400547, 5.93557215, 9.23428917]], device='cuda:0') None\nverified with init bound!\nResult: unsat\nTime: 5.409303903579712\n"
        },
        {
            "network": "convBigRELU__PGD",
            "property": "cifar10_spec_idx_37_eps_0.00784",
            "timeout": "300",
            "verifier": "nnenum",
            "config": "Configuration(values={\n  'BRANCH_MODE': 0,\n  'COMPRESS_INIT_BOX': True,\n  'CONTRACT_LP_OPTIMIZED': True,\n  'CONTRACT_LP_TRACK_WITNESSES': True,\n  'CONTRACT_ZONOTOPE': False,\n  'CONTRACT_ZONOTOPE_LP': True,\n  'EAGER_BOUNDS': True,\n  'GLPK_FIRST_PRIMAL': True,\n  'GLPK_RESET_BEFORE_MINIMIZE': False,\n  'GLPK_TIMEOUT': 60,\n  'INF_OVERAPPROX_LP_TIMEOUT': False,\n  'INF_OVERAPPROX_MIN_GEN_LIMIT': False,\n  'OFFLOAD_CLOSEST_TO_ROOT': True,\n  'OVERAPPROX_BOTH_BOUNDS': False,\n  'OVERAPPROX_GEN_LIMIT_MULTIPLIER': 1.5,\n  'OVERAPPROX_LP_TIMEOUT': 1.0,\n  'OVERAPPROX_MIN_GEN_LIMIT': 50,\n  'OVERAPPROX_NEAR_ROOT_MAX_SPLITS': 2,\n  'SINGLE_SET': False,\n  'SKIP_COMPRESSED_CHECK': False,\n  'SKIP_CONSTRAINT_NORMALIZATION': False,\n  'SPLIT_IF_IDLE': True,\n  'SPLIT_ORDER': 1,\n  'SPLIT_TOLERANCE': 1e-08,\n  'TRY_QUICK_OVERAPPROX': True,\n})",
            "success": "ERR",
            "result": "ERR",
            "took": "0.810549259185791",
            "stderr": "",
            "stdout": "Traceback (most recent call last):\n  File \"/home/tristan/.local/share/autoverify/verifiers/nnenum/tool/src/nnenum/nnenum.py\", line 175, in main\n    network = load_onnx_network_optimized(onnx_filename)\n  File \"/home/tristan/.local/share/autoverify/verifiers/nnenum/tool/src/nnenum/onnx_network.py\", line 294, in load_onnx_network_optimized\n    init = init_map[cur_node.input[1]]\nKeyError: '15'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/tristan/miniconda3/envs/__av__nnenum/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/home/tristan/miniconda3/envs/__av__nnenum/lib/python3.9/runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"/home/tristan/.local/share/autoverify/verifiers/nnenum/tool/src/nnenum/nnenum.py\", line 262, in <module>\n    main()\n  File \"/home/tristan/.local/share/autoverify/verifiers/nnenum/tool/src/nnenum/nnenum.py\", line 178, in main\n    network = load_onnx_network(onnx_filename)\n  File \"/home/tristan/.local/share/autoverify/verifiers/nnenum/tool/src/nnenum/onnx_network.py\", line 764, in load_onnx_network\n    assert o in Settings.ONNX_WHITELIST, f\"Onnx model contains node with op {o}, which may not be a linear operation. \" + \\\nAssertionError: Onnx model contains node with op Div, which may not be a linear operation. Updated Settings.WHITELIST if you want to override this.\n"
        },
        {
            "network": "convBigRELU__PGD",
            "property": "cifar10_spec_idx_37_eps_0.00784",
            "timeout": "300",
            "verifier": "abcrown",
            "config": "Configuration(values={\n  'attack__attack_mode': 'PGD',\n  'attack__enable_mip_attack': False,\n  'attack__pgd_order': 'before',\n  'bab__branching__input_split__enable': False,\n  'bab__branching__method': 'kfsb',\n  'bab__branching__reduceop': 'min',\n  'general__complete_verifier': 'bab',\n  'general__enable_incomplete_verification': True,\n  'general__loss_reduction_func': 'sum',\n  'solver__bound_prop_method': 'alpha-crown',\n})",
            "success": "OK",
            "result": "UNSAT",
            "took": "7.135623216629028",
            "stderr": "",
            "stdout": "/bin/bash: /home/tristan/miniconda3/envs/__av__abcrown/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nConfigurations:\n\ngeneral:\n  device: cuda\n  seed: 100\n  conv_mode: patches\n  deterministic: false\n  double_fp: false\n  loss_reduction_func: sum\n  record_bounds: false\n  sparse_alpha: true\n  save_adv_example: true\n  precompile_jit: false\n  complete_verifier: bab\n  enable_incomplete_verification: true\n  csv_name: null\n  results_file: /tmp/tmpk_rum72a.txt\n  root_path: ''\nmodel:\n  name: null\n  path: null\n  onnx_path: /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/convBigRELU__PGD.onnx\n  onnx_path_prefix: ''\n  cache_onnx_conversion: false\n  onnx_quirks: null\n  input_shape: null\n  onnx_loader: default_onnx_and_vnnlib_loader\n  onnx_optimization_flags: none\ndata:\n  start: 0\n  end: 10000\n  select_instance: null\n  num_outputs: 10\n  mean: 0.0\n  std: 1.0\n  pkl_path: null\n  dataset: CIFAR\n  data_filter_path: null\n  data_idx_file: null\nspecification:\n  type: lp\n  robustness_type: verified-acc\n  norm: .inf\n  epsilon: null\n  vnnlib_path: /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_37_eps_0.00784.vnnlib\n  vnnlib_path_prefix: ''\nsolver:\n  batch_size: 512\n  min_batch_size_ratio: 0.1\n  use_float64_in_last_iteration: false\n  early_stop_patience: 10\n  start_save_best: 0.5\n  bound_prop_method: alpha-crown\n  prune_after_crown: false\n  crown:\n    batch_size: 1000000000\n    max_crown_size: 1000000000\n  alpha-crown:\n    alpha: true\n    lr_alpha: 0.1\n    iteration: 100\n    share_slopes: false\n    no_joint_opt: false\n    lr_decay: 0.98\n    full_conv_alpha: true\n  beta-crown:\n    lr_alpha: 0.01\n    lr_beta: 0.05\n    lr_decay: 0.98\n    optimizer: adam\n    iteration: 50\n    beta: true\n    beta_warmup: true\n    enable_opt_interm_bounds: false\n    all_node_split_LP: false\n  forward:\n    refine: false\n    dynamic: false\n    max_dim: 10000\n  multi_class:\n    multi_class_method: allclass_domain\n    label_batch_size: 32\n    skip_with_refined_bound: true\n  mip:\n    parallel_solvers: null\n    solver_threads: 1\n    refine_neuron_timeout: 15\n    refine_neuron_time_percentage: 0.8\n    early_stop: true\n    adv_warmup: true\n    mip_solver: gurobi\nbab:\n  initial_max_domains: 1\n  max_domains: .inf\n  decision_thresh: 0\n  timeout: 300.0\n  timeout_scale: 1\n  override_timeout: null\n  get_upper_bound: false\n  dfs_percent: 0.0\n  pruning_in_iteration: true\n  pruning_in_iteration_ratio: 0.2\n  sort_targets: false\n  batched_domain_list: true\n  optimized_intermediate_layers: ''\n  interm_transfer: true\n  cut:\n    enabled: false\n    bab_cut: false\n    lp_cut: false\n    method: null\n    lr: 0.01\n    lr_decay: 1.0\n    iteration: 100\n    bab_iteration: -1\n    early_stop_patience: -1\n    lr_beta: 0.02\n    number_cuts: 50\n    topk_cuts_in_filter: 100\n    batch_size_primal: 100\n    max_num: 1000000000\n    patches_cut: false\n    cplex_cuts: false\n    cplex_cuts_wait: 0\n    cplex_cuts_revpickup: true\n    cut_reference_bounds: true\n    fix_intermediate_bounds: false\n  branching:\n    method: kfsb\n    candidates: 3\n    reduceop: min\n    sb_coeff_thresh: 0.001\n    input_split:\n      enable: false\n      enhanced_bound_prop_method: alpha-crown\n      enhanced_branching_method: naive\n      enhanced_bound_patience: 100000000.0\n      attack_patience: 100000000.0\n      adv_check: 0\n      sort_domain_interval: -1\n  attack:\n    enabled: false\n    beam_candidates: 8\n    beam_depth: 7\n    max_dive_fix_ratio: 0.8\n    min_local_free_ratio: 0.2\n    mip_start_iteration: 5\n    mip_timeout: 30.0\n    adv_pool_threshold: null\n    refined_mip_attacker: false\n    refined_batch_size: null\nattack:\n  pgd_order: before\n  pgd_steps: 100\n  pgd_restarts: 30\n  pgd_early_stop: true\n  pgd_lr_decay: 0.99\n  pgd_alpha: auto\n  pgd_loss_mode: null\n  enable_mip_attack: false\n  cex_path: ./test_cex.txt\n  attack_mode: PGD\n  gama_lambda: 10.0\n  gama_decay: 0.9\n  check_clean: false\n  input_split:\n    pgd_steps: 100\n    pgd_restarts: 30\n    pgd_alpha: auto\n  input_split_enhanced:\n    pgd_steps: 200\n    pgd_restarts: 5000000\n    pgd_alpha: auto\n  input_split_check_adv:\n    pgd_steps: 5\n    pgd_restarts: 5\n    pgd_alpha: auto\ndebug:\n  lp_test: null\n\nExperiments at Mon May 13 21:16:08 2024 on Cerberus\nInternal results will be saved to /tmp/tmpk_rum72a.txt.\n\n %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nUsing onnx /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/convBigRELU__PGD.onnx\nUsing vnnlib /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_37_eps_0.00784.vnnlib\nPrecompiled vnnlib file found at /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_37_eps_0.00784.vnnlib.compiled\nLoading onnx /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/convBigRELU__PGD.onnx wih quirks {}\n/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/onnx2pytorch/convert/layer.py:30: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_numpy.cpp:178.)\n  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))\n/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/onnx2pytorch/convert/model.py:154: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.\n  \"Using experimental implementation that allows 'batch_size > 1'.\"\nAttack parameters: initialization=uniform, steps=100, restarts=30, alpha=0.001960787922143936, initialization=uniform, GAMA=False\nModel output of first 5 examples:\n tensor([[ 0.25571486,  3.77851868, -4.00916004, -3.22680521, -4.53054523,\n         -4.37565517, -5.53191614, -4.20376968,  0.47601944,  3.14984918]],\n       device='cuda:0')\nAdv example prediction (first 2 examples and 2 restarts):\n tensor([[[ 0.21722656,  3.55940342, -3.96903133, -3.15021801, -4.50026608,\n          -4.26555204, -5.46244669, -4.09355307,  0.32603645,  3.24944854],\n         [ 0.21722656,  3.55940342, -3.96903133, -3.15021801, -4.50026608,\n          -4.26555204, -5.46244669, -4.09355307,  0.32603645,  3.24944854]]],\n       device='cuda:0')\nPGD attack margin (first 2 examles and 10 specs):\n tensor([[[3.34217691, 7.52843475, 6.70962143, 8.05966949, 7.82495546,\n          9.02185059, 7.65295649, 3.23336697, 0.30995488]]], device='cuda:0')\nnumber of violation:  0\nAttack finished in 1.6938 seconds.\nPGD attack failed\nModel prediction is: tensor([[ 0.25571486,  3.77851868, -4.00916004, -3.22680521, -4.53054523,\n         -4.37565517, -5.53191614, -4.20376968,  0.47601944,  3.14984918]],\n       device='cuda:0')\nlayer /34 using sparse-features alpha with shape [2147]; unstable size 2147; total size 32768 (torch.Size([1, 32, 32, 32]))\nlayer /34 start_node /input.7 using sparse-spec alpha with unstable size 70 total_size 8192 output_shape (32, 16, 16)\nlayer /34 start_node /input.11 using sparse-spec alpha with unstable size 52 total_size 64 output_shape 64\nlayer /34 start_node /input.15 using sparse-spec alpha with unstable size 60 total_size 4096 output_shape (64, 8, 8)\nlayer /34 start_node /input.19 using sparse-spec alpha with unstable size 24 total_size 512 output_shape torch.Size([512])\nlayer /34 start_node /input.23 using sparse-spec alpha with unstable size 42 total_size 512 output_shape torch.Size([512])\nlayer /34 start_node /46 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /36 using sparse-features alpha with shape [70]; unstable size 70; total size 8192 (torch.Size([1, 32, 16, 16]))\nlayer /36 start_node /input.11 using sparse-spec alpha with unstable size 52 total_size 64 output_shape 64\nlayer /36 start_node /input.15 using sparse-spec alpha with unstable size 60 total_size 4096 output_shape (64, 8, 8)\nlayer /36 start_node /input.19 using sparse-spec alpha with unstable size 24 total_size 512 output_shape torch.Size([512])\nlayer /36 start_node /input.23 using sparse-spec alpha with unstable size 42 total_size 512 output_shape torch.Size([512])\nlayer /36 start_node /46 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /38 using sparse-features alpha with shape [731]; unstable size 731; total size 16384 (torch.Size([1, 64, 16, 16]))\nlayer /38 start_node /input.15 using sparse-spec alpha with unstable size 60 total_size 4096 output_shape (64, 8, 8)\nlayer /38 start_node /input.19 using sparse-spec alpha with unstable size 24 total_size 512 output_shape torch.Size([512])\nlayer /38 start_node /input.23 using sparse-spec alpha with unstable size 42 total_size 512 output_shape torch.Size([512])\nlayer /38 start_node /46 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /40 using sparse-features alpha with shape [60]; unstable size 60; total size 4096 (torch.Size([1, 64, 8, 8]))\nlayer /40 start_node /input.19 using sparse-spec alpha with unstable size 24 total_size 512 output_shape torch.Size([512])\nlayer /40 start_node /input.23 using sparse-spec alpha with unstable size 42 total_size 512 output_shape torch.Size([512])\nlayer /40 start_node /46 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /43 using sparse-features alpha with shape [24]; unstable size 24; total size 512 (torch.Size([1, 512]))\nlayer /43 start_node /input.23 using sparse-spec alpha with unstable size 42 total_size 512 output_shape torch.Size([512])\nlayer /43 start_node /46 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /45 using sparse-features alpha with shape [42]; unstable size 42; total size 512 (torch.Size([1, 512]))\nlayer /45 start_node /46 using full alpha with unstable size None total_size 9 output_shape 9\nOptimizable variables initialized.\ninitial CROWN bounds: tensor([[2.43055344, 6.70373440, 6.04302597, 7.19202328, 7.07307386, 8.29016590,\n         6.64738464, 2.35014200, 0.03637898]], device='cuda:0') None\nverified with init bound!\nResult: unsat\nTime: 5.500481605529785\n"
        },
        {
            "network": "convBigRELU__PGD",
            "property": "cifar10_spec_idx_50_eps_0.00784",
            "timeout": "300",
            "verifier": "nnenum",
            "config": "Configuration(values={\n  'BRANCH_MODE': 0,\n  'COMPRESS_INIT_BOX': True,\n  'CONTRACT_LP_OPTIMIZED': True,\n  'CONTRACT_LP_TRACK_WITNESSES': True,\n  'CONTRACT_ZONOTOPE': False,\n  'CONTRACT_ZONOTOPE_LP': True,\n  'EAGER_BOUNDS': True,\n  'GLPK_FIRST_PRIMAL': True,\n  'GLPK_RESET_BEFORE_MINIMIZE': False,\n  'GLPK_TIMEOUT': 60,\n  'INF_OVERAPPROX_LP_TIMEOUT': False,\n  'INF_OVERAPPROX_MIN_GEN_LIMIT': False,\n  'OFFLOAD_CLOSEST_TO_ROOT': True,\n  'OVERAPPROX_BOTH_BOUNDS': False,\n  'OVERAPPROX_GEN_LIMIT_MULTIPLIER': 1.5,\n  'OVERAPPROX_LP_TIMEOUT': 1.0,\n  'OVERAPPROX_MIN_GEN_LIMIT': 50,\n  'OVERAPPROX_NEAR_ROOT_MAX_SPLITS': 2,\n  'SINGLE_SET': False,\n  'SKIP_COMPRESSED_CHECK': False,\n  'SKIP_CONSTRAINT_NORMALIZATION': False,\n  'SPLIT_IF_IDLE': True,\n  'SPLIT_ORDER': 1,\n  'SPLIT_TOLERANCE': 1e-08,\n  'TRY_QUICK_OVERAPPROX': True,\n})",
            "success": "ERR",
            "result": "ERR",
            "took": "0.8878309726715088",
            "stderr": "",
            "stdout": "Traceback (most recent call last):\n  File \"/home/tristan/.local/share/autoverify/verifiers/nnenum/tool/src/nnenum/nnenum.py\", line 175, in main\n    network = load_onnx_network_optimized(onnx_filename)\n  File \"/home/tristan/.local/share/autoverify/verifiers/nnenum/tool/src/nnenum/onnx_network.py\", line 294, in load_onnx_network_optimized\n    init = init_map[cur_node.input[1]]\nKeyError: '15'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/tristan/miniconda3/envs/__av__nnenum/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/home/tristan/miniconda3/envs/__av__nnenum/lib/python3.9/runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"/home/tristan/.local/share/autoverify/verifiers/nnenum/tool/src/nnenum/nnenum.py\", line 262, in <module>\n    main()\n  File \"/home/tristan/.local/share/autoverify/verifiers/nnenum/tool/src/nnenum/nnenum.py\", line 178, in main\n    network = load_onnx_network(onnx_filename)\n  File \"/home/tristan/.local/share/autoverify/verifiers/nnenum/tool/src/nnenum/onnx_network.py\", line 764, in load_onnx_network\n    assert o in Settings.ONNX_WHITELIST, f\"Onnx model contains node with op {o}, which may not be a linear operation. \" + \\\nAssertionError: Onnx model contains node with op Div, which may not be a linear operation. Updated Settings.WHITELIST if you want to override this.\n"
        },
        {
            "network": "convBigRELU__PGD",
            "property": "cifar10_spec_idx_50_eps_0.00784",
            "timeout": "300",
            "verifier": "abcrown",
            "config": "Configuration(values={\n  'attack__attack_mode': 'PGD',\n  'attack__enable_mip_attack': False,\n  'attack__pgd_order': 'before',\n  'bab__branching__input_split__enable': False,\n  'bab__branching__method': 'kfsb',\n  'bab__branching__reduceop': 'min',\n  'general__complete_verifier': 'bab',\n  'general__enable_incomplete_verification': True,\n  'general__loss_reduction_func': 'sum',\n  'solver__bound_prop_method': 'alpha-crown',\n})",
            "success": "OK",
            "result": "UNSAT",
            "took": "7.020003795623779",
            "stderr": "",
            "stdout": "/bin/bash: /home/tristan/miniconda3/envs/__av__abcrown/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nConfigurations:\n\ngeneral:\n  device: cuda\n  seed: 100\n  conv_mode: patches\n  deterministic: false\n  double_fp: false\n  loss_reduction_func: sum\n  record_bounds: false\n  sparse_alpha: true\n  save_adv_example: true\n  precompile_jit: false\n  complete_verifier: bab\n  enable_incomplete_verification: true\n  csv_name: null\n  results_file: /tmp/tmpord9plvo.txt\n  root_path: ''\nmodel:\n  name: null\n  path: null\n  onnx_path: /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/convBigRELU__PGD.onnx\n  onnx_path_prefix: ''\n  cache_onnx_conversion: false\n  onnx_quirks: null\n  input_shape: null\n  onnx_loader: default_onnx_and_vnnlib_loader\n  onnx_optimization_flags: none\ndata:\n  start: 0\n  end: 10000\n  select_instance: null\n  num_outputs: 10\n  mean: 0.0\n  std: 1.0\n  pkl_path: null\n  dataset: CIFAR\n  data_filter_path: null\n  data_idx_file: null\nspecification:\n  type: lp\n  robustness_type: verified-acc\n  norm: .inf\n  epsilon: null\n  vnnlib_path: /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_50_eps_0.00784.vnnlib\n  vnnlib_path_prefix: ''\nsolver:\n  batch_size: 512\n  min_batch_size_ratio: 0.1\n  use_float64_in_last_iteration: false\n  early_stop_patience: 10\n  start_save_best: 0.5\n  bound_prop_method: alpha-crown\n  prune_after_crown: false\n  crown:\n    batch_size: 1000000000\n    max_crown_size: 1000000000\n  alpha-crown:\n    alpha: true\n    lr_alpha: 0.1\n    iteration: 100\n    share_slopes: false\n    no_joint_opt: false\n    lr_decay: 0.98\n    full_conv_alpha: true\n  beta-crown:\n    lr_alpha: 0.01\n    lr_beta: 0.05\n    lr_decay: 0.98\n    optimizer: adam\n    iteration: 50\n    beta: true\n    beta_warmup: true\n    enable_opt_interm_bounds: false\n    all_node_split_LP: false\n  forward:\n    refine: false\n    dynamic: false\n    max_dim: 10000\n  multi_class:\n    multi_class_method: allclass_domain\n    label_batch_size: 32\n    skip_with_refined_bound: true\n  mip:\n    parallel_solvers: null\n    solver_threads: 1\n    refine_neuron_timeout: 15\n    refine_neuron_time_percentage: 0.8\n    early_stop: true\n    adv_warmup: true\n    mip_solver: gurobi\nbab:\n  initial_max_domains: 1\n  max_domains: .inf\n  decision_thresh: 0\n  timeout: 300.0\n  timeout_scale: 1\n  override_timeout: null\n  get_upper_bound: false\n  dfs_percent: 0.0\n  pruning_in_iteration: true\n  pruning_in_iteration_ratio: 0.2\n  sort_targets: false\n  batched_domain_list: true\n  optimized_intermediate_layers: ''\n  interm_transfer: true\n  cut:\n    enabled: false\n    bab_cut: false\n    lp_cut: false\n    method: null\n    lr: 0.01\n    lr_decay: 1.0\n    iteration: 100\n    bab_iteration: -1\n    early_stop_patience: -1\n    lr_beta: 0.02\n    number_cuts: 50\n    topk_cuts_in_filter: 100\n    batch_size_primal: 100\n    max_num: 1000000000\n    patches_cut: false\n    cplex_cuts: false\n    cplex_cuts_wait: 0\n    cplex_cuts_revpickup: true\n    cut_reference_bounds: true\n    fix_intermediate_bounds: false\n  branching:\n    method: kfsb\n    candidates: 3\n    reduceop: min\n    sb_coeff_thresh: 0.001\n    input_split:\n      enable: false\n      enhanced_bound_prop_method: alpha-crown\n      enhanced_branching_method: naive\n      enhanced_bound_patience: 100000000.0\n      attack_patience: 100000000.0\n      adv_check: 0\n      sort_domain_interval: -1\n  attack:\n    enabled: false\n    beam_candidates: 8\n    beam_depth: 7\n    max_dive_fix_ratio: 0.8\n    min_local_free_ratio: 0.2\n    mip_start_iteration: 5\n    mip_timeout: 30.0\n    adv_pool_threshold: null\n    refined_mip_attacker: false\n    refined_batch_size: null\nattack:\n  pgd_order: before\n  pgd_steps: 100\n  pgd_restarts: 30\n  pgd_early_stop: true\n  pgd_lr_decay: 0.99\n  pgd_alpha: auto\n  pgd_loss_mode: null\n  enable_mip_attack: false\n  cex_path: ./test_cex.txt\n  attack_mode: PGD\n  gama_lambda: 10.0\n  gama_decay: 0.9\n  check_clean: false\n  input_split:\n    pgd_steps: 100\n    pgd_restarts: 30\n    pgd_alpha: auto\n  input_split_enhanced:\n    pgd_steps: 200\n    pgd_restarts: 5000000\n    pgd_alpha: auto\n  input_split_check_adv:\n    pgd_steps: 5\n    pgd_restarts: 5\n    pgd_alpha: auto\ndebug:\n  lp_test: null\n\nExperiments at Mon May 13 21:16:17 2024 on Cerberus\nInternal results will be saved to /tmp/tmpord9plvo.txt.\n\n %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nUsing onnx /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/convBigRELU__PGD.onnx\nUsing vnnlib /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_50_eps_0.00784.vnnlib\nPrecompiled vnnlib file found at /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_50_eps_0.00784.vnnlib.compiled\nLoading onnx /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/convBigRELU__PGD.onnx wih quirks {}\n/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/onnx2pytorch/convert/layer.py:30: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_numpy.cpp:178.)\n  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))\n/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/onnx2pytorch/convert/model.py:154: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.\n  \"Using experimental implementation that allows 'batch_size > 1'.\"\nAttack parameters: initialization=uniform, steps=100, restarts=30, alpha=0.001960787922143936, initialization=uniform, GAMA=False\nModel output of first 5 examples:\n tensor([[-0.88575494, -2.46948004, -0.98218197, -1.86838031, -2.75453448,\n         -3.04634857, -3.35564113, -0.76873565, -1.40446281,  0.81824809]],\n       device='cuda:0')\nAdv example prediction (first 2 examples and 2 restarts):\n tensor([[[-0.84236693, -2.81302500, -0.87701511, -1.80246806, -2.65725541,\n          -2.97314787, -3.35251307, -0.61052889, -1.43700242,  0.62772131],\n         [-0.84236693, -2.81302500, -0.87701511, -1.80246806, -2.65725541,\n          -2.97314787, -3.35251307, -0.61052889, -1.43700242,  0.62772131]]],\n       device='cuda:0')\nPGD attack margin (first 2 examles and 10 specs):\n tensor([[[1.47008824, 3.44074631, 1.50473642, 2.43018937, 3.28497672,\n          3.60086918, 3.98023438, 1.23825026, 2.06472373]]], device='cuda:0')\nnumber of violation:  0\nAttack finished in 1.7173 seconds.\nPGD attack failed\nModel prediction is: tensor([[-0.88575494, -2.46948004, -0.98218197, -1.86838031, -2.75453448,\n         -3.04634857, -3.35564113, -0.76873565, -1.40446281,  0.81824809]],\n       device='cuda:0')\nlayer /34 using sparse-features alpha with shape [2520]; unstable size 2520; total size 32768 (torch.Size([1, 32, 32, 32]))\nlayer /34 start_node /input.7 using sparse-spec alpha with unstable size 126 total_size 8192 output_shape (32, 16, 16)\nlayer /34 start_node /input.11 using sparse-spec alpha with unstable size 52 total_size 64 output_shape 64\nlayer /34 start_node /input.15 using sparse-spec alpha with unstable size 68 total_size 4096 output_shape (64, 8, 8)\nlayer /34 start_node /input.19 using sparse-spec alpha with unstable size 27 total_size 512 output_shape torch.Size([512])\nlayer /34 start_node /input.23 using sparse-spec alpha with unstable size 27 total_size 512 output_shape torch.Size([512])\nlayer /34 start_node /46 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /36 using sparse-features alpha with shape [126]; unstable size 126; total size 8192 (torch.Size([1, 32, 16, 16]))\nlayer /36 start_node /input.11 using sparse-spec alpha with unstable size 52 total_size 64 output_shape 64\nlayer /36 start_node /input.15 using sparse-spec alpha with unstable size 68 total_size 4096 output_shape (64, 8, 8)\nlayer /36 start_node /input.19 using sparse-spec alpha with unstable size 27 total_size 512 output_shape torch.Size([512])\nlayer /36 start_node /input.23 using sparse-spec alpha with unstable size 27 total_size 512 output_shape torch.Size([512])\nlayer /36 start_node /46 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /38 using sparse-features alpha with shape [956]; unstable size 956; total size 16384 (torch.Size([1, 64, 16, 16]))\nlayer /38 start_node /input.15 using sparse-spec alpha with unstable size 68 total_size 4096 output_shape (64, 8, 8)\nlayer /38 start_node /input.19 using sparse-spec alpha with unstable size 27 total_size 512 output_shape torch.Size([512])\nlayer /38 start_node /input.23 using sparse-spec alpha with unstable size 27 total_size 512 output_shape torch.Size([512])\nlayer /38 start_node /46 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /40 using sparse-features alpha with shape [68]; unstable size 68; total size 4096 (torch.Size([1, 64, 8, 8]))\nlayer /40 start_node /input.19 using sparse-spec alpha with unstable size 27 total_size 512 output_shape torch.Size([512])\nlayer /40 start_node /input.23 using sparse-spec alpha with unstable size 27 total_size 512 output_shape torch.Size([512])\nlayer /40 start_node /46 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /43 using sparse-features alpha with shape [27]; unstable size 27; total size 512 (torch.Size([1, 512]))\nlayer /43 start_node /input.23 using sparse-spec alpha with unstable size 27 total_size 512 output_shape torch.Size([512])\nlayer /43 start_node /46 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /45 using sparse-features alpha with shape [27]; unstable size 27; total size 512 (torch.Size([1, 512]))\nlayer /45 start_node /46 using full alpha with unstable size None total_size 9 output_shape 9\nOptimizable variables initialized.\ninitial CROWN bounds: tensor([[1.05932534, 2.63591576, 1.12628925, 2.04380655, 2.82444167, 3.17685604,\n         3.54555488, 0.90777135, 1.59514761]], device='cuda:0') None\nverified with init bound!\nResult: unsat\nTime: 5.468400478363037\n"
        },
        {
            "network": "convBigRELU__PGD",
            "property": "cifar10_spec_idx_64_eps_0.00784",
            "timeout": "300",
            "verifier": "nnenum",
            "config": "Configuration(values={\n  'BRANCH_MODE': 0,\n  'COMPRESS_INIT_BOX': True,\n  'CONTRACT_LP_OPTIMIZED': True,\n  'CONTRACT_LP_TRACK_WITNESSES': True,\n  'CONTRACT_ZONOTOPE': False,\n  'CONTRACT_ZONOTOPE_LP': True,\n  'EAGER_BOUNDS': True,\n  'GLPK_FIRST_PRIMAL': True,\n  'GLPK_RESET_BEFORE_MINIMIZE': False,\n  'GLPK_TIMEOUT': 60,\n  'INF_OVERAPPROX_LP_TIMEOUT': False,\n  'INF_OVERAPPROX_MIN_GEN_LIMIT': False,\n  'OFFLOAD_CLOSEST_TO_ROOT': True,\n  'OVERAPPROX_BOTH_BOUNDS': False,\n  'OVERAPPROX_GEN_LIMIT_MULTIPLIER': 1.5,\n  'OVERAPPROX_LP_TIMEOUT': 1.0,\n  'OVERAPPROX_MIN_GEN_LIMIT': 50,\n  'OVERAPPROX_NEAR_ROOT_MAX_SPLITS': 2,\n  'SINGLE_SET': False,\n  'SKIP_COMPRESSED_CHECK': False,\n  'SKIP_CONSTRAINT_NORMALIZATION': False,\n  'SPLIT_IF_IDLE': True,\n  'SPLIT_ORDER': 1,\n  'SPLIT_TOLERANCE': 1e-08,\n  'TRY_QUICK_OVERAPPROX': True,\n})",
            "success": "ERR",
            "result": "ERR",
            "took": "0.786963939666748",
            "stderr": "",
            "stdout": "Traceback (most recent call last):\n  File \"/home/tristan/.local/share/autoverify/verifiers/nnenum/tool/src/nnenum/nnenum.py\", line 175, in main\n    network = load_onnx_network_optimized(onnx_filename)\n  File \"/home/tristan/.local/share/autoverify/verifiers/nnenum/tool/src/nnenum/onnx_network.py\", line 294, in load_onnx_network_optimized\n    init = init_map[cur_node.input[1]]\nKeyError: '15'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/tristan/miniconda3/envs/__av__nnenum/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/home/tristan/miniconda3/envs/__av__nnenum/lib/python3.9/runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"/home/tristan/.local/share/autoverify/verifiers/nnenum/tool/src/nnenum/nnenum.py\", line 262, in <module>\n    main()\n  File \"/home/tristan/.local/share/autoverify/verifiers/nnenum/tool/src/nnenum/nnenum.py\", line 178, in main\n    network = load_onnx_network(onnx_filename)\n  File \"/home/tristan/.local/share/autoverify/verifiers/nnenum/tool/src/nnenum/onnx_network.py\", line 764, in load_onnx_network\n    assert o in Settings.ONNX_WHITELIST, f\"Onnx model contains node with op {o}, which may not be a linear operation. \" + \\\nAssertionError: Onnx model contains node with op Div, which may not be a linear operation. Updated Settings.WHITELIST if you want to override this.\n"
        },
        {
            "network": "convBigRELU__PGD",
            "property": "cifar10_spec_idx_64_eps_0.00784",
            "timeout": "300",
            "verifier": "abcrown",
            "config": "Configuration(values={\n  'attack__attack_mode': 'PGD',\n  'attack__enable_mip_attack': False,\n  'attack__pgd_order': 'before',\n  'bab__branching__input_split__enable': False,\n  'bab__branching__method': 'kfsb',\n  'bab__branching__reduceop': 'min',\n  'general__complete_verifier': 'bab',\n  'general__enable_incomplete_verification': True,\n  'general__loss_reduction_func': 'sum',\n  'solver__bound_prop_method': 'alpha-crown',\n})",
            "success": "OK",
            "result": "UNSAT",
            "took": "9.81209111213684",
            "stderr": "",
            "stdout": "/bin/bash: /home/tristan/miniconda3/envs/__av__abcrown/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nConfigurations:\n\ngeneral:\n  device: cuda\n  seed: 100\n  conv_mode: patches\n  deterministic: false\n  double_fp: false\n  loss_reduction_func: sum\n  record_bounds: false\n  sparse_alpha: true\n  save_adv_example: true\n  precompile_jit: false\n  complete_verifier: bab\n  enable_incomplete_verification: true\n  csv_name: null\n  results_file: /tmp/tmp6zvi4vrg.txt\n  root_path: ''\nmodel:\n  name: null\n  path: null\n  onnx_path: /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/convBigRELU__PGD.onnx\n  onnx_path_prefix: ''\n  cache_onnx_conversion: false\n  onnx_quirks: null\n  input_shape: null\n  onnx_loader: default_onnx_and_vnnlib_loader\n  onnx_optimization_flags: none\ndata:\n  start: 0\n  end: 10000\n  select_instance: null\n  num_outputs: 10\n  mean: 0.0\n  std: 1.0\n  pkl_path: null\n  dataset: CIFAR\n  data_filter_path: null\n  data_idx_file: null\nspecification:\n  type: lp\n  robustness_type: verified-acc\n  norm: .inf\n  epsilon: null\n  vnnlib_path: /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_64_eps_0.00784.vnnlib\n  vnnlib_path_prefix: ''\nsolver:\n  batch_size: 512\n  min_batch_size_ratio: 0.1\n  use_float64_in_last_iteration: false\n  early_stop_patience: 10\n  start_save_best: 0.5\n  bound_prop_method: alpha-crown\n  prune_after_crown: false\n  crown:\n    batch_size: 1000000000\n    max_crown_size: 1000000000\n  alpha-crown:\n    alpha: true\n    lr_alpha: 0.1\n    iteration: 100\n    share_slopes: false\n    no_joint_opt: false\n    lr_decay: 0.98\n    full_conv_alpha: true\n  beta-crown:\n    lr_alpha: 0.01\n    lr_beta: 0.05\n    lr_decay: 0.98\n    optimizer: adam\n    iteration: 50\n    beta: true\n    beta_warmup: true\n    enable_opt_interm_bounds: false\n    all_node_split_LP: false\n  forward:\n    refine: false\n    dynamic: false\n    max_dim: 10000\n  multi_class:\n    multi_class_method: allclass_domain\n    label_batch_size: 32\n    skip_with_refined_bound: true\n  mip:\n    parallel_solvers: null\n    solver_threads: 1\n    refine_neuron_timeout: 15\n    refine_neuron_time_percentage: 0.8\n    early_stop: true\n    adv_warmup: true\n    mip_solver: gurobi\nbab:\n  initial_max_domains: 1\n  max_domains: .inf\n  decision_thresh: 0\n  timeout: 300.0\n  timeout_scale: 1\n  override_timeout: null\n  get_upper_bound: false\n  dfs_percent: 0.0\n  pruning_in_iteration: true\n  pruning_in_iteration_ratio: 0.2\n  sort_targets: false\n  batched_domain_list: true\n  optimized_intermediate_layers: ''\n  interm_transfer: true\n  cut:\n    enabled: false\n    bab_cut: false\n    lp_cut: false\n    method: null\n    lr: 0.01\n    lr_decay: 1.0\n    iteration: 100\n    bab_iteration: -1\n    early_stop_patience: -1\n    lr_beta: 0.02\n    number_cuts: 50\n    topk_cuts_in_filter: 100\n    batch_size_primal: 100\n    max_num: 1000000000\n    patches_cut: false\n    cplex_cuts: false\n    cplex_cuts_wait: 0\n    cplex_cuts_revpickup: true\n    cut_reference_bounds: true\n    fix_intermediate_bounds: false\n  branching:\n    method: kfsb\n    candidates: 3\n    reduceop: min\n    sb_coeff_thresh: 0.001\n    input_split:\n      enable: false\n      enhanced_bound_prop_method: alpha-crown\n      enhanced_branching_method: naive\n      enhanced_bound_patience: 100000000.0\n      attack_patience: 100000000.0\n      adv_check: 0\n      sort_domain_interval: -1\n  attack:\n    enabled: false\n    beam_candidates: 8\n    beam_depth: 7\n    max_dive_fix_ratio: 0.8\n    min_local_free_ratio: 0.2\n    mip_start_iteration: 5\n    mip_timeout: 30.0\n    adv_pool_threshold: null\n    refined_mip_attacker: false\n    refined_batch_size: null\nattack:\n  pgd_order: before\n  pgd_steps: 100\n  pgd_restarts: 30\n  pgd_early_stop: true\n  pgd_lr_decay: 0.99\n  pgd_alpha: auto\n  pgd_loss_mode: null\n  enable_mip_attack: false\n  cex_path: ./test_cex.txt\n  attack_mode: PGD\n  gama_lambda: 10.0\n  gama_decay: 0.9\n  check_clean: false\n  input_split:\n    pgd_steps: 100\n    pgd_restarts: 30\n    pgd_alpha: auto\n  input_split_enhanced:\n    pgd_steps: 200\n    pgd_restarts: 5000000\n    pgd_alpha: auto\n  input_split_check_adv:\n    pgd_steps: 5\n    pgd_restarts: 5\n    pgd_alpha: auto\ndebug:\n  lp_test: null\n\nExperiments at Mon May 13 21:16:25 2024 on Cerberus\nInternal results will be saved to /tmp/tmp6zvi4vrg.txt.\n\n %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nUsing onnx /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/convBigRELU__PGD.onnx\nUsing vnnlib /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_64_eps_0.00784.vnnlib\nPrecompiled vnnlib file found at /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_64_eps_0.00784.vnnlib.compiled\nLoading onnx /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/convBigRELU__PGD.onnx wih quirks {}\n/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/onnx2pytorch/convert/layer.py:30: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_numpy.cpp:178.)\n  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))\n/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/onnx2pytorch/convert/model.py:154: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.\n  \"Using experimental implementation that allows 'batch_size > 1'.\"\nAttack parameters: initialization=uniform, steps=100, restarts=30, alpha=0.001960787922143936, initialization=uniform, GAMA=False\nModel output of first 5 examples:\n tensor([[-2.04189730, -1.39616895,  0.58027250,  0.29884806,  0.46679962,\n          0.18952516,  1.31852853, -0.25026628, -4.26790476, -1.34158278]],\n       device='cuda:0')\nAdv example prediction (first 2 examples and 2 restarts):\n tensor([[[-2.01591706, -1.55922532,  0.63024652,  0.30251116,  0.53322899,\n           0.23309767,  1.22137964, -0.18820685, -4.19713736, -1.40943885],\n         [-2.01591706, -1.55922532,  0.63024652,  0.30251116,  0.53322899,\n           0.23309767,  1.22137964, -0.18820685, -4.19713736, -1.40943885]]],\n       device='cuda:0')\nPGD attack margin (first 2 examles and 10 specs):\n tensor([[[3.23729658, 2.78060484, 0.59113312, 0.91886848, 0.68815064,\n          0.98828197, 1.40958643, 5.41851711, 2.63081837]]], device='cuda:0')\nnumber of violation:  0\nAttack finished in 1.7080 seconds.\nPGD attack failed\nModel prediction is: tensor([[-2.04189730, -1.39616895,  0.58027250,  0.29884806,  0.46679962,\n          0.18952516,  1.31852853, -0.25026628, -4.26790476, -1.34158278]],\n       device='cuda:0')\nlayer /34 using sparse-features alpha with shape [2044]; unstable size 2044; total size 32768 (torch.Size([1, 32, 32, 32]))\nlayer /34 start_node /input.7 using sparse-spec alpha with unstable size 138 total_size 8192 output_shape (32, 16, 16)\nlayer /34 start_node /input.11 using sparse-spec alpha with unstable size 50 total_size 64 output_shape 64\nlayer /34 start_node /input.15 using sparse-spec alpha with unstable size 124 total_size 4096 output_shape (64, 8, 8)\nlayer /34 start_node /input.19 using sparse-spec alpha with unstable size 49 total_size 512 output_shape torch.Size([512])\nlayer /34 start_node /input.23 using sparse-spec alpha with unstable size 90 total_size 512 output_shape torch.Size([512])\nlayer /34 start_node /46 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /36 using sparse-features alpha with shape [138]; unstable size 138; total size 8192 (torch.Size([1, 32, 16, 16]))\nlayer /36 start_node /input.11 using sparse-spec alpha with unstable size 50 total_size 64 output_shape 64\nlayer /36 start_node /input.15 using sparse-spec alpha with unstable size 124 total_size 4096 output_shape (64, 8, 8)\nlayer /36 start_node /input.19 using sparse-spec alpha with unstable size 49 total_size 512 output_shape torch.Size([512])\nlayer /36 start_node /input.23 using sparse-spec alpha with unstable size 90 total_size 512 output_shape torch.Size([512])\nlayer /36 start_node /46 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /38 using sparse-features alpha with shape [1413]; unstable size 1413; total size 16384 (torch.Size([1, 64, 16, 16]))\nlayer /38 start_node /input.15 using sparse-spec alpha with unstable size 124 total_size 4096 output_shape (64, 8, 8)\nlayer /38 start_node /input.19 using sparse-spec alpha with unstable size 49 total_size 512 output_shape torch.Size([512])\nlayer /38 start_node /input.23 using sparse-spec alpha with unstable size 90 total_size 512 output_shape torch.Size([512])\nlayer /38 start_node /46 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /40 using sparse-features alpha with shape [124]; unstable size 124; total size 4096 (torch.Size([1, 64, 8, 8]))\nlayer /40 start_node /input.19 using sparse-spec alpha with unstable size 49 total_size 512 output_shape torch.Size([512])\nlayer /40 start_node /input.23 using sparse-spec alpha with unstable size 90 total_size 512 output_shape torch.Size([512])\nlayer /40 start_node /46 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /43 using sparse-features alpha with shape [49]; unstable size 49; total size 512 (torch.Size([1, 512]))\nlayer /43 start_node /input.23 using sparse-spec alpha with unstable size 90 total_size 512 output_shape torch.Size([512])\nlayer /43 start_node /46 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /45 using sparse-features alpha with shape [90]; unstable size 90; total size 512 (torch.Size([1, 512]))\nlayer /45 start_node /46 using full alpha with unstable size None total_size 9 output_shape 9\nOptimizable variables initialized.\ninitial CROWN bounds: tensor([[ 1.81039202,  0.72419512, -0.10799131,  0.31532460,  0.10968983,\n          0.27898526,  0.39123285,  3.65472889,  0.96664262]], device='cuda:0') None\n\nall verified at 11th iter\nbest_l after optimization: 9.575699806213379 with beta sum per layer: []\nalpha/beta optimization time: 2.8800017833709717\ninitial alpha-CROWN bounds: tensor([[1.99569821e+00, 1.03388333e+00, 2.20695138e-03, 4.26993817e-01,\n         1.97594523e-01, 3.70850623e-01, 5.36541820e-01, 3.82398582e+00,\n         1.18794465e+00]], device='cuda:0')\nWorst class: (+ rhs) 0.002206951379776001\nverified with init bound!\nResult: unsat\nTime: 8.263221740722656\n"
        },
        {
            "network": "convBigRELU__PGD",
            "property": "cifar10_spec_idx_78_eps_0.00784",
            "timeout": "300",
            "verifier": "nnenum",
            "config": "Configuration(values={\n  'BRANCH_MODE': 0,\n  'COMPRESS_INIT_BOX': True,\n  'CONTRACT_LP_OPTIMIZED': True,\n  'CONTRACT_LP_TRACK_WITNESSES': True,\n  'CONTRACT_ZONOTOPE': False,\n  'CONTRACT_ZONOTOPE_LP': True,\n  'EAGER_BOUNDS': True,\n  'GLPK_FIRST_PRIMAL': True,\n  'GLPK_RESET_BEFORE_MINIMIZE': False,\n  'GLPK_TIMEOUT': 60,\n  'INF_OVERAPPROX_LP_TIMEOUT': False,\n  'INF_OVERAPPROX_MIN_GEN_LIMIT': False,\n  'OFFLOAD_CLOSEST_TO_ROOT': True,\n  'OVERAPPROX_BOTH_BOUNDS': False,\n  'OVERAPPROX_GEN_LIMIT_MULTIPLIER': 1.5,\n  'OVERAPPROX_LP_TIMEOUT': 1.0,\n  'OVERAPPROX_MIN_GEN_LIMIT': 50,\n  'OVERAPPROX_NEAR_ROOT_MAX_SPLITS': 2,\n  'SINGLE_SET': False,\n  'SKIP_COMPRESSED_CHECK': False,\n  'SKIP_CONSTRAINT_NORMALIZATION': False,\n  'SPLIT_IF_IDLE': True,\n  'SPLIT_ORDER': 1,\n  'SPLIT_TOLERANCE': 1e-08,\n  'TRY_QUICK_OVERAPPROX': True,\n})",
            "success": "ERR",
            "result": "ERR",
            "took": "0.7963173389434814",
            "stderr": "",
            "stdout": "Traceback (most recent call last):\n  File \"/home/tristan/.local/share/autoverify/verifiers/nnenum/tool/src/nnenum/nnenum.py\", line 175, in main\n    network = load_onnx_network_optimized(onnx_filename)\n  File \"/home/tristan/.local/share/autoverify/verifiers/nnenum/tool/src/nnenum/onnx_network.py\", line 294, in load_onnx_network_optimized\n    init = init_map[cur_node.input[1]]\nKeyError: '15'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/tristan/miniconda3/envs/__av__nnenum/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/home/tristan/miniconda3/envs/__av__nnenum/lib/python3.9/runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"/home/tristan/.local/share/autoverify/verifiers/nnenum/tool/src/nnenum/nnenum.py\", line 262, in <module>\n    main()\n  File \"/home/tristan/.local/share/autoverify/verifiers/nnenum/tool/src/nnenum/nnenum.py\", line 178, in main\n    network = load_onnx_network(onnx_filename)\n  File \"/home/tristan/.local/share/autoverify/verifiers/nnenum/tool/src/nnenum/onnx_network.py\", line 764, in load_onnx_network\n    assert o in Settings.ONNX_WHITELIST, f\"Onnx model contains node with op {o}, which may not be a linear operation. \" + \\\nAssertionError: Onnx model contains node with op Div, which may not be a linear operation. Updated Settings.WHITELIST if you want to override this.\n"
        },
        {
            "network": "convBigRELU__PGD",
            "property": "cifar10_spec_idx_78_eps_0.00784",
            "timeout": "300",
            "verifier": "abcrown",
            "config": "Configuration(values={\n  'attack__attack_mode': 'PGD',\n  'attack__enable_mip_attack': False,\n  'attack__pgd_order': 'before',\n  'bab__branching__input_split__enable': False,\n  'bab__branching__method': 'kfsb',\n  'bab__branching__reduceop': 'min',\n  'general__complete_verifier': 'bab',\n  'general__enable_incomplete_verification': True,\n  'general__loss_reduction_func': 'sum',\n  'solver__bound_prop_method': 'alpha-crown',\n})",
            "success": "ERR",
            "result": "ERR",
            "took": "229.54885387420654",
            "stderr": "",
            "stdout": "/bin/bash: /home/tristan/miniconda3/envs/__av__abcrown/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nConfigurations:\n\ngeneral:\n  device: cuda\n  seed: 100\n  conv_mode: patches\n  deterministic: false\n  double_fp: false\n  loss_reduction_func: sum\n  record_bounds: false\n  sparse_alpha: true\n  save_adv_example: true\n  precompile_jit: false\n  complete_verifier: bab\n  enable_incomplete_verification: true\n  csv_name: null\n  results_file: /tmp/tmp8rk5q__q.txt\n  root_path: ''\nmodel:\n  name: null\n  path: null\n  onnx_path: /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/convBigRELU__PGD.onnx\n  onnx_path_prefix: ''\n  cache_onnx_conversion: false\n  onnx_quirks: null\n  input_shape: null\n  onnx_loader: default_onnx_and_vnnlib_loader\n  onnx_optimization_flags: none\ndata:\n  start: 0\n  end: 10000\n  select_instance: null\n  num_outputs: 10\n  mean: 0.0\n  std: 1.0\n  pkl_path: null\n  dataset: CIFAR\n  data_filter_path: null\n  data_idx_file: null\nspecification:\n  type: lp\n  robustness_type: verified-acc\n  norm: .inf\n  epsilon: null\n  vnnlib_path: /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_78_eps_0.00784.vnnlib\n  vnnlib_path_prefix: ''\nsolver:\n  batch_size: 512\n  min_batch_size_ratio: 0.1\n  use_float64_in_last_iteration: false\n  early_stop_patience: 10\n  start_save_best: 0.5\n  bound_prop_method: alpha-crown\n  prune_after_crown: false\n  crown:\n    batch_size: 1000000000\n    max_crown_size: 1000000000\n  alpha-crown:\n    alpha: true\n    lr_alpha: 0.1\n    iteration: 100\n    share_slopes: false\n    no_joint_opt: false\n    lr_decay: 0.98\n    full_conv_alpha: true\n  beta-crown:\n    lr_alpha: 0.01\n    lr_beta: 0.05\n    lr_decay: 0.98\n    optimizer: adam\n    iteration: 50\n    beta: true\n    beta_warmup: true\n    enable_opt_interm_bounds: false\n    all_node_split_LP: false\n  forward:\n    refine: false\n    dynamic: false\n    max_dim: 10000\n  multi_class:\n    multi_class_method: allclass_domain\n    label_batch_size: 32\n    skip_with_refined_bound: true\n  mip:\n    parallel_solvers: null\n    solver_threads: 1\n    refine_neuron_timeout: 15\n    refine_neuron_time_percentage: 0.8\n    early_stop: true\n    adv_warmup: true\n    mip_solver: gurobi\nbab:\n  initial_max_domains: 1\n  max_domains: .inf\n  decision_thresh: 0\n  timeout: 300.0\n  timeout_scale: 1\n  override_timeout: null\n  get_upper_bound: false\n  dfs_percent: 0.0\n  pruning_in_iteration: true\n  pruning_in_iteration_ratio: 0.2\n  sort_targets: false\n  batched_domain_list: true\n  optimized_intermediate_layers: ''\n  interm_transfer: true\n  cut:\n    enabled: false\n    bab_cut: false\n    lp_cut: false\n    method: null\n    lr: 0.01\n    lr_decay: 1.0\n    iteration: 100\n    bab_iteration: -1\n    early_stop_patience: -1\n    lr_beta: 0.02\n    number_cuts: 50\n    topk_cuts_in_filter: 100\n    batch_size_primal: 100\n    max_num: 1000000000\n    patches_cut: false\n    cplex_cuts: false\n    cplex_cuts_wait: 0\n    cplex_cuts_revpickup: true\n    cut_reference_bounds: true\n    fix_intermediate_bounds: false\n  branching:\n    method: kfsb\n    candidates: 3\n    reduceop: min\n    sb_coeff_thresh: 0.001\n    input_split:\n      enable: false\n      enhanced_bound_prop_method: alpha-crown\n      enhanced_branching_method: naive\n      enhanced_bound_patience: 100000000.0\n      attack_patience: 100000000.0\n      adv_check: 0\n      sort_domain_interval: -1\n  attack:\n    enabled: false\n    beam_candidates: 8\n    beam_depth: 7\n    max_dive_fix_ratio: 0.8\n    min_local_free_ratio: 0.2\n    mip_start_iteration: 5\n    mip_timeout: 30.0\n    adv_pool_threshold: null\n    refined_mip_attacker: false\n    refined_batch_size: null\nattack:\n  pgd_order: before\n  pgd_steps: 100\n  pgd_restarts: 30\n  pgd_early_stop: true\n  pgd_lr_decay: 0.99\n  pgd_alpha: auto\n  pgd_loss_mode: null\n  enable_mip_attack: false\n  cex_path: ./test_cex.txt\n  attack_mode: PGD\n  gama_lambda: 10.0\n  gama_decay: 0.9\n  check_clean: false\n  input_split:\n    pgd_steps: 100\n    pgd_restarts: 30\n    pgd_alpha: auto\n  input_split_enhanced:\n    pgd_steps: 200\n    pgd_restarts: 5000000\n    pgd_alpha: auto\n  input_split_check_adv:\n    pgd_steps: 5\n    pgd_restarts: 5\n    pgd_alpha: auto\ndebug:\n  lp_test: null\n\nExperiments at Mon May 13 21:16:37 2024 on Cerberus\nInternal results will be saved to /tmp/tmp8rk5q__q.txt.\n\n %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nUsing onnx /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/convBigRELU__PGD.onnx\nUsing vnnlib /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_78_eps_0.00784.vnnlib\nPrecompiled vnnlib file found at /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_78_eps_0.00784.vnnlib.compiled\nLoading onnx /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/convBigRELU__PGD.onnx wih quirks {}\n/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/onnx2pytorch/convert/layer.py:30: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_numpy.cpp:178.)\n  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))\n/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/onnx2pytorch/convert/model.py:154: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.\n  \"Using experimental implementation that allows 'batch_size > 1'.\"\nAttack parameters: initialization=uniform, steps=100, restarts=30, alpha=0.001960787922143936, initialization=uniform, GAMA=False\nModel output of first 5 examples:\n tensor([[-2.14970326, -3.42058086,  0.84200227,  1.14106989,  0.81408489,\n          1.07924342,  0.76167828, -0.52608585, -3.17128658, -3.46410918]],\n       device='cuda:0')\nAdv example prediction (first 2 examples and 2 restarts):\n tensor([[[-2.12218428, -3.37873507,  0.83384383,  1.15502465,  0.81430137,\n           1.14255941,  0.72699016, -0.51800579, -3.24479532, -3.37587047],\n         [-2.12218428, -3.37873507,  0.83384383,  1.15502465,  0.81430137,\n           1.14255941,  0.72699016, -0.51800579, -3.24479532, -3.37587047]]],\n       device='cuda:0')\nPGD attack margin (first 2 examles and 10 specs):\n tensor([[[3.27720881, 4.53375959, 0.32118082, 0.34072328, 0.01246524,\n          0.42803448, 1.67303038, 4.39981985, 4.53089523]]], device='cuda:0')\nnumber of violation:  0\nAttack finished in 1.7720 seconds.\nPGD attack failed\nModel prediction is: tensor([[-2.14970326, -3.42058086,  0.84200227,  1.14106989,  0.81408489,\n          1.07924342,  0.76167828, -0.52608585, -3.17128658, -3.46410918]],\n       device='cuda:0')\nlayer /34 using sparse-features alpha with shape [1942]; unstable size 1942; total size 32768 (torch.Size([1, 32, 32, 32]))\nlayer /34 start_node /input.7 using sparse-spec alpha with unstable size 171 total_size 8192 output_shape (32, 16, 16)\nlayer /34 start_node /input.11 using sparse-spec alpha with unstable size 52 total_size 64 output_shape 64\nlayer /34 start_node /input.15 using sparse-spec alpha with unstable size 81 total_size 4096 output_shape (64, 8, 8)\nlayer /34 start_node /input.19 using sparse-spec alpha with unstable size 26 total_size 512 output_shape torch.Size([512])\nlayer /34 start_node /input.23 using sparse-spec alpha with unstable size 50 total_size 512 output_shape torch.Size([512])\nlayer /34 start_node /46 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /36 using sparse-features alpha with shape [171]; unstable size 171; total size 8192 (torch.Size([1, 32, 16, 16]))\nlayer /36 start_node /input.11 using sparse-spec alpha with unstable size 52 total_size 64 output_shape 64\nlayer /36 start_node /input.15 using sparse-spec alpha with unstable size 81 total_size 4096 output_shape (64, 8, 8)\nlayer /36 start_node /input.19 using sparse-spec alpha with unstable size 26 total_size 512 output_shape torch.Size([512])\nlayer /36 start_node /input.23 using sparse-spec alpha with unstable size 50 total_size 512 output_shape torch.Size([512])\nlayer /36 start_node /46 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /38 using sparse-features alpha with shape [1141]; unstable size 1141; total size 16384 (torch.Size([1, 64, 16, 16]))\nlayer /38 start_node /input.15 using sparse-spec alpha with unstable size 81 total_size 4096 output_shape (64, 8, 8)\nlayer /38 start_node /input.19 using sparse-spec alpha with unstable size 26 total_size 512 output_shape torch.Size([512])\nlayer /38 start_node /input.23 using sparse-spec alpha with unstable size 50 total_size 512 output_shape torch.Size([512])\nlayer /38 start_node /46 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /40 using sparse-features alpha with shape [81]; unstable size 81; total size 4096 (torch.Size([1, 64, 8, 8]))\nlayer /40 start_node /input.19 using sparse-spec alpha with unstable size 26 total_size 512 output_shape torch.Size([512])\nlayer /40 start_node /input.23 using sparse-spec alpha with unstable size 50 total_size 512 output_shape torch.Size([512])\nlayer /40 start_node /46 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /43 using sparse-features alpha with shape [26]; unstable size 26; total size 512 (torch.Size([1, 512]))\nlayer /43 start_node /input.23 using sparse-spec alpha with unstable size 50 total_size 512 output_shape torch.Size([512])\nlayer /43 start_node /46 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /45 using sparse-features alpha with shape [50]; unstable size 50; total size 512 (torch.Size([1, 512]))\nlayer /45 start_node /46 using full alpha with unstable size None total_size 9 output_shape 9\nOptimizable variables initialized.\ninitial CROWN bounds: tensor([[ 2.46627474,  3.58290195,  0.00764871,  0.03963804, -0.11114860,\n         -0.01987243,  1.07829607,  3.52050591,  3.87006426]], device='cuda:0') None\nbest_l after optimization: 14.863642692565918 with beta sum per layer: []\nalpha/beta optimization time: 10.229844570159912\ninitial alpha-CROWN bounds: tensor([[ 2.54750228e+00,  3.65458965e+00,  4.54754829e-02,  7.04846382e-02,\n         -9.75860357e-02,  2.63547897e-03,  1.12346363e+00,  3.59175682e+00,\n          3.92532063e+00]], device='cuda:0')\nWorst class: (+ rhs) -0.09758603572845459\nTotal VNNLIB file length: 9, max property batch size: 1, total number of batches: 9\nlA shape: [torch.Size([1, 9, 32, 32, 32]), torch.Size([1, 9, 32, 16, 16]), torch.Size([1, 9, 64, 16, 16]), torch.Size([1, 9, 64, 8, 8]), torch.Size([1, 9, 512]), torch.Size([1, 9, 512])]\n\nProperties batch 0, size 1\nRemaining timeout: 284.19744539260864\n##### Instance 0 first 10 spec matrices: [[[-1.  0.  0.  1.  0.  0.  0.  0.  0.  0.]]]\nthresholds: [0.] ######\nInitial alpha-CROWN verified for spec index [0] with bound 2.547502279281616.\n\nProperties batch 1, size 1\nRemaining timeout: 284.1558794975281\n##### Instance 0 first 10 spec matrices: [[[ 0. -1.  0.  1.  0.  0.  0.  0.  0.  0.]]]\nthresholds: [0.] ######\nInitial alpha-CROWN verified for spec index [0] with bound 3.6545896530151367.\n\nProperties batch 2, size 1\nRemaining timeout: 284.1251564025879\n##### Instance 0 first 10 spec matrices: [[[ 0.  0. -1.  1.  0.  0.  0.  0.  0.  0.]]]\nthresholds: [0.] ######\nInitial alpha-CROWN verified for spec index [0] with bound 0.04547548294067383.\n\nProperties batch 3, size 1\nRemaining timeout: 284.0964424610138\n##### Instance 0 first 10 spec matrices: [[[ 0.  0.  0.  1. -1.  0.  0.  0.  0.  0.]]]\nthresholds: [0.] ######\nInitial alpha-CROWN verified for spec index [0] with bound 0.07048463821411133.\n\nProperties batch 4, size 1\nRemaining timeout: 284.06738114356995\n##### Instance 0 first 10 spec matrices: [[[ 0.  0.  0.  1.  0. -1.  0.  0.  0.  0.]]]\nthresholds: [0.] ######\nRemaining spec index [0] with bounds tensor([[-0.09758604]], device='cuda:0') need to verify.\nModel prediction is: tensor([-2.14970326, -3.42058086,  0.84200227,  1.14106989,  0.81408489,\n         1.07924342,  0.76167828, -0.52608585, -3.17128658, -3.46410918],\n       device='cuda:0')\nbuild_the_model_with_refined_bounds batch [0/1]\nsetting alpha for layer /34 start_node /46 with alignment adjustment\nsetting alpha for layer /36 start_node /46 with alignment adjustment\nsetting alpha for layer /38 start_node /46 with alignment adjustment\nsetting alpha for layer /40 start_node /46 with alignment adjustment\nsetting alpha for layer /43 start_node /46 with alignment adjustment\nsetting alpha for layer /45 start_node /46 with alignment adjustment\nall slope initialized\ndirectly get lb and ub from refined bounds\nlA shapes: [torch.Size([1, 1, 32, 32, 32]), torch.Size([1, 1, 32, 16, 16]), torch.Size([1, 1, 64, 16, 16]), torch.Size([1, 1, 64, 8, 8]), torch.Size([1, 1, 512]), torch.Size([1, 1, 512])]\nc shape: torch.Size([1, 1, 10])\nalpha-CROWN with fixed intermediate bounds: tensor([[-0.09758604]], device='cuda:0') tensor([[inf]], device='cuda:0')\nKeeping slopes for these layers: ['/46']\nKeeping slopes for these layers: ['/46']\nlayer 0 size torch.Size([32768]) unstable 1942\nlayer 1 size torch.Size([8192]) unstable 166\nlayer 2 size torch.Size([16384]) unstable 1113\nlayer 3 size torch.Size([4096]) unstable 77\nlayer 4 size torch.Size([512]) unstable 25\nlayer 5 size torch.Size([512]) unstable 49\n-----------------\n# of unstable neurons: 3372\n-----------------\n\nbatch:  torch.Size([1, 32, 32, 32]) pre split depth:  5\nbatch:  torch.Size([1, 32, 32, 32]) post split depth:  5\nsplitting decisions: \nsplit level 0: [5, 112] \nsplit level 1: [4, 444] \nsplit level 2: [5, 419] \nsplit level 3: [5, 444] \nsplit level 4: [5, 202] \n(32, 3, 32, 32) torch.Size([32, 1, 10]) torch.Size([32, 1])\npruning_in_iteration open status: True\nratio of positive domain = 14 / 32 = 0.4375\npruning-in-iteration extra time: 0.03140544891357422\nTensors transferred: pre=3.8125M lA=1.0723M alpha=0.2082M beta=0.0002M\nThis batch time : update_bounds func: 0.9599\t prepare: 0.0023\t bound: 0.9523\t transfer: 0.0046\t finalize: 0.0006\nAccumulated time: update_bounds func: 0.9599\t prepare: 0.0023\t bound: 0.9523\t transfer: 0.0046\t finalize: 0.0006\nbatch bounding time:  0.9599359035491943\nCurrent worst splitting domains lb-rhs (depth):\n-0.06755 (5), -0.05573 (5), -0.05415 (5), -0.04667 (5), -0.04550 (5), -0.03473 (5), -0.02976 (5), -0.02654 (5), -0.02517 (5), -0.02263 (5), -0.01366 (5), -0.01080 (5), -0.00789 (5), -0.00785 (5), -0.00581 (5), -0.00557 (5), -0.00478 (5), -0.00445 (5), \nlength of domains: 18\nTotal time: 1.2033\t pickout: 0.0010\t decision: 0.2337\t get_bound: 0.9646\t add_domain: 0.0040\nAccumulated time:\t pickout: 0.0010\t decision: 0.2337\t get_bound: 0.9646\t add_domain: 0.0040\nCurrent (lb-rhs): -0.0675499439239502\n14 domains visited\nCumulative time: 1.4697020053863525\n\nbatch:  torch.Size([18, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([18, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [4, 36] [4, 166] [4, 36] [4, 166] [4, 36] [4, 395] [4, 36] [4, 395] [4, 36] [4, 395] \n(36, 3, 32, 32) torch.Size([36, 1, 10]) torch.Size([36, 1])\npruning_in_iteration open status: True\nratio of positive domain = 12 / 36 = 0.33333333333333337\npruning-in-iteration extra time: 0.030837297439575195\nTensors transferred: pre=4.2891M lA=1.4297M alpha=0.2342M beta=0.0002M\nThis batch time : update_bounds func: 0.7504\t prepare: 0.0034\t bound: 0.7414\t transfer: 0.0049\t finalize: 0.0006\nAccumulated time: update_bounds func: 1.7103\t prepare: 0.0057\t bound: 1.6937\t transfer: 0.0096\t finalize: 0.0012\nbatch bounding time:  0.7505109310150146\nCurrent worst splitting domains lb-rhs (depth):\n-0.05872 (6), -0.05512 (6), -0.04727 (6), -0.04578 (6), -0.04182 (6), -0.04008 (6), -0.03942 (6), -0.03905 (6), -0.03698 (6), -0.03044 (6), -0.02910 (6), -0.02629 (6), -0.02538 (6), -0.02119 (6), -0.02098 (6), -0.01910 (6), -0.01895 (6), -0.01839 (6), -0.01357 (6), -0.00458 (6), \nlength of domains: 24\nTotal time: 0.7879\t pickout: 0.0011\t decision: 0.0305\t get_bound: 0.7506\t add_domain: 0.0057\nAccumulated time:\t pickout: 0.0021\t decision: 0.2643\t get_bound: 1.7151\t add_domain: 0.0097\nCurrent (lb-rhs): -0.0587160587310791\n26 domains visited\nCumulative time: 2.2579333782196045\n\nbatch:  torch.Size([24, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([24, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [4, 316] [4, 395] [4, 316] [4, 395] [4, 316] [4, 166] [4, 359] [4, 166] [4, 359] [4, 166] \n(48, 3, 32, 32) torch.Size([48, 1, 10]) torch.Size([48, 1])\npruning_in_iteration open status: True\nratio of positive domain = 10 / 48 = 0.20833333333333337\npruning-in-iteration extra time: 0.007758378982543945\nTensors transferred: pre=5.7188M lA=2.2637M alpha=0.3123M beta=0.0004M\nThis batch time : update_bounds func: 0.6933\t prepare: 0.0035\t bound: 0.6831\t transfer: 0.0057\t finalize: 0.0010\nAccumulated time: update_bounds func: 2.4036\t prepare: 0.0092\t bound: 2.3768\t transfer: 0.0152\t finalize: 0.0022\nbatch bounding time:  0.6934056282043457\nCurrent worst splitting domains lb-rhs (depth):\n-0.05447 (7), -0.05081 (7), -0.04514 (7), -0.04290 (7), -0.04260 (7), -0.04246 (7), -0.03844 (7), -0.03811 (7), -0.03644 (7), -0.03600 (7), -0.03532 (7), -0.03352 (7), -0.03320 (7), -0.03210 (7), -0.03058 (7), -0.02987 (7), -0.02700 (7), -0.02597 (7), -0.02535 (7), -0.02505 (7), \nlength of domains: 38\nTotal time: 0.7366\t pickout: 0.0012\t decision: 0.0348\t get_bound: 0.6935\t add_domain: 0.0072\nAccumulated time:\t pickout: 0.0033\t decision: 0.2990\t get_bound: 2.4086\t add_domain: 0.0169\nCurrent (lb-rhs): -0.054467082023620605\n36 domains visited\nCumulative time: 2.994899272918701\n\nbatch:  torch.Size([38, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([38, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [5, 413] [5, 413] [5, 413] [4, 316] [5, 413] [4, 316] [5, 413] [4, 316] [4, 166] [5, 413] \n(76, 3, 32, 32) torch.Size([76, 1, 10]) torch.Size([76, 1])\npruning_in_iteration open status: False\nratio of positive domain = 7 / 76 = 0.09210526315789469\npruning-in-iteration extra time: 0.00016188621520996094\nTensors transferred: pre=9.0547M lA=4.5273M alpha=0.4945M beta=0.0007M\nThis batch time : update_bounds func: 0.6775\t prepare: 0.0047\t bound: 0.6588\t transfer: 0.0123\t finalize: 0.0016\nAccumulated time: update_bounds func: 3.0811\t prepare: 0.0139\t bound: 3.0356\t transfer: 0.0275\t finalize: 0.0038\nbatch bounding time:  0.6775500774383545\nCurrent worst splitting domains lb-rhs (depth):\n-0.05067 (8), -0.04708 (8), -0.04703 (8), -0.04333 (8), -0.04163 (8), -0.03980 (8), -0.03930 (8), -0.03879 (8), -0.03871 (8), -0.03560 (8), -0.03538 (8), -0.03508 (8), -0.03388 (8), -0.03363 (8), -0.03363 (8), -0.03348 (8), -0.03304 (8), -0.03292 (8), -0.03187 (8), -0.03141 (8), \nlength of domains: 69\nTotal time: 0.7308\t pickout: 0.0012\t decision: 0.0410\t get_bound: 0.6776\t add_domain: 0.0109\nAccumulated time:\t pickout: 0.0045\t decision: 0.3401\t get_bound: 3.0862\t add_domain: 0.0278\nCurrent (lb-rhs): -0.05066537857055664\n43 domains visited\nCumulative time: 3.7266085147857666\n\nbatch:  torch.Size([69, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([69, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [4, 166] [4, 166] [4, 89] [5, 413] [4, 359] [5, 413] [4, 359] [5, 413] [4, 166] [4, 89] \n(138, 3, 32, 32) torch.Size([138, 1, 10]) torch.Size([138, 1])\npruning_in_iteration open status: False\nratio of positive domain = 22 / 138 = 0.1594202898550725\npruning-in-iteration extra time: 0.00016069412231445312\nTensors transferred: pre=16.4414M lA=8.2207M alpha=0.8978M beta=0.0013M\nThis batch time : update_bounds func: 0.7389\t prepare: 0.0070\t bound: 0.7050\t transfer: 0.0247\t finalize: 0.0021\nAccumulated time: update_bounds func: 3.8200\t prepare: 0.0209\t bound: 3.7406\t transfer: 0.0522\t finalize: 0.0059\nbatch bounding time:  0.7389407157897949\nCurrent worst splitting domains lb-rhs (depth):\n-0.04770 (9), -0.04637 (9), -0.04419 (9), -0.04410 (9), -0.04219 (9), -0.04212 (9), -0.04041 (9), -0.03856 (9), -0.03784 (9), -0.03744 (9), -0.03717 (9), -0.03642 (9), -0.03585 (9), -0.03578 (9), -0.03458 (9), -0.03320 (9), -0.03319 (9), -0.03233 (9), -0.03229 (9), -0.03104 (9), \nlength of domains: 116\nTotal time: 0.8180\t pickout: 0.0029\t decision: 0.0603\t get_bound: 0.7390\t add_domain: 0.0158\nAccumulated time:\t pickout: 0.0074\t decision: 0.4004\t get_bound: 3.8252\t add_domain: 0.0436\nCurrent (lb-rhs): -0.047699570655822754\n65 domains visited\nCumulative time: 4.545287609100342\n\nbatch:  torch.Size([116, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([116, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [4, 89] [5, 281] [4, 395] [4, 395] [4, 89] [5, 281] [4, 89] [5, 281] [4, 166] [4, 395] \n(232, 3, 32, 32) torch.Size([232, 1, 10]) torch.Size([232, 1])\npruning_in_iteration open status: True\nratio of positive domain = 52 / 232 = 0.22413793103448276\npruning-in-iteration extra time: 0.02811908721923828\nTensors transferred: pre=27.6406M lA=10.7227M alpha=1.5094M beta=0.0027M\nThis batch time : update_bounds func: 0.9402\t prepare: 0.0117\t bound: 0.8892\t transfer: 0.0353\t finalize: 0.0038\nAccumulated time: update_bounds func: 4.7602\t prepare: 0.0326\t bound: 4.6298\t transfer: 0.0875\t finalize: 0.0097\nbatch bounding time:  0.9403140544891357\nCurrent worst splitting domains lb-rhs (depth):\n-0.04478 (10), -0.04331 (10), -0.04140 (10), -0.04135 (10), -0.04002 (10), -0.03923 (10), -0.03905 (10), -0.03863 (10), -0.03750 (10), -0.03653 (10), -0.03563 (10), -0.03554 (10), -0.03529 (10), -0.03463 (10), -0.03442 (10), -0.03376 (10), -0.03375 (10), -0.03307 (10), -0.03290 (10), -0.03279 (10), \nlength of domains: 180\nTotal time: 1.0558\t pickout: 0.0046\t decision: 0.0865\t get_bound: 0.9404\t add_domain: 0.0243\nAccumulated time:\t pickout: 0.0120\t decision: 0.4869\t get_bound: 4.7656\t add_domain: 0.0679\nCurrent (lb-rhs): -0.0447840690612793\n117 domains visited\nCumulative time: 5.602027893066406\n\nbatch:  torch.Size([180, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([180, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [4, 395] [4, 166] [4, 166] [5, 281] [4, 348] [4, 359] [5, 413] [5, 281] [4, 395] [4, 166] \n(360, 3, 32, 32) torch.Size([360, 1, 10]) torch.Size([360, 1])\npruning_in_iteration open status: True\nratio of positive domain = 111 / 360 = 0.30833333333333335\npruning-in-iteration extra time: 0.036149024963378906\nTensors transferred: pre=42.8906M lA=14.8330M alpha=2.3421M beta=0.0045M\nThis batch time : update_bounds func: 1.1849\t prepare: 0.0184\t bound: 1.1007\t transfer: 0.0599\t finalize: 0.0055\nAccumulated time: update_bounds func: 5.9450\t prepare: 0.0510\t bound: 5.7305\t transfer: 0.1475\t finalize: 0.0151\nbatch bounding time:  1.1850731372833252\nCurrent worst splitting domains lb-rhs (depth):\n-0.04209 (11), -0.04013 (11), -0.03864 (11), -0.03861 (11), -0.03725 (11), -0.03589 (11), -0.03584 (11), -0.03571 (11), -0.03476 (11), -0.03360 (11), -0.03359 (11), -0.03281 (11), -0.03281 (11), -0.03208 (11), -0.03164 (11), -0.03091 (11), -0.03074 (11), -0.03072 (11), -0.03063 (11), -0.03037 (11), \nlength of domains: 249\nTotal time: 1.3710\t pickout: 0.0067\t decision: 0.1419\t get_bound: 1.1852\t add_domain: 0.0373\nAccumulated time:\t pickout: 0.0187\t decision: 0.6287\t get_bound: 5.9508\t add_domain: 0.1052\nCurrent (lb-rhs): -0.04209423065185547\n228 domains visited\nCumulative time: 6.974578619003296\n\nbatch:  torch.Size([249, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([249, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [4, 348] [4, 89] [4, 348] [4, 348] [4, 89] [4, 348] [4, 348] [5, 281] [4, 89] [5, 281] \n(498, 3, 32, 32) torch.Size([498, 1, 10]) torch.Size([498, 1])\npruning_in_iteration open status: True\nratio of positive domain = 165 / 498 = 0.3313253012048193\npruning-in-iteration extra time: 0.0361332893371582\nTensors transferred: pre=59.3320M lA=19.8369M alpha=3.2400M beta=0.0071M\nThis batch time : update_bounds func: 1.4356\t prepare: 0.0255\t bound: 1.3407\t transfer: 0.0618\t finalize: 0.0072\nAccumulated time: update_bounds func: 7.3807\t prepare: 0.0765\t bound: 7.0712\t transfer: 0.2093\t finalize: 0.0223\nbatch bounding time:  1.4358227252960205\nCurrent worst splitting domains lb-rhs (depth):\n-0.04000 (12), -0.03833 (12), -0.03647 (12), -0.03643 (12), -0.03630 (12), -0.03516 (12), -0.03432 (12), -0.03401 (12), -0.03391 (12), -0.03386 (12), -0.03378 (12), -0.03340 (12), -0.03244 (12), -0.03138 (12), -0.03110 (12), -0.03104 (12), -0.03094 (12), -0.03082 (12), -0.03076 (12), -0.03048 (12), \nlength of domains: 333\nTotal time: 1.6765\t pickout: 0.0091\t decision: 0.1823\t get_bound: 1.4359\t add_domain: 0.0492\nAccumulated time:\t pickout: 0.0278\t decision: 0.8111\t get_bound: 7.3867\t add_domain: 0.1543\nCurrent (lb-rhs): -0.039997100830078125\n393 domains visited\nCumulative time: 8.652796268463135\n\nbatch:  torch.Size([333, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([333, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [4, 348] [4, 348] [4, 348] [4, 348] [4, 348] [4, 348] [4, 348] [4, 348] [4, 348] [4, 348] \n(666, 3, 32, 32) torch.Size([666, 1, 10]) torch.Size([666, 1])\npruning_in_iteration open status: True\nratio of positive domain = 317 / 666 = 0.47597597597597596\npruning-in-iteration extra time: 0.0787506103515625\nTensors transferred: pre=79.3477M lA=20.7900M alpha=4.3330M beta=0.0108M\nThis batch time : update_bounds func: 1.8857\t prepare: 0.0335\t bound: 1.7579\t transfer: 0.0842\t finalize: 0.0094\nAccumulated time: update_bounds func: 9.2664\t prepare: 0.1100\t bound: 8.8291\t transfer: 0.2935\t finalize: 0.0317\nbatch bounding time:  1.8859009742736816\nCurrent worst splitting domains lb-rhs (depth):\n-0.03834 (13), -0.03612 (13), -0.03471 (13), -0.03469 (13), -0.03453 (13), -0.03336 (13), -0.03205 (13), -0.03180 (13), -0.03179 (13), -0.03159 (13), -0.03142 (13), -0.03136 (13), -0.03074 (13), -0.02953 (13), -0.02950 (13), -0.02911 (13), -0.02905 (13), -0.02876 (13), -0.02873 (13), -0.02862 (13), \nlength of domains: 349\nTotal time: 2.4989\t pickout: 0.0118\t decision: 0.5472\t get_bound: 1.8860\t add_domain: 0.0539\nAccumulated time:\t pickout: 0.0396\t decision: 1.3583\t get_bound: 9.2726\t add_domain: 0.2082\nCurrent (lb-rhs): -0.03834211826324463\n710 domains visited\nCumulative time: 11.154294967651367\n\nbatch:  torch.Size([349, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([349, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [4, 348] [5, 45] [5, 45] [5, 45] [5, 45] [5, 45] [4, 348] [5, 281] [5, 45] [5, 45] \n(698, 3, 32, 32) torch.Size([698, 1, 10]) torch.Size([698, 1])\npruning_in_iteration open status: True\nratio of positive domain = 369 / 698 = 0.5286532951289398\npruning-in-iteration extra time: 0.0451512336730957\nTensors transferred: pre=83.1602M lA=19.6582M alpha=4.5412M beta=0.0120M\nThis batch time : update_bounds func: 2.3062\t prepare: 0.0527\t bound: 2.1504\t transfer: 0.0910\t finalize: 0.0111\nAccumulated time: update_bounds func: 11.5726\t prepare: 0.1626\t bound: 10.9795\t transfer: 0.3845\t finalize: 0.0428\nbatch bounding time:  2.3064162731170654\nCurrent worst splitting domains lb-rhs (depth):\n-0.03685 (14), -0.03455 (14), -0.03322 (14), -0.03321 (14), -0.03289 (14), -0.03191 (14), -0.03045 (14), -0.03038 (14), -0.03016 (14), -0.02998 (14), -0.02988 (14), -0.02975 (14), -0.02924 (14), -0.02813 (14), -0.02806 (14), -0.02780 (14), -0.02778 (14), -0.02721 (14), -0.02712 (14), -0.02703 (14), \nlength of domains: 329\nTotal time: 4.1165\t pickout: 0.0124\t decision: 1.7422\t get_bound: 2.3065\t add_domain: 0.0554\nAccumulated time:\t pickout: 0.0520\t decision: 3.1005\t get_bound: 11.5791\t add_domain: 0.2636\nCurrent (lb-rhs): -0.03684556484222412\n1079 domains visited\nCumulative time: 15.274687767028809\n\nbatch:  torch.Size([329, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([329, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [5, 281] [5, 281] [5, 281] [5, 281] [5, 281] [5, 281] [5, 281] [5, 281] [5, 281] [5, 281] \n(658, 3, 32, 32) torch.Size([658, 1, 10]) torch.Size([658, 1])\npruning_in_iteration open status: True\nratio of positive domain = 348 / 658 = 0.5288753799392097\npruning-in-iteration extra time: 0.04157876968383789\nTensors transferred: pre=78.3945M lA=18.5264M alpha=4.2809M beta=0.0126M\nThis batch time : update_bounds func: 2.3370\t prepare: 0.0325\t bound: 2.2087\t transfer: 0.0854\t finalize: 0.0098\nAccumulated time: update_bounds func: 13.9096\t prepare: 0.1952\t bound: 13.1882\t transfer: 0.4699\t finalize: 0.0526\nbatch bounding time:  2.3372833728790283\nCurrent worst splitting domains lb-rhs (depth):\n-0.03540 (15), -0.03313 (15), -0.03182 (15), -0.03176 (15), -0.03134 (15), -0.03046 (15), -0.02893 (15), -0.02885 (15), -0.02852 (15), -0.02851 (15), -0.02841 (15), -0.02831 (15), -0.02783 (15), -0.02707 (15), -0.02668 (15), -0.02628 (15), -0.02600 (15), -0.02578 (15), -0.02564 (15), -0.02542 (15), \nlength of domains: 310\nTotal time: 2.6949\t pickout: 0.0117\t decision: 0.2955\t get_bound: 2.3374\t add_domain: 0.0503\nAccumulated time:\t pickout: 0.0637\t decision: 3.3960\t get_bound: 13.9165\t add_domain: 0.3139\nCurrent (lb-rhs): -0.035396575927734375\n1427 domains visited\nCumulative time: 17.972584009170532\n\nbatch:  torch.Size([310, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([310, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [3, 1876] [5, 454] [4, 251] [5, 354] [4, 348] [4, 348] [5, 354] [3, 1876] [4, 329] [4, 329] \n(620, 3, 32, 32) torch.Size([620, 1, 10]) torch.Size([620, 1])\npruning_in_iteration open status: True\nratio of positive domain = 265 / 620 = 0.42741935483870963\npruning-in-iteration extra time: 0.042026519775390625\nTensors transferred: pre=73.8672M lA=21.1475M alpha=4.0337M beta=0.0124M\nThis batch time : update_bounds func: 2.3844\t prepare: 0.0293\t bound: 2.2550\t transfer: 0.0888\t finalize: 0.0107\nAccumulated time: update_bounds func: 16.2940\t prepare: 0.2245\t bound: 15.4431\t transfer: 0.5587\t finalize: 0.0633\nbatch bounding time:  2.384612560272217\nCurrent worst splitting domains lb-rhs (depth):\n-0.03438 (16), -0.03222 (16), -0.03080 (16), -0.03072 (16), -0.03030 (16), -0.02945 (16), -0.02792 (16), -0.02784 (16), -0.02758 (16), -0.02749 (16), -0.02735 (16), -0.02725 (16), -0.02681 (16), -0.02634 (16), -0.02595 (16), -0.02565 (16), -0.02526 (16), -0.02494 (16), -0.02473 (16), -0.02457 (16), \nlength of domains: 355\nTotal time: 2.7366\t pickout: 0.0119\t decision: 0.2802\t get_bound: 2.3847\t add_domain: 0.0598\nAccumulated time:\t pickout: 0.0756\t decision: 3.6763\t get_bound: 16.3012\t add_domain: 0.3737\nCurrent (lb-rhs): -0.03438103199005127\n1692 domains visited\nCumulative time: 20.711734771728516\n\nbatch:  torch.Size([355, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([355, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [4, 55] [3, 1876] [4, 329] [4, 329] [4, 329] [5, 40] [5, 40] [5, 40] [4, 251] [4, 251] \n(710, 3, 32, 32) torch.Size([710, 1, 10]) torch.Size([710, 1])\npruning_in_iteration open status: True\nratio of positive domain = 333 / 710 = 0.4690140845070423\npruning-in-iteration extra time: 0.04110455513000488\nTensors transferred: pre=84.5898M lA=22.4580M alpha=4.6192M beta=0.0149M\nThis batch time : update_bounds func: 2.4043\t prepare: 0.0350\t bound: 2.2636\t transfer: 0.0943\t finalize: 0.0108\nAccumulated time: update_bounds func: 18.6984\t prepare: 0.2595\t bound: 17.7067\t transfer: 0.6531\t finalize: 0.0741\nbatch bounding time:  2.4045674800872803\nCurrent worst splitting domains lb-rhs (depth):\n-0.03352 (17), -0.03126 (17), -0.02996 (17), -0.02949 (17), -0.02940 (17), -0.02893 (17), -0.02857 (17), -0.02701 (17), -0.02697 (17), -0.02655 (17), -0.02652 (17), -0.02643 (17), -0.02638 (17), -0.02599 (17), -0.02541 (17), -0.02507 (17), -0.02480 (17), -0.02435 (17), -0.02398 (17), -0.02387 (17), \nlength of domains: 377\nTotal time: 8.3481\t pickout: 0.0130\t decision: 5.8671\t get_bound: 2.4046\t add_domain: 0.0633\nAccumulated time:\t pickout: 0.0886\t decision: 9.5433\t get_bound: 18.7058\t add_domain: 0.4371\nCurrent (lb-rhs): -0.03351724147796631\n2025 domains visited\nCumulative time: 29.062987565994263\n\nbatch:  torch.Size([377, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([377, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [5, 454] [5, 313] [4, 348] [5, 454] [5, 40] [3, 3316] [3, 3316] [5, 454] [5, 201] [5, 201] \n(754, 3, 32, 32) torch.Size([754, 1, 10]) torch.Size([754, 1])\npruning_in_iteration open status: True\nratio of positive domain = 331 / 754 = 0.4389920424403183\npruning-in-iteration extra time: 0.09111666679382324\nTensors transferred: pre=89.8320M lA=25.1982M alpha=4.9055M beta=0.0173M\nThis batch time : update_bounds func: 3.4412\t prepare: 0.1723\t bound: 3.1433\t transfer: 0.1104\t finalize: 0.0131\nAccumulated time: update_bounds func: 22.1396\t prepare: 0.4318\t bound: 20.8500\t transfer: 0.7635\t finalize: 0.0872\nbatch bounding time:  3.4414680004119873\nCurrent worst splitting domains lb-rhs (depth):\n-0.03262 (18), -0.03037 (18), -0.02908 (18), -0.02860 (18), -0.02845 (18), -0.02803 (18), -0.02768 (18), -0.02606 (18), -0.02603 (18), -0.02568 (18), -0.02562 (18), -0.02549 (18), -0.02546 (18), -0.02513 (18), -0.02448 (18), -0.02417 (18), -0.02393 (18), -0.02346 (18), -0.02310 (18), -0.02309 (18), \nlength of domains: 423\nTotal time: 10.1654\t pickout: 0.0138\t decision: 6.6417\t get_bound: 3.4416\t add_domain: 0.0683\nAccumulated time:\t pickout: 0.1024\t decision: 16.1851\t get_bound: 22.1474\t add_domain: 0.5054\nCurrent (lb-rhs): -0.032624125480651855\n2356 domains visited\nCumulative time: 39.23184943199158\n\nbatch:  torch.Size([423, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([423, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [5, 313] [4, 89] [5, 40] [3, 3316] [5, 454] [5, 454] [3, 3316] [3, 3316] [3, 3316] [4, 329] \n(846, 3, 32, 32) torch.Size([846, 1, 10]) torch.Size([846, 1])\npruning_in_iteration open status: True\nratio of positive domain = 379 / 846 = 0.4479905437352246\npruning-in-iteration extra time: 0.056830644607543945\nTensors transferred: pre=100.7930M lA=27.8193M alpha=5.5040M beta=0.0210M\nThis batch time : update_bounds func: 3.9505\t prepare: 0.1195\t bound: 3.4126\t transfer: 0.3948\t finalize: 0.0226\nAccumulated time: update_bounds func: 26.0901\t prepare: 0.5513\t bound: 24.2627\t transfer: 1.1583\t finalize: 0.1098\nbatch bounding time:  3.9508044719696045\nCurrent worst splitting domains lb-rhs (depth):\n-0.03182 (19), -0.02933 (19), -0.02840 (19), -0.02830 (19), -0.02774 (19), -0.02761 (19), -0.02717 (19), -0.02689 (19), -0.02522 (19), -0.02516 (19), -0.02472 (19), -0.02463 (19), -0.02462 (19), -0.02461 (19), -0.02428 (19), -0.02392 (19), -0.02389 (19), -0.02370 (19), -0.02360 (19), -0.02323 (19), \nlength of domains: 467\nTotal time: 11.7813\t pickout: 0.0154\t decision: 7.7232\t get_bound: 3.9509\t add_domain: 0.0918\nAccumulated time:\t pickout: 0.1178\t decision: 23.9082\t get_bound: 26.0984\t add_domain: 0.5972\nCurrent (lb-rhs): -0.03182196617126465\n2735 domains visited\nCumulative time: 51.01763129234314\n\nbatch:  torch.Size([467, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([467, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [5, 40] [5, 454] [3, 1876] [3, 1876] [5, 124] [4, 329] [4, 329] [3, 1876] [5, 40] [5, 124] \n(934, 3, 32, 32) torch.Size([934, 1, 10]) torch.Size([934, 1])\npruning_in_iteration open status: True\nratio of positive domain = 387 / 934 = 0.4143468950749465\npruning-in-iteration extra time: 0.04649806022644043\nTensors transferred: pre=111.2773M lA=32.5850M alpha=6.0766M beta=0.0232M\nThis batch time : update_bounds func: 3.6851\t prepare: 0.0463\t bound: 3.3243\t transfer: 0.2980\t finalize: 0.0155\nAccumulated time: update_bounds func: 29.7751\t prepare: 0.5976\t bound: 27.5870\t transfer: 1.4562\t finalize: 0.1253\nbatch bounding time:  3.685518503189087\nCurrent worst splitting domains lb-rhs (depth):\n-0.03073 (20), -0.03011 (20), -0.02852 (20), -0.02758 (20), -0.02726 (20), -0.02686 (20), -0.02685 (20), -0.02654 (20), -0.02630 (20), -0.02599 (20), -0.02598 (20), -0.02500 (20), -0.02438 (20), -0.02394 (20), -0.02393 (20), -0.02375 (20), -0.02366 (20), -0.02356 (20), -0.02354 (20), -0.02327 (20), \nlength of domains: 547\nTotal time: 12.6499\t pickout: 0.0170\t decision: 8.8347\t get_bound: 3.6856\t add_domain: 0.1125\nAccumulated time:\t pickout: 0.1348\t decision: 32.7429\t get_bound: 29.7840\t add_domain: 0.7097\nCurrent (lb-rhs): -0.030732393264770508\n3122 domains visited\nCumulative time: 63.67299795150757\n\nbatch:  torch.Size([512, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([512, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [5, 454] [3, 3286] [3, 1876] [3, 1876] [3, 3627] [4, 329] [5, 96] [4, 329] [4, 329] [5, 96] \n(1024, 3, 32, 32) torch.Size([1024, 1, 10]) torch.Size([1024, 1])\npruning_in_iteration open status: True\nratio of positive domain = 445 / 1024 = 0.4345703125\npruning-in-iteration extra time: 0.05217766761779785\nTensors transferred: pre=122.0000M lA=34.4912M alpha=6.6621M beta=0.0273M\nThis batch time : update_bounds func: 4.6903\t prepare: 0.0497\t bound: 3.9281\t transfer: 0.6954\t finalize: 0.0162\nAccumulated time: update_bounds func: 34.4654\t prepare: 0.6474\t bound: 31.5151\t transfer: 2.1516\t finalize: 0.1415\nbatch bounding time:  4.690735578536987\nCurrent worst splitting domains lb-rhs (depth):\n-0.02996 (21), -0.02933 (21), -0.02777 (21), -0.02681 (21), -0.02654 (21), -0.02613 (21), -0.02600 (21), -0.02574 (21), -0.02541 (21), -0.02520 (21), -0.02516 (21), -0.02418 (21), -0.02365 (21), -0.02315 (21), -0.02306 (21), -0.02291 (21), -0.02284 (21), -0.02276 (21), -0.02266 (21), -0.02249 (21), \nlength of domains: 614\nTotal time: 17.3894\t pickout: 0.0198\t decision: 12.5030\t get_bound: 4.6908\t add_domain: 0.1758\nAccumulated time:\t pickout: 0.1546\t decision: 45.2460\t get_bound: 34.4748\t add_domain: 0.8855\nCurrent (lb-rhs): -0.029959678649902344\n3567 domains visited\nCumulative time: 81.06847167015076\n\nbatch:  torch.Size([512, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([512, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [5, 96] [3, 1876] [5, 96] [4, 55] [3, 3294] [3, 1876] [3, 1876] [4, 55] [5, 96] [5, 96] \n(1024, 3, 32, 32) torch.Size([1024, 1, 10]) torch.Size([1024, 1])\npruning_in_iteration open status: True\nratio of positive domain = 376 / 1024 = 0.3671875\npruning-in-iteration extra time: 0.05318307876586914\nTensors transferred: pre=122.0000M lA=38.6016M alpha=6.6621M beta=0.0273M\nThis batch time : update_bounds func: 4.5117\t prepare: 0.0499\t bound: 4.1405\t transfer: 0.2651\t finalize: 0.0551\nAccumulated time: update_bounds func: 38.9770\t prepare: 0.6972\t bound: 35.6556\t transfer: 2.4168\t finalize: 0.1966\nbatch bounding time:  4.512306213378906\nCurrent worst splitting domains lb-rhs (depth):\n-0.02925 (22), -0.02860 (22), -0.02777 (21), -0.02614 (22), -0.02582 (22), -0.02540 (22), -0.02521 (22), -0.02498 (22), -0.02472 (22), -0.02461 (22), -0.02451 (22), -0.02439 (22), -0.02413 (22), -0.02355 (22), -0.02347 (22), -0.02311 (22), -0.02242 (22), -0.02225 (22), -0.02220 (22), -0.02207 (22), \nlength of domains: 750\nTotal time: 14.7982\t pickout: 0.0293\t decision: 10.1308\t get_bound: 4.5124\t add_domain: 0.1257\nAccumulated time:\t pickout: 0.1838\t decision: 55.3767\t get_bound: 38.9872\t add_domain: 1.0112\nCurrent (lb-rhs): -0.029248595237731934\n3943 domains visited\nCumulative time: 95.87111520767212\n\nbatch:  torch.Size([512, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([512, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [5, 96] [5, 454] [3, 3316] [3, 1883] [3, 1883] [3, 1883] [3, 1883] [5, 454] [3, 670] [5, 96] \n(1024, 3, 32, 32) torch.Size([1024, 1, 10]) torch.Size([1024, 1])\npruning_in_iteration open status: True\nratio of positive domain = 356 / 1024 = 0.34765625\npruning-in-iteration extra time: 0.04915928840637207\nTensors transferred: pre=122.0000M lA=39.7930M alpha=6.6621M beta=0.0283M\nThis batch time : update_bounds func: 4.6289\t prepare: 0.0498\t bound: 4.2981\t transfer: 0.2486\t finalize: 0.0316\nAccumulated time: update_bounds func: 43.6060\t prepare: 0.7470\t bound: 39.9537\t transfer: 2.6654\t finalize: 0.2282\nbatch bounding time:  4.6296164989471436\nCurrent worst splitting domains lb-rhs (depth):\n-0.02925 (22), -0.02792 (23), -0.02777 (21), -0.02660 (23), -0.02582 (22), -0.02531 (23), -0.02498 (22), -0.02467 (23), -0.02451 (22), -0.02451 (23), -0.02447 (23), -0.02413 (22), -0.02389 (23), -0.02386 (23), -0.02370 (23), -0.02358 (23), -0.02355 (22), -0.02311 (22), -0.02309 (23), -0.02284 (23), \nlength of domains: 906\nTotal time: 14.5476\t pickout: 0.0184\t decision: 9.7607\t get_bound: 4.6297\t add_domain: 0.1388\nAccumulated time:\t pickout: 0.2022\t decision: 65.1374\t get_bound: 43.6169\t add_domain: 1.1501\nCurrent (lb-rhs): -0.029248595237731934\n4299 domains visited\nCumulative time: 110.423583984375\n\nbatch:  torch.Size([512, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([512, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [5, 454] [5, 454] [3, 1883] [5, 454] [5, 40] [5, 454] [5, 454] [3, 1258] [4, 55] [5, 454] \n(1024, 3, 32, 32) torch.Size([1024, 1, 10]) torch.Size([1024, 1])\npruning_in_iteration open status: True\nratio of positive domain = 294 / 1024 = 0.287109375\npruning-in-iteration extra time: 0.04638791084289551\nTensors transferred: pre=122.0000M lA=43.4863M alpha=6.6621M beta=0.0283M\nThis batch time : update_bounds func: 4.4224\t prepare: 0.0550\t bound: 4.1799\t transfer: 0.1708\t finalize: 0.0156\nAccumulated time: update_bounds func: 48.0284\t prepare: 0.8020\t bound: 44.1335\t transfer: 2.8362\t finalize: 0.2438\nbatch bounding time:  4.4228410720825195\nCurrent worst splitting domains lb-rhs (depth):\n-0.02925 (22), -0.02777 (21), -0.02711 (24), -0.02660 (23), -0.02616 (24), -0.02582 (22), -0.02498 (22), -0.02485 (24), -0.02451 (22), -0.02413 (22), -0.02397 (24), -0.02389 (23), -0.02386 (24), -0.02369 (24), -0.02358 (23), -0.02355 (22), -0.02311 (22), -0.02309 (24), -0.02307 (24), -0.02293 (24), \nlength of domains: 1124\nTotal time: 16.3437\t pickout: 0.0188\t decision: 11.1384\t get_bound: 4.4229\t add_domain: 0.7636\nAccumulated time:\t pickout: 0.2210\t decision: 76.2758\t get_bound: 48.0399\t add_domain: 1.9136\nCurrent (lb-rhs): -0.029248595237731934\n4593 domains visited\nCumulative time: 126.77169752120972\n\nbatch:  torch.Size([512, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([512, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [5, 454] [3, 1258] [5, 313] [5, 454] [5, 40] [5, 40] [3, 1258] [5, 40] [5, 40] [5, 40] \n(1024, 3, 32, 32) torch.Size([1024, 1, 10]) torch.Size([1024, 1])\npruning_in_iteration open status: True\nratio of positive domain = 340 / 1024 = 0.33203125\npruning-in-iteration extra time: 0.04941105842590332\nTensors transferred: pre=122.0000M lA=40.7461M alpha=6.6621M beta=0.0303M\nThis batch time : update_bounds func: 5.4748\t prepare: 0.0527\t bound: 5.1221\t transfer: 0.2817\t finalize: 0.0175\nAccumulated time: update_bounds func: 53.5032\t prepare: 0.8547\t bound: 49.2556\t transfer: 3.1179\t finalize: 0.2613\nbatch bounding time:  5.4753007888793945\nCurrent worst splitting domains lb-rhs (depth):\n-0.02925 (22), -0.02777 (21), -0.02660 (25), -0.02660 (23), -0.02582 (22), -0.02562 (25), -0.02498 (22), -0.02485 (24), -0.02451 (22), -0.02413 (22), -0.02389 (23), -0.02369 (24), -0.02358 (23), -0.02355 (22), -0.02348 (25), -0.02327 (25), -0.02311 (22), -0.02309 (24), -0.02258 (25), -0.02238 (25), \nlength of domains: 1296\nTotal time: 16.1235\t pickout: 0.0188\t decision: 10.4850\t get_bound: 5.4754\t add_domain: 0.1443\nAccumulated time:\t pickout: 0.2398\t decision: 86.7608\t get_bound: 53.5152\t add_domain: 2.0579\nCurrent (lb-rhs): -0.029248595237731934\n4933 domains visited\nCumulative time: 142.8996570110321\n\nbatch:  torch.Size([512, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([512, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [3, 3627] [4, 191] [5, 454] [3, 3627] [5, 313] [3, 3316] [3, 3294] [3, 1667] [4, 191] [3, 3051] \n(1024, 3, 32, 32) torch.Size([1024, 1, 10]) torch.Size([1024, 1])\npruning_in_iteration open status: True\nratio of positive domain = 363 / 1024 = 0.3544921875\npruning-in-iteration extra time: 0.04260897636413574\nTensors transferred: pre=122.0000M lA=39.3760M alpha=6.6621M beta=0.0303M\nThis batch time : update_bounds func: 3.4088\t prepare: 0.0519\t bound: 3.1008\t transfer: 0.2354\t finalize: 0.0197\nAccumulated time: update_bounds func: 56.9120\t prepare: 0.9067\t bound: 52.3563\t transfer: 3.3533\t finalize: 0.2810\nbatch bounding time:  3.409240484237671\nCurrent worst splitting domains lb-rhs (depth):\n-0.02925 (22), -0.02777 (21), -0.02660 (25), -0.02660 (23), -0.02582 (22), -0.02513 (26), -0.02498 (22), -0.02485 (24), -0.02451 (22), -0.02413 (22), -0.02389 (23), -0.02369 (24), -0.02358 (23), -0.02355 (22), -0.02311 (22), -0.02309 (24), -0.02302 (26), -0.02275 (26), -0.02230 (23), -0.02202 (26), \nlength of domains: 1445\nTotal time: 14.1367\t pickout: 0.0182\t decision: 10.5614\t get_bound: 3.4093\t add_domain: 0.1478\nAccumulated time:\t pickout: 0.2580\t decision: 97.3222\t get_bound: 56.9246\t add_domain: 2.2058\nCurrent (lb-rhs): -0.029248595237731934\n5296 domains visited\nCumulative time: 157.04168701171875\n\nbatch:  torch.Size([512, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([512, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [5, 124] [5, 40] [3, 3286] [5, 40] [4, 191] [4, 191] [3, 3316] [5, 40] [5, 40] [4, 55] \n(1024, 3, 32, 32) torch.Size([1024, 1, 10]) torch.Size([1024, 1])\npruning_in_iteration open status: True\nratio of positive domain = 343 / 1024 = 0.3349609375\npruning-in-iteration extra time: 0.0381319522857666\nTensors transferred: pre=122.0000M lA=40.5674M alpha=6.6621M beta=0.0312M\nThis batch time : update_bounds func: 3.3612\t prepare: 0.0520\t bound: 3.0732\t transfer: 0.2176\t finalize: 0.0175\nAccumulated time: update_bounds func: 60.2732\t prepare: 0.9587\t bound: 55.4296\t transfer: 3.5709\t finalize: 0.2985\nbatch bounding time:  3.361851930618286\nCurrent worst splitting domains lb-rhs (depth):\n-0.02925 (22), -0.02777 (21), -0.02660 (25), -0.02660 (23), -0.02582 (22), -0.02498 (22), -0.02485 (24), -0.02463 (27), -0.02451 (22), -0.02413 (22), -0.02389 (23), -0.02369 (24), -0.02358 (23), -0.02355 (22), -0.02311 (22), -0.02309 (24), -0.02274 (27), -0.02255 (27), -0.02230 (23), -0.02227 (27), \nlength of domains: 1614\nTotal time: 12.4049\t pickout: 0.0188\t decision: 8.7969\t get_bound: 3.3620\t add_domain: 0.2272\nAccumulated time:\t pickout: 0.2769\t decision: 106.1190\t get_bound: 60.2865\t add_domain: 2.4330\nCurrent (lb-rhs): -0.029248595237731934\n5639 domains visited\nCumulative time: 169.45060348510742\n\nbatch:  torch.Size([512, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([512, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [3, 1667] [3, 670] [3, 670] [3, 1667] [3, 1883] [3, 3294] [3, 670] [5, 313] [2, 10573] [3, 1883] \n(1024, 3, 32, 32) torch.Size([1024, 1, 10]) torch.Size([1024, 1])\npruning_in_iteration open status: True\nratio of positive domain = 295 / 1024 = 0.2880859375\npruning-in-iteration extra time: 0.04157686233520508\nTensors transferred: pre=122.0000M lA=43.4268M alpha=6.6621M beta=0.0332M\nThis batch time : update_bounds func: 3.5460\t prepare: 0.0492\t bound: 3.2659\t transfer: 0.2069\t finalize: 0.0231\nAccumulated time: update_bounds func: 63.8191\t prepare: 1.0079\t bound: 58.6954\t transfer: 3.7777\t finalize: 0.3216\nbatch bounding time:  3.5465402603149414\nCurrent worst splitting domains lb-rhs (depth):\n-0.02925 (22), -0.02777 (21), -0.02660 (25), -0.02660 (23), -0.02582 (22), -0.02498 (22), -0.02485 (24), -0.02451 (22), -0.02415 (28), -0.02413 (22), -0.02389 (23), -0.02369 (24), -0.02358 (23), -0.02355 (22), -0.02311 (22), -0.02309 (24), -0.02288 (28), -0.02230 (23), -0.02224 (28), -0.02205 (28), \nlength of domains: 1831\nTotal time: 11.6872\t pickout: 0.0180\t decision: 7.9643\t get_bound: 3.5466\t add_domain: 0.1583\nAccumulated time:\t pickout: 0.2948\t decision: 114.0833\t get_bound: 63.8331\t add_domain: 2.5913\nCurrent (lb-rhs): -0.029248595237731934\n5934 domains visited\nCumulative time: 181.14241647720337\n\nbatch:  torch.Size([512, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([512, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [4, 316] [3, 1876] [4, 191] [3, 3051] [5, 124] [4, 191] [3, 1667] [3, 3051] [4, 191] [3, 1667] \n(1024, 3, 32, 32) torch.Size([1024, 1, 10]) torch.Size([1024, 1])\npruning_in_iteration open status: True\nratio of positive domain = 345 / 1024 = 0.3369140625\npruning-in-iteration extra time: 0.047991275787353516\nTensors transferred: pre=122.0000M lA=40.4482M alpha=6.6621M beta=0.0352M\nThis batch time : update_bounds func: 3.9129\t prepare: 0.0523\t bound: 3.6194\t transfer: 0.2233\t finalize: 0.0169\nAccumulated time: update_bounds func: 67.7320\t prepare: 1.0602\t bound: 62.3148\t transfer: 4.0010\t finalize: 0.3385\nbatch bounding time:  3.913353443145752\nCurrent worst splitting domains lb-rhs (depth):\n-0.02925 (22), -0.02777 (21), -0.02660 (25), -0.02660 (23), -0.02582 (22), -0.02498 (22), -0.02485 (24), -0.02451 (22), -0.02413 (22), -0.02389 (23), -0.02370 (29), -0.02369 (24), -0.02358 (23), -0.02355 (22), -0.02311 (22), -0.02309 (24), -0.02241 (29), -0.02230 (23), -0.02198 (22), -0.02184 (28), \nlength of domains: 1998\nTotal time: 12.4042\t pickout: 0.0183\t decision: 8.3287\t get_bound: 3.9134\t add_domain: 0.1437\nAccumulated time:\t pickout: 0.3132\t decision: 122.4120\t get_bound: 67.7466\t add_domain: 2.7350\nCurrent (lb-rhs): -0.029248595237731934\n6279 domains visited\nCumulative time: 193.55188965797424\n\nbatch:  torch.Size([512, 32, 32, 32]) pre split depth:  1\nbatch:  torch.Size([512, 32, 32, 32]) post split depth:  1\nsplitting decisions: \nsplit level 0: [3, 1667] [3, 1883] [5, 313] [3, 681] [3, 3051] [3, 3324] [2, 14023] [3, 3051] [2, 4216] [3, 3286] \n(1024, 3, 32, 32) torch.Size([1024, 1, 10]) torch.Size([1024, 1])\npruning_in_iteration open status: True\nratio of positive domain = 240 / 1024 = 0.234375\npruning-in-iteration extra time: 0.04284310340881348\nTensors transferred: pre=122.0000M lA=46.7031M alpha=6.6621M beta=0.0381M\nThis batch time : update_bounds func: 4.5605\t prepare: 0.0582\t bound: 4.2221\t transfer: 0.2484\t finalize: 0.0303\nAccumulated time: update_bounds func: 72.2926\t prepare: 1.1184\t bound: 66.5369\t transfer: 4.2494\t finalize: 0.3689\nbatch bounding time:  4.5610785484313965\nTraceback (most recent call last):\n  File \"abcrown.py\", line 647, in <module>\n    main()\n  File \"abcrown.py\", line 570, in main\n    refined_betas=refined_betas, attack_images=all_adv_candidates, attack_margins=attack_margins)\n  File \"abcrown.py\", line 392, in complete_verifier\n    attack_images=this_spec_attack_images)\n  File \"abcrown.py\", line 206, in bab\n    timeout=timeout, refined_betas=refined_betas, rhs=rhs)\n  File \"/home/tristan/.local/share/autoverify/verifiers/abcrown/tool/complete_verifier/batch_branch_and_bound.py\", line 561, in relu_bab_parallel\n    stop_func=stop_criterion, multi_spec_keep_func=multi_spec_keep_func)\n  File \"/home/tristan/.local/share/autoverify/verifiers/abcrown/tool/complete_verifier/batch_branch_and_bound.py\", line 283, in batch_verification\n    branching_decision, rhs, intermediate_betas, check_infeasibility, dom_cs, (2*num_copy)*batch)\n  File \"/home/tristan/.local/share/autoverify/verifiers/abcrown/tool/complete_verifier/branching_domains.py\", line 536, in add\n    [lb.append(new_lb[right_indexer + batch]) if new_lb is not None else None for lb, new_lb in zip(self.all_lb_alls, lb_alls)]\n  File \"/home/tristan/.local/share/autoverify/verifiers/abcrown/tool/complete_verifier/branching_domains.py\", line 536, in <listcomp>\n    [lb.append(new_lb[right_indexer + batch]) if new_lb is not None else None for lb, new_lb in zip(self.all_lb_alls, lb_alls)]\n  File \"/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n    return func(*args, **kwargs)\n  File \"/home/tristan/.local/share/autoverify/verifiers/abcrown/tool/complete_verifier/tensor_storage.py\", line 70, in append\n    new_tensor = self._allocate(new_size)\n  File \"/home/tristan/.local/share/autoverify/verifiers/abcrown/tool/complete_verifier/tensor_storage.py\", line 51, in _allocate\n    return torch.empty(allocate_shape, dtype=self.dtype, device=self.device, pin_memory=True)\nRuntimeError: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n"
        },
        {
            "network": "convBigRELU__PGD",
            "property": "cifar10_spec_idx_88_eps_0.00784",
            "timeout": "300",
            "verifier": "nnenum",
            "config": "Configuration(values={\n  'BRANCH_MODE': 0,\n  'COMPRESS_INIT_BOX': True,\n  'CONTRACT_LP_OPTIMIZED': True,\n  'CONTRACT_LP_TRACK_WITNESSES': True,\n  'CONTRACT_ZONOTOPE': False,\n  'CONTRACT_ZONOTOPE_LP': True,\n  'EAGER_BOUNDS': True,\n  'GLPK_FIRST_PRIMAL': True,\n  'GLPK_RESET_BEFORE_MINIMIZE': False,\n  'GLPK_TIMEOUT': 60,\n  'INF_OVERAPPROX_LP_TIMEOUT': False,\n  'INF_OVERAPPROX_MIN_GEN_LIMIT': False,\n  'OFFLOAD_CLOSEST_TO_ROOT': True,\n  'OVERAPPROX_BOTH_BOUNDS': False,\n  'OVERAPPROX_GEN_LIMIT_MULTIPLIER': 1.5,\n  'OVERAPPROX_LP_TIMEOUT': 1.0,\n  'OVERAPPROX_MIN_GEN_LIMIT': 50,\n  'OVERAPPROX_NEAR_ROOT_MAX_SPLITS': 2,\n  'SINGLE_SET': False,\n  'SKIP_COMPRESSED_CHECK': False,\n  'SKIP_CONSTRAINT_NORMALIZATION': False,\n  'SPLIT_IF_IDLE': True,\n  'SPLIT_ORDER': 1,\n  'SPLIT_TOLERANCE': 1e-08,\n  'TRY_QUICK_OVERAPPROX': True,\n})",
            "success": "ERR",
            "result": "ERR",
            "took": "1.0716118812561035",
            "stderr": "",
            "stdout": "Traceback (most recent call last):\n  File \"/home/tristan/.local/share/autoverify/verifiers/nnenum/tool/src/nnenum/nnenum.py\", line 175, in main\n    network = load_onnx_network_optimized(onnx_filename)\n  File \"/home/tristan/.local/share/autoverify/verifiers/nnenum/tool/src/nnenum/onnx_network.py\", line 294, in load_onnx_network_optimized\n    init = init_map[cur_node.input[1]]\nKeyError: '15'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/tristan/miniconda3/envs/__av__nnenum/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/home/tristan/miniconda3/envs/__av__nnenum/lib/python3.9/runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"/home/tristan/.local/share/autoverify/verifiers/nnenum/tool/src/nnenum/nnenum.py\", line 262, in <module>\n    main()\n  File \"/home/tristan/.local/share/autoverify/verifiers/nnenum/tool/src/nnenum/nnenum.py\", line 178, in main\n    network = load_onnx_network(onnx_filename)\n  File \"/home/tristan/.local/share/autoverify/verifiers/nnenum/tool/src/nnenum/onnx_network.py\", line 764, in load_onnx_network\n    assert o in Settings.ONNX_WHITELIST, f\"Onnx model contains node with op {o}, which may not be a linear operation. \" + \\\nAssertionError: Onnx model contains node with op Div, which may not be a linear operation. Updated Settings.WHITELIST if you want to override this.\n"
        },
        {
            "network": "convBigRELU__PGD",
            "property": "cifar10_spec_idx_88_eps_0.00784",
            "timeout": "300",
            "verifier": "abcrown",
            "config": "Configuration(values={\n  'attack__attack_mode': 'PGD',\n  'attack__enable_mip_attack': False,\n  'attack__pgd_order': 'before',\n  'bab__branching__input_split__enable': False,\n  'bab__branching__method': 'kfsb',\n  'bab__branching__reduceop': 'min',\n  'general__complete_verifier': 'bab',\n  'general__enable_incomplete_verification': True,\n  'general__loss_reduction_func': 'sum',\n  'solver__bound_prop_method': 'alpha-crown',\n})",
            "success": "OK",
            "result": "UNSAT",
            "took": "11.546544075012207",
            "stderr": "",
            "stdout": "/bin/bash: /home/tristan/miniconda3/envs/__av__abcrown/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nConfigurations:\n\ngeneral:\n  device: cuda\n  seed: 100\n  conv_mode: patches\n  deterministic: false\n  double_fp: false\n  loss_reduction_func: sum\n  record_bounds: false\n  sparse_alpha: true\n  save_adv_example: true\n  precompile_jit: false\n  complete_verifier: bab\n  enable_incomplete_verification: true\n  csv_name: null\n  results_file: /tmp/tmp0pek1vk3.txt\n  root_path: ''\nmodel:\n  name: null\n  path: null\n  onnx_path: /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/convBigRELU__PGD.onnx\n  onnx_path_prefix: ''\n  cache_onnx_conversion: false\n  onnx_quirks: null\n  input_shape: null\n  onnx_loader: default_onnx_and_vnnlib_loader\n  onnx_optimization_flags: none\ndata:\n  start: 0\n  end: 10000\n  select_instance: null\n  num_outputs: 10\n  mean: 0.0\n  std: 1.0\n  pkl_path: null\n  dataset: CIFAR\n  data_filter_path: null\n  data_idx_file: null\nspecification:\n  type: lp\n  robustness_type: verified-acc\n  norm: .inf\n  epsilon: null\n  vnnlib_path: /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_88_eps_0.00784.vnnlib\n  vnnlib_path_prefix: ''\nsolver:\n  batch_size: 512\n  min_batch_size_ratio: 0.1\n  use_float64_in_last_iteration: false\n  early_stop_patience: 10\n  start_save_best: 0.5\n  bound_prop_method: alpha-crown\n  prune_after_crown: false\n  crown:\n    batch_size: 1000000000\n    max_crown_size: 1000000000\n  alpha-crown:\n    alpha: true\n    lr_alpha: 0.1\n    iteration: 100\n    share_slopes: false\n    no_joint_opt: false\n    lr_decay: 0.98\n    full_conv_alpha: true\n  beta-crown:\n    lr_alpha: 0.01\n    lr_beta: 0.05\n    lr_decay: 0.98\n    optimizer: adam\n    iteration: 50\n    beta: true\n    beta_warmup: true\n    enable_opt_interm_bounds: false\n    all_node_split_LP: false\n  forward:\n    refine: false\n    dynamic: false\n    max_dim: 10000\n  multi_class:\n    multi_class_method: allclass_domain\n    label_batch_size: 32\n    skip_with_refined_bound: true\n  mip:\n    parallel_solvers: null\n    solver_threads: 1\n    refine_neuron_timeout: 15\n    refine_neuron_time_percentage: 0.8\n    early_stop: true\n    adv_warmup: true\n    mip_solver: gurobi\nbab:\n  initial_max_domains: 1\n  max_domains: .inf\n  decision_thresh: 0\n  timeout: 300.0\n  timeout_scale: 1\n  override_timeout: null\n  get_upper_bound: false\n  dfs_percent: 0.0\n  pruning_in_iteration: true\n  pruning_in_iteration_ratio: 0.2\n  sort_targets: false\n  batched_domain_list: true\n  optimized_intermediate_layers: ''\n  interm_transfer: true\n  cut:\n    enabled: false\n    bab_cut: false\n    lp_cut: false\n    method: null\n    lr: 0.01\n    lr_decay: 1.0\n    iteration: 100\n    bab_iteration: -1\n    early_stop_patience: -1\n    lr_beta: 0.02\n    number_cuts: 50\n    topk_cuts_in_filter: 100\n    batch_size_primal: 100\n    max_num: 1000000000\n    patches_cut: false\n    cplex_cuts: false\n    cplex_cuts_wait: 0\n    cplex_cuts_revpickup: true\n    cut_reference_bounds: true\n    fix_intermediate_bounds: false\n  branching:\n    method: kfsb\n    candidates: 3\n    reduceop: min\n    sb_coeff_thresh: 0.001\n    input_split:\n      enable: false\n      enhanced_bound_prop_method: alpha-crown\n      enhanced_branching_method: naive\n      enhanced_bound_patience: 100000000.0\n      attack_patience: 100000000.0\n      adv_check: 0\n      sort_domain_interval: -1\n  attack:\n    enabled: false\n    beam_candidates: 8\n    beam_depth: 7\n    max_dive_fix_ratio: 0.8\n    min_local_free_ratio: 0.2\n    mip_start_iteration: 5\n    mip_timeout: 30.0\n    adv_pool_threshold: null\n    refined_mip_attacker: false\n    refined_batch_size: null\nattack:\n  pgd_order: before\n  pgd_steps: 100\n  pgd_restarts: 30\n  pgd_early_stop: true\n  pgd_lr_decay: 0.99\n  pgd_alpha: auto\n  pgd_loss_mode: null\n  enable_mip_attack: false\n  cex_path: ./test_cex.txt\n  attack_mode: PGD\n  gama_lambda: 10.0\n  gama_decay: 0.9\n  check_clean: false\n  input_split:\n    pgd_steps: 100\n    pgd_restarts: 30\n    pgd_alpha: auto\n  input_split_enhanced:\n    pgd_steps: 200\n    pgd_restarts: 5000000\n    pgd_alpha: auto\n  input_split_check_adv:\n    pgd_steps: 5\n    pgd_restarts: 5\n    pgd_alpha: auto\ndebug:\n  lp_test: null\n\nExperiments at Mon May 13 21:20:28 2024 on Cerberus\nInternal results will be saved to /tmp/tmp0pek1vk3.txt.\n\n %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nUsing onnx /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/convBigRELU__PGD.onnx\nUsing vnnlib /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_88_eps_0.00784.vnnlib\nPrecompiled vnnlib file found at /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_88_eps_0.00784.vnnlib.compiled\nLoading onnx /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/convBigRELU__PGD.onnx wih quirks {}\n/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/onnx2pytorch/convert/layer.py:30: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_numpy.cpp:178.)\n  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))\n/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/onnx2pytorch/convert/model.py:154: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.\n  \"Using experimental implementation that allows 'batch_size > 1'.\"\nAttack parameters: initialization=uniform, steps=100, restarts=30, alpha=0.001960787922143936, initialization=uniform, GAMA=False\nModel output of first 5 examples:\n tensor([[ 0.39393386, -0.71249902, -1.62325943, -1.73206186, -0.67567652,\n         -2.47843599, -3.07558155, -1.90466976,  2.34261847, -0.12327250]],\n       device='cuda:0')\nAdv example prediction (first 2 examples and 2 restarts):\n tensor([[[ 0.49835101, -0.59551758, -1.62404847, -1.84851956, -0.67073911,\n          -2.59058094, -3.11322832, -1.92009211,  2.25205374, -0.12188021],\n         [ 0.49835101, -0.59551758, -1.62404847, -1.84851956, -0.67073911,\n          -2.59058094, -3.11322832, -1.92009211,  2.25205374, -0.12188021]]],\n       device='cuda:0')\nPGD attack margin (first 2 examles and 10 specs):\n tensor([[[1.75370276, 2.84757137, 3.87610221, 4.10057354, 2.92279291,\n          4.84263468, 5.36528206, 4.17214584, 2.37393403]]], device='cuda:0')\nnumber of violation:  0\nAttack finished in 2.8339 seconds.\nPGD attack failed\nModel prediction is: tensor([[ 0.39393386, -0.71249902, -1.62325943, -1.73206186, -0.67567652,\n         -2.47843599, -3.07558155, -1.90466976,  2.34261847, -0.12327250]],\n       device='cuda:0')\nlayer /34 using sparse-features alpha with shape [2270]; unstable size 2270; total size 32768 (torch.Size([1, 32, 32, 32]))\nlayer /34 start_node /input.7 using sparse-spec alpha with unstable size 82 total_size 8192 output_shape (32, 16, 16)\nlayer /34 start_node /input.11 using sparse-spec alpha with unstable size 52 total_size 64 output_shape 64\nlayer /34 start_node /input.15 using sparse-spec alpha with unstable size 71 total_size 4096 output_shape (64, 8, 8)\nlayer /34 start_node /input.19 using sparse-spec alpha with unstable size 35 total_size 512 output_shape torch.Size([512])\nlayer /34 start_node /input.23 using sparse-spec alpha with unstable size 68 total_size 512 output_shape torch.Size([512])\nlayer /34 start_node /46 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /36 using sparse-features alpha with shape [82]; unstable size 82; total size 8192 (torch.Size([1, 32, 16, 16]))\nlayer /36 start_node /input.11 using sparse-spec alpha with unstable size 52 total_size 64 output_shape 64\nlayer /36 start_node /input.15 using sparse-spec alpha with unstable size 71 total_size 4096 output_shape (64, 8, 8)\nlayer /36 start_node /input.19 using sparse-spec alpha with unstable size 35 total_size 512 output_shape torch.Size([512])\nlayer /36 start_node /input.23 using sparse-spec alpha with unstable size 68 total_size 512 output_shape torch.Size([512])\nlayer /36 start_node /46 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /38 using sparse-features alpha with shape [1004]; unstable size 1004; total size 16384 (torch.Size([1, 64, 16, 16]))\nlayer /38 start_node /input.15 using sparse-spec alpha with unstable size 71 total_size 4096 output_shape (64, 8, 8)\nlayer /38 start_node /input.19 using sparse-spec alpha with unstable size 35 total_size 512 output_shape torch.Size([512])\nlayer /38 start_node /input.23 using sparse-spec alpha with unstable size 68 total_size 512 output_shape torch.Size([512])\nlayer /38 start_node /46 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /40 using sparse-features alpha with shape [71]; unstable size 71; total size 4096 (torch.Size([1, 64, 8, 8]))\nlayer /40 start_node /input.19 using sparse-spec alpha with unstable size 35 total_size 512 output_shape torch.Size([512])\nlayer /40 start_node /input.23 using sparse-spec alpha with unstable size 68 total_size 512 output_shape torch.Size([512])\nlayer /40 start_node /46 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /43 using sparse-features alpha with shape [35]; unstable size 35; total size 512 (torch.Size([1, 512]))\nlayer /43 start_node /input.23 using sparse-spec alpha with unstable size 68 total_size 512 output_shape torch.Size([512])\nlayer /43 start_node /46 using full alpha with unstable size None total_size 9 output_shape 9\nlayer /45 using sparse-features alpha with shape [68]; unstable size 68; total size 512 (torch.Size([1, 512]))\nlayer /45 start_node /46 using full alpha with unstable size None total_size 9 output_shape 9\nOptimizable variables initialized.\ninitial CROWN bounds: tensor([[1.14224100, 1.87831402, 2.95791960, 3.11696887, 1.87635303, 3.81624556,\n         4.26846266, 2.82570100, 1.48256922]], device='cuda:0') None\nverified with init bound!\nResult: unsat\nTime: 9.574295043945312\n"
        },
        {
            "network": "convBigRELU__PGD",
            "property": "cifar10_spec_idx_97_eps_0.00784",
            "timeout": "300",
            "verifier": "nnenum",
            "config": "Configuration(values={\n  'BRANCH_MODE': 0,\n  'COMPRESS_INIT_BOX': True,\n  'CONTRACT_LP_OPTIMIZED': True,\n  'CONTRACT_LP_TRACK_WITNESSES': True,\n  'CONTRACT_ZONOTOPE': False,\n  'CONTRACT_ZONOTOPE_LP': True,\n  'EAGER_BOUNDS': True,\n  'GLPK_FIRST_PRIMAL': True,\n  'GLPK_RESET_BEFORE_MINIMIZE': False,\n  'GLPK_TIMEOUT': 60,\n  'INF_OVERAPPROX_LP_TIMEOUT': False,\n  'INF_OVERAPPROX_MIN_GEN_LIMIT': False,\n  'OFFLOAD_CLOSEST_TO_ROOT': True,\n  'OVERAPPROX_BOTH_BOUNDS': False,\n  'OVERAPPROX_GEN_LIMIT_MULTIPLIER': 1.5,\n  'OVERAPPROX_LP_TIMEOUT': 1.0,\n  'OVERAPPROX_MIN_GEN_LIMIT': 50,\n  'OVERAPPROX_NEAR_ROOT_MAX_SPLITS': 2,\n  'SINGLE_SET': False,\n  'SKIP_COMPRESSED_CHECK': False,\n  'SKIP_CONSTRAINT_NORMALIZATION': False,\n  'SPLIT_IF_IDLE': True,\n  'SPLIT_ORDER': 1,\n  'SPLIT_TOLERANCE': 1e-08,\n  'TRY_QUICK_OVERAPPROX': True,\n})",
            "success": "ERR",
            "result": "ERR",
            "took": "0.8972933292388916",
            "stderr": "",
            "stdout": "Traceback (most recent call last):\n  File \"/home/tristan/.local/share/autoverify/verifiers/nnenum/tool/src/nnenum/nnenum.py\", line 175, in main\n    network = load_onnx_network_optimized(onnx_filename)\n  File \"/home/tristan/.local/share/autoverify/verifiers/nnenum/tool/src/nnenum/onnx_network.py\", line 294, in load_onnx_network_optimized\n    init = init_map[cur_node.input[1]]\nKeyError: '15'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/tristan/miniconda3/envs/__av__nnenum/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/home/tristan/miniconda3/envs/__av__nnenum/lib/python3.9/runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"/home/tristan/.local/share/autoverify/verifiers/nnenum/tool/src/nnenum/nnenum.py\", line 262, in <module>\n    main()\n  File \"/home/tristan/.local/share/autoverify/verifiers/nnenum/tool/src/nnenum/nnenum.py\", line 178, in main\n    network = load_onnx_network(onnx_filename)\n  File \"/home/tristan/.local/share/autoverify/verifiers/nnenum/tool/src/nnenum/onnx_network.py\", line 764, in load_onnx_network\n    assert o in Settings.ONNX_WHITELIST, f\"Onnx model contains node with op {o}, which may not be a linear operation. \" + \\\nAssertionError: Onnx model contains node with op Div, which may not be a linear operation. Updated Settings.WHITELIST if you want to override this.\n"
        },
        {
            "network": "convBigRELU__PGD",
            "property": "cifar10_spec_idx_97_eps_0.00784",
            "timeout": "300",
            "verifier": "abcrown",
            "config": "Configuration(values={\n  'attack__attack_mode': 'PGD',\n  'attack__enable_mip_attack': False,\n  'attack__pgd_order': 'before',\n  'bab__branching__input_split__enable': False,\n  'bab__branching__method': 'kfsb',\n  'bab__branching__reduceop': 'min',\n  'general__complete_verifier': 'bab',\n  'general__enable_incomplete_verification': True,\n  'general__loss_reduction_func': 'sum',\n  'solver__bound_prop_method': 'alpha-crown',\n})",
            "success": "OK",
            "result": "SAT",
            "took": "5.9252800941467285",
            "stderr": "",
            "stdout": "/bin/bash: /home/tristan/miniconda3/envs/__av__abcrown/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nConfigurations:\n\ngeneral:\n  device: cuda\n  seed: 100\n  conv_mode: patches\n  deterministic: false\n  double_fp: false\n  loss_reduction_func: sum\n  record_bounds: false\n  sparse_alpha: true\n  save_adv_example: true\n  precompile_jit: false\n  complete_verifier: bab\n  enable_incomplete_verification: true\n  csv_name: null\n  results_file: /tmp/tmp86fk27qf.txt\n  root_path: ''\nmodel:\n  name: null\n  path: null\n  onnx_path: /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/convBigRELU__PGD.onnx\n  onnx_path_prefix: ''\n  cache_onnx_conversion: false\n  onnx_quirks: null\n  input_shape: null\n  onnx_loader: default_onnx_and_vnnlib_loader\n  onnx_optimization_flags: none\ndata:\n  start: 0\n  end: 10000\n  select_instance: null\n  num_outputs: 10\n  mean: 0.0\n  std: 1.0\n  pkl_path: null\n  dataset: CIFAR\n  data_filter_path: null\n  data_idx_file: null\nspecification:\n  type: lp\n  robustness_type: verified-acc\n  norm: .inf\n  epsilon: null\n  vnnlib_path: /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_97_eps_0.00784.vnnlib\n  vnnlib_path_prefix: ''\nsolver:\n  batch_size: 512\n  min_batch_size_ratio: 0.1\n  use_float64_in_last_iteration: false\n  early_stop_patience: 10\n  start_save_best: 0.5\n  bound_prop_method: alpha-crown\n  prune_after_crown: false\n  crown:\n    batch_size: 1000000000\n    max_crown_size: 1000000000\n  alpha-crown:\n    alpha: true\n    lr_alpha: 0.1\n    iteration: 100\n    share_slopes: false\n    no_joint_opt: false\n    lr_decay: 0.98\n    full_conv_alpha: true\n  beta-crown:\n    lr_alpha: 0.01\n    lr_beta: 0.05\n    lr_decay: 0.98\n    optimizer: adam\n    iteration: 50\n    beta: true\n    beta_warmup: true\n    enable_opt_interm_bounds: false\n    all_node_split_LP: false\n  forward:\n    refine: false\n    dynamic: false\n    max_dim: 10000\n  multi_class:\n    multi_class_method: allclass_domain\n    label_batch_size: 32\n    skip_with_refined_bound: true\n  mip:\n    parallel_solvers: null\n    solver_threads: 1\n    refine_neuron_timeout: 15\n    refine_neuron_time_percentage: 0.8\n    early_stop: true\n    adv_warmup: true\n    mip_solver: gurobi\nbab:\n  initial_max_domains: 1\n  max_domains: .inf\n  decision_thresh: 0\n  timeout: 300.0\n  timeout_scale: 1\n  override_timeout: null\n  get_upper_bound: false\n  dfs_percent: 0.0\n  pruning_in_iteration: true\n  pruning_in_iteration_ratio: 0.2\n  sort_targets: false\n  batched_domain_list: true\n  optimized_intermediate_layers: ''\n  interm_transfer: true\n  cut:\n    enabled: false\n    bab_cut: false\n    lp_cut: false\n    method: null\n    lr: 0.01\n    lr_decay: 1.0\n    iteration: 100\n    bab_iteration: -1\n    early_stop_patience: -1\n    lr_beta: 0.02\n    number_cuts: 50\n    topk_cuts_in_filter: 100\n    batch_size_primal: 100\n    max_num: 1000000000\n    patches_cut: false\n    cplex_cuts: false\n    cplex_cuts_wait: 0\n    cplex_cuts_revpickup: true\n    cut_reference_bounds: true\n    fix_intermediate_bounds: false\n  branching:\n    method: kfsb\n    candidates: 3\n    reduceop: min\n    sb_coeff_thresh: 0.001\n    input_split:\n      enable: false\n      enhanced_bound_prop_method: alpha-crown\n      enhanced_branching_method: naive\n      enhanced_bound_patience: 100000000.0\n      attack_patience: 100000000.0\n      adv_check: 0\n      sort_domain_interval: -1\n  attack:\n    enabled: false\n    beam_candidates: 8\n    beam_depth: 7\n    max_dive_fix_ratio: 0.8\n    min_local_free_ratio: 0.2\n    mip_start_iteration: 5\n    mip_timeout: 30.0\n    adv_pool_threshold: null\n    refined_mip_attacker: false\n    refined_batch_size: null\nattack:\n  pgd_order: before\n  pgd_steps: 100\n  pgd_restarts: 30\n  pgd_early_stop: true\n  pgd_lr_decay: 0.99\n  pgd_alpha: auto\n  pgd_loss_mode: null\n  enable_mip_attack: false\n  cex_path: ./test_cex.txt\n  attack_mode: PGD\n  gama_lambda: 10.0\n  gama_decay: 0.9\n  check_clean: false\n  input_split:\n    pgd_steps: 100\n    pgd_restarts: 30\n    pgd_alpha: auto\n  input_split_enhanced:\n    pgd_steps: 200\n    pgd_restarts: 5000000\n    pgd_alpha: auto\n  input_split_check_adv:\n    pgd_steps: 5\n    pgd_restarts: 5\n    pgd_alpha: auto\ndebug:\n  lp_test: null\n\nExperiments at Mon May 13 21:20:41 2024 on Cerberus\nInternal results will be saved to /tmp/tmp86fk27qf.txt.\n\n %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% idx: 0, vnnlib ID: 0 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nUsing onnx /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/convBigRELU__PGD.onnx\nUsing vnnlib /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_97_eps_0.00784.vnnlib\nPrecompiled vnnlib file found at /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/vnnlib/cifar10_spec_idx_97_eps_0.00784.vnnlib.compiled\nLoading onnx /home/tristan/scriptie/auto-verify-fork/vnncomp/vnncomp2022/benchmarks/cifar2020/onnx/convBigRELU__PGD.onnx wih quirks {}\n/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/onnx2pytorch/convert/layer.py:30: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_numpy.cpp:178.)\n  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))\n/home/tristan/miniconda3/envs/__av__abcrown/lib/python3.7/site-packages/onnx2pytorch/convert/model.py:154: UserWarning: Using experimental implementation that allows 'batch_size > 1'.Batchnorm layers could potentially produce false outputs.\n  \"Using experimental implementation that allows 'batch_size > 1'.\"\nAttack parameters: initialization=uniform, steps=100, restarts=30, alpha=0.001960787922143936, initialization=uniform, GAMA=False\nModel output of first 5 examples:\n tensor([[ 0.96105886, -4.99818325,  0.49796951, -1.34900188,  0.09806482,\n         -1.69785976, -2.05051923, -2.63068223,  0.86458349, -4.01851368]],\n       device='cuda:0')\npgd early stop\nAdv example prediction (first 2 examples and 2 restarts):\n tensor([[[ 0.90111589, -5.00151634,  0.45460641, -1.36289418,  0.06061684,\n          -1.70949721, -2.10207391, -2.64322639,  0.98923618, -3.94865346],\n         [ 0.90111589, -5.00151634,  0.45460641, -1.36289418,  0.06061684,\n          -1.70949721, -2.10207391, -2.64322639,  0.98923618, -3.94865346]]],\n       device='cuda:0')\nPGD attack margin (first 2 examles and 10 specs):\n tensor([[[ 5.90263224,  0.44650948,  2.26400995,  0.84049904,  2.61061311,\n           3.00318980,  3.54434228, -0.08812028,  4.84976959]]],\n       device='cuda:0')\nnumber of violation:  1\nAttack finished in 1.1397 seconds.\nPGD attack succeeded!\nResult: sat\nTime: 4.241852283477783\n"
        }
    ]
}